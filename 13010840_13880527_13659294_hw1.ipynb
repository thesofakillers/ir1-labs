{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2506602b-e699-4ea6-9aa5-4cb13cc4f3c0",
    "deepnote_cell_height": 824,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bba455de8bc2825ca70469169bbadaa",
     "grade": false,
     "grade_id": "cell-c9cd9e550239e812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 1 (Total Points: 250) <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "**Submission instructions**:\n",
    "- The cells with the `# YOUR CODE HERE` denote that these sections are graded and you need to add your implementation.\n",
    "- For Part 1: You can use the `nltk`, `NumPy`, and `matplotlib` libraries here. Other libraries, e.g., `gensim` or `scikit-learn`, may not be used. For Part 2: `gensim` is allowed in addition to the imported libraries in the next code cell\n",
    "- Please use Python 3.6.5 and `pip install -r requirements.txt` to avoid version issues.\n",
    "- The notebook you submit has to have the student ids, separated by underscores (E.g., `12341234_12341234_12341234_hw1.ipynb`).\n",
    "- This will be parsed by a regexp, **so please double check your filename**.\n",
    "- Only one member of each group has to submit the file (**please do not compress the .ipynb file when you will submit it**) to canvas.\n",
    "- **Make sure to check that your notebook runs before submission**. A quick way to do this is to restart the kernel and run all the cells.\n",
    "- Do not change the number of arugments in the given functions.\n",
    "- **Please do not delete/add new cells**. Removing cells **will** lead to grade deduction.\n",
    "- Note, that you are not allowed to use Google Colab.\n",
    "\n",
    "\n",
    "**Learning Goals**:\n",
    "- [Part 1, Term-based matching](#part1) (165 points):\n",
    "    - Learn how to load a dataset and process it.\n",
    "    - Learn how to implement several standard IR methods (TF-IDF, BM25, QL) and understand their weaknesses & strengths.\n",
    "    - Learn how to evaluate IR methods.\n",
    "- [Part 2, Semantic-based matching](#part2) (85 points):\n",
    "    - Learn how to implement vector-space retrieval methods (LSI, LDA).\n",
    "    - Learn how to use LSI and LDA for re-ranking.\n",
    "\n",
    "\n",
    "**Resources**:\n",
    "- **Part 1**: Sections 2.3, 4.1, 4.2, 4.3, 5.3, 5.6, 5.7, 6.2, 7, 8 of [Search Engines: Information Retrieval in Practice](https://ciir.cs.umass.edu/downloads/SEIRiP.pdf)\n",
    "- **Part 2**: [LSI - Chapter 18](https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf) from [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/) book and the [original LDA paper](https://jmlr.org/papers/volume3/blei03a/blei03a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-e743cc22-6da0-404e-8b14-8521799dfd06",
    "deepnote_cell_height": 477,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 4063,
    "execution_start": 1645186524256,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c55bfe94ff1f564dd595547e516c4c6e",
     "grade": false,
     "grade_id": "cell-f5357fabdb9660e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "33e174b2"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "# TODO: Ensure that no additional library is imported in the notebook.\n",
    "# TODO: Only the standard library and the following libraries are allowed:\n",
    "# TODO: You can also use unlisted classes from these libraries or standard libraries (such as defaultdict, Counter, ...).\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# from IPython.html import widgets\n",
    "from collections import namedtuple\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-8e715841-7edb-4d33-8595-6680b7d47ad7",
    "deepnote_cell_height": 412.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8328f758ca5b69f76eee03dbbdd4715",
     "grade": false,
     "grade_id": "cell-7428e12ed184408b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Part 1: Term-based Matching (165 points) <a class=\"anchor\" id=\"part1\"></a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "In the first part, we will learn the basics of IR from loading and preprocessing the material, to implementing some well known search algorithms, to evaluating the ranking performance of the implemented algorithms. We will be using the CACM dataset throughout the assignment. The CACM dataset is a collection of titles and abstracts from the journal CACM (Communication of the ACM).\n",
    "\n",
    "Table of contents:\n",
    "- [Section 1: Text Processing](#text_processing) (5 points)\n",
    "- [Section 2: Indexing](#indexing) (10 points)\n",
    "- [Section 3: Ranking](#ranking) (80 points)\n",
    "- [Section 4: Evaluation](#evaluation) (40 points)\n",
    "- [Section 5: Analysis](#analysis) (30 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-584ac16f-6a3d-441f-a49b-132e6d063b8d",
    "deepnote_cell_height": 412.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e3f938065183dc743aa8254b96b4f5e",
     "grade": false,
     "grade_id": "cell-4b24825cf4ae55ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 1: Text Processing (5 points)<a class=\"anchor\" id=\"text_processing\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "In this section, we will load the dataset and learn how to clean up the data to make it usable for an IR system.\n",
    "First, go through the implementation of the following functions:\n",
    "- `read_cacm_docs`: Reads in the CACM documents.\n",
    "- `read_queries`: Reads in the CACM queries.\n",
    "- `load_stopwords`: Loads the stopwords.\n",
    "\n",
    "The points of this section are earned for the following implementations:\n",
    "- `tokenize` (3 points): Tokenizes the input text.\n",
    "- `stem_token` (2 points): Stems the given token.\n",
    "\n",
    "We are using the [CACM dataset](http://ir.dcs.gla.ac.uk/resources/test_collections/cacm/), which is a small, classic IR dataset, composed of a collection of titles and abstracts from the journal CACM. It comes with relevance judgements for queries, so we can evaluate our IR system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-f5f9096a-743b-4587-85d1-fc5628227046",
    "deepnote_cell_height": 109,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0155d897c7016389d73d160921947a6f",
     "grade": false,
     "grade_id": "cell-45651364e7af6d5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.1 Read the CACM documents\n",
    "\n",
    "\n",
    "The following cell downloads the dataset and unzips it to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00005-2240a6e7-e312-4d7a-842b-04b160e1f27e",
    "deepnote_cell_height": 549,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 161,
    "execution_start": 1645186528335,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d43c9ad6e77cc01ce4cef0c34824930",
     "grade": false,
     "grade_id": "cell-bbc3030bb3fe7e02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "2753ab21"
   },
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    folder_path = os.environ.get(\"IR1_DATA_PATH\")\n",
    "    if not folder_path:\n",
    "        folder_path = \"./datasets/\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    file_location = os.path.join(folder_path, \"cacm.zip\")\n",
    "\n",
    "    # download file if it doesn't exist\n",
    "    if not os.path.exists(file_location):\n",
    "\n",
    "        url = \"https://surfdrive.surf.nl/files/index.php/s/M0FGJpX2p8wDwxR/download\"\n",
    "\n",
    "        with open(file_location, \"wb\") as handle:\n",
    "            print(f\"Downloading file from {url} to {file_location}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for data in tqdm(response.iter_content()):\n",
    "                handle.write(data)\n",
    "            print(\"Finished downloading file\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_path, \"train.txt\")):\n",
    "\n",
    "        # unzip file\n",
    "        with zipfile.ZipFile(file_location, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(folder_path)\n",
    "\n",
    "\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-c429df2f-f87d-4f2b-9acd-506a563a27ba",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31609b0d61d0c74cbd69bc43e47c23be",
     "grade": false,
     "grade_id": "cell-a7dd9a9bf98ede05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "You can see a brief description of each file in the dataset by looking at the README file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-95c07c75-3366-4db7-b32e-1d9903085e53",
    "deepnote_cell_height": 487,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 27,
    "execution_start": 1645186528514,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb3c9a2b8b2bf4fd5b7446b0c4c00f43",
     "grade": false,
     "grade_id": "cell-9b6ff1a17124711f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "4c0f03ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in this directory with sizes:\n",
      "          0 Jun 19 21:01 README\n",
      "\n",
      "    2187734 Jun 19 20:55 cacm.all              text of documents\n",
      "        626 Jun 19 20:58 cite.info             key to citation info\n",
      "                                                (the X sections in cacm.all)\n",
      "       2668 Jun 19 20:55 common_words           stop words used by smart\n",
      "       2194 Jun 19 20:55 make_coll*             shell script to make collection\n",
      "       1557 Jun 19 20:55 make_coll_term*        ditto (both useless without\n",
      "                                                smart system)\n",
      "       9948 Jun 19 20:55 qrels.text             relation giving\n",
      "                                                    qid did 0 0\n",
      "                                                to indicate dument did is\n",
      "                                                relevant to query qid\n",
      "      13689 Jun 19 20:55 query.text             Original text of the query\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Read the README file\n",
    "with open(\"./datasets/README\", \"r\") as file:\n",
    "    readme = file.read()\n",
    "    print(readme)\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-c7944957-2e0e-4d0f-be8e-5b5b0a07c4e0",
    "deepnote_cell_height": 180,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e2712c4c4632bf7486a532f7f18074d",
     "grade": false,
     "grade_id": "cell-73351431869fda76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "We are interested in 4 files:\n",
    "- `cacm.all` : Contains the text for all documents. Note that some documents do not have abstracts available\n",
    "- `query.text` : The text of all queries\n",
    "- `qrels.text` : The relevance judgements\n",
    "- `common_words` : A list of common words. This may be used as a collection of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00009-e25d351e-8873-4762-a7b4-b03b83e9e5bb",
    "deepnote_cell_height": 845,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 26,
    "execution_start": 1645186528538,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1162c15177eb4ffe466531d03cff4a2",
     "grade": false,
     "grade_id": "cell-b44dd14079f278ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "febb8f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\n",
      ".T\n",
      "Preliminary Report-International Algebraic Language\n",
      ".B\n",
      "CACM December, 1958\n",
      ".A\n",
      "Perlis, A. J.\n",
      "Samelson,K.\n",
      ".N\n",
      "CA581203 JB March 22, 1978  8:28 PM\n",
      ".X\n",
      "100\t5\t1\n",
      "123\t5\t1\n",
      "164\t5\t1\n",
      "1\t5\t1\n",
      "1\t5\t1\n",
      "1\t5\t1\n",
      "205\t5\t1\n",
      "210\t5\t1\n",
      "214\t5\t1\n",
      "1982\t5\t1\n",
      "398\t5\t1\n",
      "642\t5\t1\n",
      "669\t5\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "1\t6\t1\n",
      "165\t6\t1\n",
      "196\t6\t1\n",
      "196\t6\t1\n",
      "1273\t6\t1\n",
      "1883\t6\t1\n",
      "324\t6\t1\n",
      "43\t6\t1\n",
      "53\t6\t1\n",
      "91\t6\t1\n",
      "410\t6\t1\n",
      "3184\t6\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### The first 45 lines of the CACM dataset forms the first record\n",
    "# We are interested only in 3 fields.\n",
    "# 1. the '.I' field, which is the document id\n",
    "# 2. the '.T' field (the title) and\n",
    "# 3. the '.W' field (the abstract, which may be absent)\n",
    "with open(\"./datasets/cacm.all\", \"r\") as file:\n",
    "    cacm_all = \"\".join(file.readlines()[:45])\n",
    "    print(cacm_all)\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-d7f469bf-422b-4c8f-b6c8-a7fd61a967cb",
    "deepnote_cell_height": 75.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "250b413baccd8efb186bb46a34ae0060",
     "grade": false,
     "grade_id": "cell-c4bf2e263ec553d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The following function reads the `cacm.all` file. Note that each document has a variable number of lines. The `.I` field denotes a new document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00011-d8ec70b0-a73d-4fdc-a8a5-9f3fb8f3ba22",
    "deepnote_cell_height": 1017,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 0,
    "execution_start": 1645186528613,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57d757e6a7a6938740dc899022b4f291",
     "grade": false,
     "grade_id": "cell-b736116eb419c624",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "fa1cfb4d"
   },
   "outputs": [],
   "source": [
    "def read_cacm_docs(root_folder=\"./datasets/\"):\n",
    "    \"\"\"\n",
    "    Reads in the CACM documents. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "    Returns: A list of 2-tuples: (doc_id, document), where 'document' is a single string created by\n",
    "        appending the title and abstract (separated by a \"\\n\").\n",
    "        In case the record doesn't have an abstract, the document is composed only by the title\n",
    "    \"\"\"\n",
    "    with open(os.path.join(root_folder, \"cacm.all\")) as reader:\n",
    "        lines = reader.readlines()\n",
    "\n",
    "    doc_id, title, abstract = None, None, None\n",
    "\n",
    "    docs = []\n",
    "    line_idx = 0\n",
    "    while line_idx < len(lines):\n",
    "        line = lines[line_idx]\n",
    "        if line.startswith(\".I\"):\n",
    "            if doc_id is not None:\n",
    "                docs.append((doc_id, title, abstract))\n",
    "                doc_id, title, abstract = None, None, None\n",
    "\n",
    "            doc_id = line.split()[-1]\n",
    "            line_idx += 1\n",
    "        elif line.startswith(\".T\"):\n",
    "            # start at next line\n",
    "            line_idx += 1\n",
    "            temp_lines = []\n",
    "            # read till next '.'\n",
    "            while not lines[line_idx].startswith(\".\"):\n",
    "                temp_lines.append(lines[line_idx].strip(\"\\n\"))\n",
    "                line_idx += 1\n",
    "            title = \"\\n\".join(temp_lines).strip(\"\\n\")\n",
    "        elif line.startswith(\".W\"):\n",
    "            # start at next line\n",
    "            line_idx += 1\n",
    "            temp_lines = []\n",
    "            # read till next '.'\n",
    "            while not lines[line_idx].startswith(\".\"):\n",
    "                temp_lines.append(lines[line_idx].strip(\"\\n\"))\n",
    "                line_idx += 1\n",
    "            abstract = \"\\n\".join(temp_lines).strip(\"\\n\")\n",
    "        else:\n",
    "            line_idx += 1\n",
    "\n",
    "    docs.append((doc_id, title, abstract))\n",
    "\n",
    "    p_docs = []\n",
    "    for (did, t, a) in docs:\n",
    "        if a is None:\n",
    "            a = \"\"\n",
    "        p_docs.append((did, t + \"\\n\" + a))\n",
    "    return p_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00012-13ff3a4b-46f3-4ca8-bc11-8b0c7a9e7c37",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 278,
    "execution_start": 1645186528614,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f81930fcd89670b6e20e2255e1f2369",
     "grade": false,
     "grade_id": "cell-a1c43818e0d3fd79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "2097c72a"
   },
   "outputs": [],
   "source": [
    "##### Function check\n",
    "docs = read_cacm_docs()\n",
    "\n",
    "assert isinstance(docs, list)\n",
    "assert len(docs) == 3204, \"There should be exactly 3204 documents\"\n",
    "\n",
    "unzipped_docs = list(zip(*docs))\n",
    "assert np.sum(np.array(list(map(int, unzipped_docs[0])))) == 5134410\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-1ff4fce0-2fe6-4b49-b16d-b5c203b29a47",
    "deepnote_cell_height": 102,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25fd3cfaf2137c56002b850699b3c9d3",
     "grade": false,
     "grade_id": "cell-5ed2ddc91f73c60e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.2 Read the CACM queries\n",
    "\n",
    "Next, let us read the queries. They are formatted similarly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00014-0bdc1ebf-91a6-4e65-8ced-22256899c96d",
    "deepnote_cell_height": 484.8125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 705,
    "execution_start": 1645186528932,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d26c0908e758acb9968b84056b1060a",
     "grade": false,
     "grade_id": "cell-5c7e8e7c4fc2757f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "77367602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\n",
      ".W\n",
      " What articles exist which deal with TSS (Time Sharing System), an\n",
      "operating system for IBM computers?\n",
      ".N\n",
      " 1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)\n",
      " \n",
      ".I 2\n",
      ".W\n",
      " I am interested in articles written either by Prieve or Udo Pooch\n",
      ".A\n",
      "Prieve, B.\n",
      "Pooch, U.\n",
      ".N\n",
      " 2. Richard Alexander, Comp Serv, Langmuir Lab (author = Pooch or Prieve)\n"
     ]
    }
   ],
   "source": [
    "##### The first 15 lines of 'query.text' has 2 queries\n",
    "# We are interested only in 2 fields.\n",
    "# 1. the '.I' - the query id\n",
    "# 2. the '.W' - the query\n",
    "!head -15 ./datasets/query.text\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-eceaa8fc-26fc-4d4d-b03e-7eb44f7e89f3",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f19f311a660f30e3f86cb0f7037d54a",
     "grade": false,
     "grade_id": "cell-88e293507d2dcef6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The following function reads the `query.text` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00016-2445d62c-60c0-4d48-a540-37dbb0d76726",
    "deepnote_cell_height": 711,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 26,
    "execution_start": 1645186529390,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3fbb193211007672849487f5cff1664",
     "grade": false,
     "grade_id": "cell-433e3ad5d0e2572a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "2d5784f8"
   },
   "outputs": [],
   "source": [
    "def read_queries(root_folder=\"./datasets/\"):\n",
    "    \"\"\"\n",
    "    Reads in the CACM queries. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "    Returns: A list of 2-tuples: (query_id, query)\n",
    "    \"\"\"\n",
    "    with open(os.path.join(root_folder, \"query.text\")) as reader:\n",
    "        lines = reader.readlines()\n",
    "\n",
    "    query_id, query = None, None\n",
    "\n",
    "    queries = []\n",
    "    line_idx = 0\n",
    "    while line_idx < len(lines):\n",
    "        line = lines[line_idx]\n",
    "        if line.startswith(\".I\"):\n",
    "            if query_id is not None:\n",
    "                queries.append((query_id, query))\n",
    "                query_id, query = None, None\n",
    "\n",
    "            query_id = line.split()[-1]\n",
    "            line_idx += 1\n",
    "        elif line.startswith(\".W\"):\n",
    "            # start at next line\n",
    "            line_idx += 1\n",
    "            temp_lines = []\n",
    "            # read till next '.'\n",
    "            while not lines[line_idx].startswith(\".\"):\n",
    "                temp_lines.append(lines[line_idx].strip(\"\\n\"))\n",
    "                line_idx += 1\n",
    "            query = \"\\n\".join(temp_lines).strip(\"\\n\")\n",
    "        else:\n",
    "            line_idx += 1\n",
    "\n",
    "    queries.append((query_id, query))\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00017-dc95abe6-036f-4502-89fe-db249a8bbfc4",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 12,
    "execution_start": 1645186529424,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a897b9771b54f447be3418d7246fc4a0",
     "grade": false,
     "grade_id": "cell-6ec540abce66c598",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "1e048f3c"
   },
   "outputs": [],
   "source": [
    "##### Function check\n",
    "queries = read_queries()\n",
    "\n",
    "assert isinstance(queries, list)\n",
    "assert len(queries) == 64 and all(\n",
    "    [q[1] is not None for q in queries]\n",
    "), \"There should be exactly 64 queries\"\n",
    "\n",
    "unzipped_queries = list(zip(*queries))\n",
    "assert np.sum(np.array(list(map(int, unzipped_queries[0])))) == 2080\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-9cf3ea3e-f138-4fe8-b91b-c92620441832",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a300c41912ac63b239070b4c15c9f5c5",
     "grade": false,
     "grade_id": "cell-1c31569491d7b782",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.3 Read the stop words\n",
    "\n",
    "We use the common words stored in `common_words`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00019-4761ff11-d8b4-4f7b-acbf-6d600cfb2ae6",
    "deepnote_cell_height": 329.875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 507,
    "execution_start": 1645186529451,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ad6f5bae6a792504c1c8513ae5751ad",
     "grade": false,
     "grade_id": "cell-34bdb63461418a96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "dcdd806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "about\n",
      "above\n",
      "accordingly\n",
      "across\n",
      "after\n",
      "afterwards\n",
      "again\n",
      "against\n",
      "all\n"
     ]
    }
   ],
   "source": [
    "##### Read the stop words file\n",
    "!head ./datasets/common_words\n",
    "##### Read the README file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-069760f9-d798-4ad6-acfa-e7454a3c3a46",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d0fe612e770213b6397c2179b07a966",
     "grade": false,
     "grade_id": "cell-4744bde0338895d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The following function reads the `common_words` file (For better coverage, we try to keep them in lowercase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00021-51bc2922-72bf-4550-a4fb-c1867fa0e652",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 9,
    "execution_start": 1645186529974,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9409713fd26eb0c33587e190638997c4",
     "grade": false,
     "grade_id": "cell-7357aa40f64e5bcb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "51ba1eb9"
   },
   "outputs": [],
   "source": [
    "def load_stopwords(root_folder=\"./datasets/\"):\n",
    "    \"\"\"\n",
    "    Loads the stopwords. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "    Output: A set of stopwords\n",
    "    \"\"\"\n",
    "    with open(os.path.join(root_folder, \"common_words\")) as reader:\n",
    "        lines = reader.readlines()\n",
    "    stopwords = set([l.strip().lower() for l in lines])\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00022-dda7ebba-cd50-496a-94a3-6c8873e6ba02",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 13,
    "execution_start": 1645186529993,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c8153c3c38133bc2db6e7b076ad470",
     "grade": false,
     "grade_id": "cell-2ca3ac162004de97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "9447931d"
   },
   "outputs": [],
   "source": [
    "##### Function check\n",
    "stopwords = load_stopwords()\n",
    "\n",
    "assert isinstance(stopwords, set)\n",
    "assert len(stopwords) == 428, \"There should be exactly 428 stop words\"\n",
    "\n",
    "assert np.sum(np.array(list(map(len, stopwords)))) == 2234\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-02a21236-0c4b-4910-9573-63f1698beaf3",
    "deepnote_cell_height": 145,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92c1191e9e7291dcf0d70dc67b907a65",
     "grade": false,
     "grade_id": "cell-134b72872f4300cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.4 Tokenization (3 points)\n",
    "\n",
    "We can now write some basic text processing functions.\n",
    "A first step is to tokenize the text.\n",
    "\n",
    "**Note**: Use the  `WordPunctTokenizer` available in the `nltk` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00024-20a3377b-ad24-430a-82d5-e091938ed1fd",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 11,
    "execution_start": 1645186530014,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f5564d3c75bf22fbf832b3a9b938f37",
     "grade": false,
     "grade_id": "cell-322be4c9499bdc4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "bd78cb4e"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (4 points)\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text. Use the WordPunctTokenizer\n",
    "    Input: text - a string\n",
    "    Output: a list of tokens\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    tk = nltk.WordPunctTokenizer()\n",
    "    return tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00025-0c49633e-d8dd-4c28-ac8d-9576e19b544d",
    "deepnote_cell_height": 274.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 54,
    "execution_start": 1645186530041,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e15af22c4d8ae0a3f9dac43bef7097ec",
     "grade": true,
     "grade_id": "cell-7fbf48bf7541a622",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "f61c33ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "tokens = tokenize(text)\n",
    "\n",
    "assert isinstance(tokens, list)\n",
    "assert len(tokens) == 9\n",
    "\n",
    "print(tokens)\n",
    "# output: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-a6caa299-880e-4184-b7bd-5732cfcf3e9c",
    "deepnote_cell_height": 109,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34210618bff4cb47aad2f03cb4b9854c",
     "grade": false,
     "grade_id": "cell-fd1b98ae61b697ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.5 Stemming (2 points)\n",
    "\n",
    "Write a function to stem tokens.\n",
    "Again, you can use the nltk library for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00027-57678786-6fcf-4e83-b285-1e3a44cb6ecb",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186530093,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c4a6aa979d66158c7b6b992af43293a",
     "grade": false,
     "grade_id": "cell-e3f6c8e3f874b28d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "e2a034fd"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (3 points)\n",
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "    Stems the given token using the PorterStemmer from the nltk library\n",
    "    Input: a single token\n",
    "    Output: the stem of the token\n",
    "    \"\"\"\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    return stemmer.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00028-4d95bdd0-4345-4198-aa73-21d2d2ec2b85",
    "deepnote_cell_height": 153,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 0,
    "execution_start": 1645186530094,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9363b4f09b556d424d9c895d4ab57b1c",
     "grade": true,
     "grade_id": "cell-cd6863e6ee6ed205",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "3fc993b6"
   },
   "outputs": [],
   "source": [
    "##### Function check\n",
    "\n",
    "assert stem_token(\"owned\") == \"own\"\n",
    "assert stem_token(\"itemization\") == \"item\"\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-e536d93c-8362-48e7-bfc2-906702746aef",
    "deepnote_cell_height": 123.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b311d014146da6afa1d39542fab9869",
     "grade": false,
     "grade_id": "cell-47c9f90498699110",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 1.6 Summary\n",
    "\n",
    "The following function puts it all together. Given an input string, this functions tokenizes and processes it according to the flags that you set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00030-31b7404f-596c-4622-9100-0bc4ab089ea7",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 0,
    "execution_start": 1645186530137,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ff2d215ee8e0039c5a91fd3de12e6bd",
     "grade": false,
     "grade_id": "cell-dd0d3f46b30801da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "c4811d1d"
   },
   "outputs": [],
   "source": [
    "#### Putting it all together\n",
    "def process_text(text, stem=False, remove_stopwords=False, lowercase_text=False):\n",
    "\n",
    "    tokens = []\n",
    "    for token in tokenize(text):\n",
    "        if remove_stopwords and token.lower() in stopwords:\n",
    "            continue\n",
    "        if stem:\n",
    "            token = stem_token(token)\n",
    "        if lowercase_text:\n",
    "            token = token.lower()\n",
    "        tokens.append(token)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-9539610f-160b-4b6d-a351-9bd434d6c9ea",
    "deepnote_cell_height": 91,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02d433b18eb43654fa4306a7bf55b190",
     "grade": false,
     "grade_id": "cell-8d885bfd2edd43ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "Let's create two sets of preprocessed documents.\n",
    "We can process the documents and queries according to these two configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00032-c5510010-2967-4ace-b12f-1e9e8118e3b4",
    "deepnote_cell_height": 513,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 7882,
    "execution_start": 1645186530149,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbe4ca667be6842fdcf512fbcad50c7f",
     "grade": false,
     "grade_id": "cell-d427365ee0fb21d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "f953b790"
   },
   "outputs": [],
   "source": [
    "# In this configuration:\n",
    "# Don't preprocess the text, except to tokenize\n",
    "config_1 = {\"stem\": False, \"remove_stopwords\": False, \"lowercase_text\": True}\n",
    "\n",
    "\n",
    "# In this configuration:\n",
    "# Preprocess the text, stem and remove stopwords\n",
    "config_2 = {\n",
    "    \"stem\": True,\n",
    "    \"remove_stopwords\": True,\n",
    "    \"lowercase_text\": True,\n",
    "}\n",
    "\n",
    "####\n",
    "doc_repr_1 = []\n",
    "doc_repr_2 = []\n",
    "for (doc_id, document) in docs:\n",
    "    doc_repr_1.append((doc_id, process_text(document, **config_1)))\n",
    "    doc_repr_2.append((doc_id, process_text(document, **config_2)))\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-f33e20e5-c218-4e92-9c23-845b4e42997e",
    "deepnote_cell_height": 415,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b60589aac19e80941d860d9b3f1e9a16",
     "grade": false,
     "grade_id": "cell-b1c102db61ae7495",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 2: Indexing (10 points)<a class=\"anchor\" id=\"indexing\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "\n",
    "\n",
    "A retrieval function usually takes in a query document pair, and scores a query against a document.  Our document set is quite small - just a few thousand documents. However, consider a web-scale dataset with a few million documents. In such a scenario, it would become infeasible to score every query and document pair. In such a case, we can build an inverted index. From Wikipedia:\n",
    "\n",
    "> ... , an inverted index (also referred to as a postings file or inverted file) is a database index storing a mapping from content, such as words or numbers, to its locations in a table, .... The purpose of an inverted index is to allow fast full-text searches, at a cost of increased processing when a document is added to the database. ...\n",
    "\n",
    "\n",
    "Consider a simple inverted index, which maps from word to document. This can improve the performance of a retrieval system significantly. In this assignment, we consider a *simple* inverted index, which maps a word to a set of documents. In practice, however, more complex indices might be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-e0be6b84-2eca-463d-9411-0a876fee2070",
    "deepnote_cell_height": 181.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "710fd943f45523ac36fcb887cc0d4d39",
     "grade": false,
     "grade_id": "cell-fa373192c1b7bb95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Term Frequency-index (10 points)\n",
    "In this assignment, we will be using an index created in memory since our dataset is tiny. To get started, build a simple index that maps each `token` to a list of `(doc_id, count)` where `count` is the count of the `token` in `doc_id`.\n",
    "For consistency, build this index using a python dictionary.\n",
    "\n",
    "Now, implement a function to build an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00035-e27ae026-b063-450a-8cb5-6336175b5cb0",
    "deepnote_cell_height": 495,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 8,
    "execution_start": 1645186538048,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4e8c6b658c469379d5fe511de05b536",
     "grade": false,
     "grade_id": "cell-077599b87e953209",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "b7da36f"
   },
   "outputs": [],
   "source": [
    "# need defaultdict to handle cases when queried word is missing from our documents\n",
    "# https://piazza.com/class/kyiksrdfk0b6te?cid=38\n",
    "# https://piazza.com/class/kyiksrdfk0b6te?cid=39\n",
    "from collections import defaultdict\n",
    "\n",
    "# TODO: Implement this! (10 points)\n",
    "def build_tf_index(documents):\n",
    "    \"\"\"\n",
    "    Build an inverted index (with counts).\n",
    "    The output is a dictionary which takes in a token and\n",
    "    returns a list of (doc_id, count)\n",
    "    where 'count' is the count of the 'token' in 'doc_id'\n",
    "\n",
    "    Input: a list of documents - (doc_id, tokens)\n",
    "    Output: An inverted index implemented within a pyhton dictionary:\n",
    "        [token] -> [(doc_id, token_count)]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    tf_index = defaultdict(list)\n",
    "    for doc_id, tokens in documents:\n",
    "        tokens_set = set(tokens)\n",
    "        for token in tokens_set:\n",
    "            tf_index[token].append((doc_id, tokens.count(token)))\n",
    "    return tf_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-4124a1b7-00df-4a57-861c-2e9cd705ce17",
    "deepnote_cell_height": 55,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15e7041b4323d2a290322de538ff7670",
     "grade": false,
     "grade_id": "cell-093aebfa504f96f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Now we can build indexed documents and preprocess the queries based on the two configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00037-db077994-3c24-4f9b-a642-d416e54c8d1e",
    "deepnote_cell_height": 531,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 845,
    "execution_start": 1645186538116,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e27540c1d8d77a3779a05f557f3f40c6",
     "grade": false,
     "grade_id": "cell-b2ff1676348b90a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "2d1fa9f3"
   },
   "outputs": [],
   "source": [
    "#### Indexed documents based on the two configs\n",
    "\n",
    "# Create the 2 indices\n",
    "tf_index_1 = build_tf_index(doc_repr_1)\n",
    "tf_index_2 = build_tf_index(doc_repr_2)\n",
    "\n",
    "# This function returns the tf_index of the corresponding config\n",
    "def get_index(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {1: tf_index_1, 2: tf_index_2}[index_set]\n",
    "\n",
    "\n",
    "####\n",
    "#### Preprocessed query based on the two configs\n",
    "\n",
    "# This function preprocesses the text given the index set, according to the specified config\n",
    "def preprocess_query(text, index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    if index_set == 1:\n",
    "        return process_text(text, **config_1)\n",
    "    elif index_set == 2:\n",
    "        return process_text(text, **config_2)\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00038-fb5a08f4-5f40-4923-a62b-02af9b853e1f",
    "deepnote_cell_height": 298.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244305,
    "execution_start": 1645186538979,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0cbc8703e1248cd6edf03f9019b69db",
     "grade": true,
     "grade_id": "cell-fc7c7232d5d2ee46",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "2220f2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tf index for computer: [('4', 1), ('7', 1), ('10', 1), ('13', 1), ('19', 1), ('22', 1), ('23', 1), ('37', 1), ('40', 3), ('41', 1)]\n",
      "sample tf index for examples: [('111', 1), ('320', 1), ('644', 1), ('691', 1), ('727', 1), ('848', 1), ('892', 1), ('893', 1), ('1049', 1), ('1051', 1)]\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "\n",
    "assert isinstance(tf_index_1, dict)\n",
    "\n",
    "assert isinstance(tf_index_1[\"computer\"], list)\n",
    "print(\"sample tf index for computer:\", tf_index_1[\"computer\"][:10])\n",
    "\n",
    "assert isinstance(tf_index_1[\"examples\"], list)\n",
    "print(\"sample tf index for examples:\", tf_index_1[\"examples\"][:10])\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00039-0f63d80d-3d2c-4ed8-b1a3-ef57df6a812d",
    "deepnote_cell_height": 298.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244324,
    "execution_start": 1645186539032,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d49b8ac36815d9a5cb4bed838ab53a50",
     "grade": true,
     "grade_id": "cell-ff06bd11204db250",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "cfcc3871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tf index for computer: [('4', 1), ('7', 1), ('10', 1), ('13', 1), ('19', 1), ('22', 1), ('23', 1), ('37', 1), ('40', 3), ('41', 1)]\n",
      "sample tf index for examples: []\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "\n",
    "assert isinstance(tf_index_2, dict)\n",
    "\n",
    "assert isinstance(tf_index_2[\"computer\"], list)\n",
    "print(\"sample tf index for computer:\", tf_index_1[\"computer\"][:10])\n",
    "\n",
    "assert isinstance(tf_index_2[\"examples\"], list)\n",
    "print(\"sample tf index for examples:\", tf_index_2[\"examples\"][:10])\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-06978f59-9c49-41bf-86fa-2ce4ff5666a1",
    "deepnote_cell_height": 493.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "880b2ef3ca405f2af6e0667d2dc7a600",
     "grade": false,
     "grade_id": "cell-89eba71f04310291",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "## Section 3: Ranking  (80 points) <a class=\"anchor\" id=\"ranking\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "Now that we have cleaned and processed our dataset, we can start building simple IR systems.\n",
    "\n",
    "For now, we consider *simple* IR systems, which involve computing scores from the tokens present in the document/query. More advanced methods are covered in later assignments.\n",
    "\n",
    "We will implement the following methods in this section:\n",
    "- [Section 3.1: Bag of Words](#bow) (10 points)\n",
    "- [Section 3.2: TF-IDF](#tfidf) (15 points)\n",
    "- [Section 3.3: Query Likelihood Model](#qlm) (35 points)\n",
    "- [Section 3.4: BM25](#bm25) (20 points)\n",
    "\n",
    "*All search functions should be able to handle multiple words queries.*\n",
    "\n",
    "**Scoring policy:**\n",
    "Your implementations in this section are scored based on the expected performance of your ranking functions.\n",
    "You will get a full mark if your implementation meets the expected performance (measured by some evaluation metric).\n",
    "Otherwise, you may get partial credit.\n",
    "For example, if your *Bag of words* ranking function has 60% of expected performance, you will get 6 out of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-95b4f50b-25e3-4bfc-853e-458b38aa6f80",
    "deepnote_cell_height": 250.375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c74e5061917358300c6e8085ec07864",
     "grade": false,
     "grade_id": "cell-3daf70a60e393adf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Section 3.1: Bag of Words (10 points)<a class=\"anchor\" id=\"bow\"></a>\n",
    "\n",
    "Probably the simplest IR model is the Bag of Words (BOW) model.\n",
    "Implement a function that scores and ranks all the documents against a query using this model.\n",
    "\n",
    "- For consistency, you should use the count of the token and **not** the binary indicator.\n",
    "- Use `float` type for the scores (even though the scores are integers in this case).\n",
    "- No normalization of the scores is necessary, as the ordering is what we are interested in.\n",
    "- If two documents have the same score, they can have any ordering: you are not required to disambiguate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "00042-78747ee0-9c14-474c-ab83-0bb691fe4f4f",
    "deepnote_cell_height": 513,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 11244305,
    "execution_start": 1645186539076,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fee4640e22bfc4f05eb958a675ef40e7",
     "grade": false,
     "grade_id": "cell-de9cf0459c4b9324",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "15c8e32"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def bow_search(query, index_set):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query.\n",
    "    Note: You have to use the `get_index` function created in the previous cells\n",
    "    Input:\n",
    "        query - a (unprocessed) query\n",
    "        index_set - the index to use\n",
    "    Output: a list of (document_id, score),\n",
    "        sorted in descending relevance to the given query.\n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # total count per document\n",
    "    documents = defaultdict(float)\n",
    "    for token in processed_query:\n",
    "        for document_id, token_count in index[token]:\n",
    "            # aggregate counts of this token across all documents\n",
    "            documents[document_id] += token_count\n",
    "    # convert documents to list and sort descending\n",
    "    documents = sorted(list(documents.items()), key=lambda x: x[1], reverse=True)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00043-a779ed03-89a7-4a9b-8bf4-e356d3146ecd",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244335,
    "execution_start": 1645186539129,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "613524fbbf02b1d122c6611a71fbf11b",
     "grade": true,
     "grade_id": "cell-9f6aceae6dd9125f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "a4e9855b"
   },
   "outputs": [],
   "source": [
    "#### Function check\n",
    "\n",
    "test_bow = bow_search(\"how to implement bag of words search\", index_set=1)[:5]\n",
    "assert isinstance(test_bow, list)\n",
    "assert len(test_bow[0]) == 2\n",
    "assert isinstance(test_bow[0][0], str)\n",
    "assert isinstance(test_bow[0][1], float)\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00044-8c0e39e0-03a8-42d9-88c0-9811823ca925",
    "deepnote_cell_height": 393.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244410,
    "execution_start": 1645186539130,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9af20897659edb62fe77598483590500",
     "grade": true,
     "grade_id": "cell-4eed3abf233d9b58",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "f3e133b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Results:\n",
      "Rank 0(1.3e+01): On Computing The Fast Fourier Transform\\nCooley an...\n",
      "Rank 1(1.2e+01): Variable Length Tree Structures Having Minimum Ave...\n",
      "Rank 2(1.1e+01): A Modular Computer Sharing System\\nAn alternative ...\n",
      "Rank 3(1e+01): PEEKABIT, Computer Offspring of Punched\\nCard PEEK...\n",
      "Rank 4(9.0): Computer Simulation-Discussion of the\\nTechnique a...\n"
     ]
    }
   ],
   "source": [
    "docs_by_id = dict(docs)\n",
    "\n",
    "\n",
    "def print_results(docs, len_limit=50):\n",
    "    for i, (doc_id, score) in enumerate(docs):\n",
    "        doc_content = (\n",
    "            docs_by_id[doc_id].strip().replace(\"\\n\", \"\\\\n\")[:len_limit] + \"...\"\n",
    "        )\n",
    "        print(f\"Rank {i}({score:.2}): {doc_content}\")\n",
    "\n",
    "\n",
    "test_bow_2 = bow_search(\"computer search word\", index_set=2)[:5]\n",
    "print(f\"BOW Results:\")\n",
    "print_results(test_bow_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00045-c576132c-ae55-4ef4-bf93-365a98921a28",
    "deepnote_cell_height": 285.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 2,
    "execution_start": 1645186539173,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c9c8b16c8e7d1032f101e9da8a6e845",
     "grade": true,
     "grade_id": "cell-4d65a2d7090c466c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "76a29ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Results:\n",
      "Rank 0(9.0): CURRICULUM 68 -- Recommendations for Academic\\nPro...\n",
      "Rank 1(9.0): Variable Length Tree Structures Having Minimum Ave...\n",
      "Rank 2(7.0): Computer Formulation of the Equations of Motion Us...\n",
      "Rank 3(7.0): The Effects of Multiplexing on a Computer-Communic...\n",
      "Rank 4(6.0): Optimizing Bit-time Computer Simulation\\nA major c...\n"
     ]
    }
   ],
   "source": [
    "test_bow_1 = bow_search(\"computer search word\", index_set=1)[:5]\n",
    "print(f\"BOW Results:\")\n",
    "print_results(test_bow_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "00046-5b571ae5-b918-4fbb-ad83-5d5d6669c906",
    "deepnote_cell_height": 168.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 2,
    "execution_start": 1645186539174,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7e593847aa4202ae45ec061fb18ad73",
     "grade": true,
     "grade_id": "cell-dedf36ab5853ce20",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "b05098cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 docs for index1: ('1771', '1936', '1543', '2535', '678')\n",
      "top-5 docs for index2: ('1525', '1936', '1844', '1700', '1366')\n"
     ]
    }
   ],
   "source": [
    "print(\"top-5 docs for index1:\", list(zip(*test_bow_1[:5]))[0])\n",
    "print(\"top-5 docs for index2:\", list(zip(*test_bow_2[:5]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-9898438b-a142-41ea-936e-02202738220e",
    "deepnote_cell_height": 235,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b04352ee0716dfdf094b8cdb6f32e984",
     "grade": false,
     "grade_id": "cell-a5c09c79ac1f2871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Section 3.2: TF-IDF (15 points) <a class=\"anchor\" id=\"tfidf\"></a>\n",
    "\n",
    "Before we implement the tf-idf scoring functions, let's first write a function to compute the document frequencies of all words.\n",
    "\n",
    "#### 3.2.1 Document frequency (5 points)\n",
    "Compute the document frequencies of all tokens in the collection.\n",
    "Your code should return a dictionary with tokens as its keys and the number of documents containing the token as values.\n",
    "For consistency, the values should have `int` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "00048-7d15cfba-6fc3-46f2-8fc4-e2ea33b6f8ab",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 11244452,
    "execution_start": 1645186539217,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c53263cf4c0b0ffcaae08b91fc364cc",
     "grade": false,
     "grade_id": "cell-9a2369f32e864b8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "da17c69a"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "def compute_df(documents):\n",
    "    \"\"\"\n",
    "    Compute the document frequency of all terms in the vocabulary\n",
    "    Input: A list of documents\n",
    "    Output: A dictionary with {token: document frequency (int)}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df_dict = defaultdict(int)\n",
    "    for document in documents:\n",
    "        # we only count a token once per document, so work on the set of unique doc tokens\n",
    "        unique_doc_tokens = set(document)\n",
    "        for token in unique_doc_tokens:\n",
    "            df_dict[token] += 1\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "00049-d09fb33d-2d8c-4b8b-aab7-f458f87425f7",
    "deepnote_cell_height": 297,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 94,
    "execution_start": 1645186539218,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154985511d7925c5793a1f97dea81880",
     "grade": false,
     "grade_id": "cell-4c3bddd0b73ac90e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "46458dbe"
   },
   "outputs": [],
   "source": [
    "#### Compute df based on the two configs\n",
    "\n",
    "# get the document frequencies of each document\n",
    "df_1 = compute_df([d[1] for d in doc_repr_1])\n",
    "df_2 = compute_df([d[1] for d in doc_repr_2])\n",
    "\n",
    "\n",
    "def get_df(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {1: df_1, 2: df_2}[index_set]\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "00050-0d714f0a-0f10-4e51-be4f-9dc1c0905ca9",
    "deepnote_cell_height": 204.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 422,
    "execution_start": 1645186539327,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "110cc180068cf3f77c682ee3de2a117c",
     "grade": true,
     "grade_id": "cell-79e8a6db1e5fc46f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "43b9edf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "\n",
    "print(df_1[\"computer\"])\n",
    "print(df_2[\"computer\"])\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00051-7d6233d2-d8c7-4fc4-8207-4bedbd2085af",
    "deepnote_cell_height": 271,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0d577668fa51b80aeab6e67209ae73b",
     "grade": false,
     "grade_id": "cell-52f6acc487e1b96d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "#### 3.2.2 TF-IDF search (10 points)\n",
    "Next, implement a function that computes a tf-idf score, given a query.\n",
    "Use the following formulas for TF and IDF:\n",
    "\n",
    "$$ TF=\\log (1 + f_{d,t}) $$\n",
    "\n",
    "$$ IDF=\\log (\\frac{N}{n_t})$$\n",
    "\n",
    "where $f_{d,t}$ is the frequency of token $t$ in document $d$, $N$ is the number of total documents and $n_t$ is the number of documents containing token $t$.\n",
    "\n",
    "**Note:** your implementation will be auto-graded assuming you have used the above formulas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "00052-d1b23bf4-b5f4-4a82-8df2-d8772e42b73a",
    "deepnote_cell_height": 567,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 20,
    "execution_start": 1645186539352,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3534c44b4a3419ca1db98eebe7115dc1",
     "grade": false,
     "grade_id": "cell-2fb5ba34b2994cd9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "1d6e90cb"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def tfidf_search(query, index_set):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using tf-idf.\n",
    "    Note #1: You have to use the `get_index` (and the `get_df`) function\n",
    "    created in the previous cells\n",
    "    Input:\n",
    "        query - a (unprocessed) query\n",
    "        index_set - the index to use\n",
    "    Output: a list of (document_id, score),\n",
    "        sorted in descending relevance to the given query\n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "\n",
    "    N = len(docs)\n",
    "    # YOUR CODE HERE\n",
    "    documents = defaultdict(float)\n",
    "    for token in processed_query:\n",
    "        for document_id, token_count in index[token]:\n",
    "            tf = np.log(1 + token_count)\n",
    "            idf = np.log(N / df[token])\n",
    "            tf_idf = tf * idf\n",
    "            documents[document_id] += tf_idf\n",
    "    # convert documents to list and sort descending\n",
    "    documents = sorted(list(documents.items()), key=lambda x: x[1], reverse=True)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "00053-487c5ebc-c09b-46d0-9f43-38c4f74264e7",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 80,
    "execution_start": 1645186539384,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b66a514663d898694b09a23a597312b",
     "grade": true,
     "grade_id": "cell-bc68aeeacf42beb3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "4907bb8a"
   },
   "outputs": [],
   "source": [
    "#### Function check\n",
    "test_tfidf = tfidf_search(\"how to implement tf idf search\", index_set=1)[:5]\n",
    "assert isinstance(test_tfidf, list)\n",
    "assert len(test_tfidf[0]) == 2\n",
    "assert isinstance(test_tfidf[0][0], str)\n",
    "assert isinstance(test_tfidf[0][1], float)\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "00054-ca226c89-ef3a-464d-aeed-2750ea928db4",
    "deepnote_cell_height": 285.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 222,
    "execution_start": 1645186539544,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98fb1326cf4bf7983ae237ca8a9105f9",
     "grade": true,
     "grade_id": "cell-c7702fa8179fadb9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "fddf59b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Results:\n",
      "Rank 0(1.3e+01): PEEKABIT, Computer Offspring of Punched\\nCard PEEK...\n",
      "Rank 1(9.8): Variable Length Tree Structures Having Minimum Ave...\n",
      "Rank 2(8.2): A Stochastic Approach to the Grammatical Coding of...\n",
      "Rank 3(8.1): Full Table Quadratic Searching for Scatter Storage...\n",
      "Rank 4(7.6): Use of Tree Structures for Processing Files\\nIn da...\n"
     ]
    }
   ],
   "source": [
    "test_tfidf_2 = tfidf_search(\"computer word search\", index_set=2)[:5]\n",
    "print(f\"TFIDF Results:\")\n",
    "print_results(test_tfidf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "00055-861246a7-b33f-43ef-8ffc-16cd768e3e3e",
    "deepnote_cell_height": 285.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 179,
    "execution_start": 1645186539589,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "733b5b67be5e53989f5b763ce5e52ee9",
     "grade": true,
     "grade_id": "cell-3284f50ac29abbaa",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "83683be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Results:\n",
      "Rank 0(9.4): Variable Length Tree Structures Having Minimum Ave...\n",
      "Rank 1(7.4): On the Feasibility of Voice Input to\\nan On-line C...\n",
      "Rank 2(7.3): Median Split Trees: A Fast Lookup Technique for Fr...\n",
      "Rank 3(7.0): Execution Time Requirements for Encipherment Progr...\n",
      "Rank 4(7.0): Storage and Search Properties of a Tree-Organized ...\n"
     ]
    }
   ],
   "source": [
    "test_tfidf_1 = tfidf_search(\"computer word search\", index_set=1)[:5]\n",
    "print(f\"TFIDF Results:\")\n",
    "print_results(test_tfidf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "00056-3513c3fe-3e9f-4b8c-aa0f-3f4a6d19816c",
    "deepnote_cell_height": 280.75,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 1,
    "execution_start": 1645186539634,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0edb37a5ae807a2de85d578c87ccb78",
     "grade": true,
     "grade_id": "cell-d908c80a3155354b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "9b7bb168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 docs for index1 with BOW search: ('1771', '1936', '1543', '2535', '678')\n",
      "top-5 docs for index2 with BOW search: ('1525', '1936', '1844', '1700', '1366')\n",
      "top-5 docs for index1 with TF-IDF search: ('1936', '2054', '3041', '2620', '944')\n",
      "top-5 docs for index2 with TF-IDF search: ('1700', '1936', '1235', '2018', '849')\n"
     ]
    }
   ],
   "source": [
    "print(\"top-5 docs for index1 with BOW search:\", list(zip(*test_bow_1[:5]))[0])\n",
    "print(\"top-5 docs for index2 with BOW search:\", list(zip(*test_bow_2[:5]))[0])\n",
    "print(\"top-5 docs for index1 with TF-IDF search:\", list(zip(*test_tfidf_1[:5]))[0])\n",
    "print(\"top-5 docs for index2 with TF-IDF search:\", list(zip(*test_tfidf_2[:5]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00057-685f4747-06a6-4177-91cd-2efd41bed6dc",
    "deepnote_cell_height": 235,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdffc83f0eaea937cf64a212e7e9af8d",
     "grade": false,
     "grade_id": "cell-f5d923459ba21733",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Section 3.3: Query Likelihood Model (35 points) <a class=\"anchor\" id=\"qlm\"></a>\n",
    "\n",
    "In this section, you will implement a simple query likelihood model.\n",
    "\n",
    "\n",
    "#### 3.3.1 Naive QL (15 points)\n",
    "\n",
    "First, let us implement a naive version of a QL model, assuming a multinomial unigram language model (with a uniform prior over the documents).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "00058-cda44e40-05f4-4632-a263-b4e4b00947bd",
    "deepnote_cell_height": 351,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 127,
    "execution_start": 1645186539642,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7ae2b7d818b428b4638c1c9206d2aca",
     "grade": false,
     "grade_id": "cell-98505778f7b68e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "41faad84"
   },
   "outputs": [],
   "source": [
    "#### Document length for normalization\n",
    "\n",
    "\n",
    "def doc_lengths(documents):\n",
    "    doc_lengths = {doc_id: len(doc) for (doc_id, doc) in documents}\n",
    "    return doc_lengths\n",
    "\n",
    "\n",
    "doc_lengths_1 = doc_lengths(doc_repr_1)\n",
    "doc_lengths_2 = doc_lengths(doc_repr_2)\n",
    "\n",
    "\n",
    "def get_doc_lengths(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {1: doc_lengths_1, 2: doc_lengths_2}[index_set]\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "00059-746be962-92e6-47b2-bf24-e3d86dedd92e",
    "deepnote_cell_height": 567,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186539698,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cedd08303a914243fefdb6b876977ca1",
     "grade": false,
     "grade_id": "cell-8bcf2b804d636c2e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "a861316b"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (15 points)\n",
    "def naive_ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using a naive QL model.\n",
    "    Note #1: You have to use the `get_index` (and get_doc_lengths) function\n",
    "        created in the previous cells\n",
    "    Input:\n",
    "        query - a (unprocessed) query\n",
    "        index_set - the index to use\n",
    "    Output: a list of (document_id, score), sorted in descending relevance\n",
    "        to the given query\n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    # YOUR CODE HERE\n",
    "    results = {}\n",
    "    \n",
    "    for token in processed_query:\n",
    "        # convert to dictionary for fast lookup\n",
    "        token_counts = dict(index[token])\n",
    "        for doc_id in doc_lengths.keys():\n",
    "            if doc_id not in token_counts:\n",
    "                # because token count is 0\n",
    "                p_qD = 0\n",
    "            else:\n",
    "                # otherwise we're able to get the tok count and proceed with computation\n",
    "                token_count = token_counts[doc_id]\n",
    "                p_qD = token_count / doc_lengths[doc_id]\n",
    "            if doc_id not in results:\n",
    "                results[doc_id] = p_qD\n",
    "            else:\n",
    "                results[doc_id] *= p_qD\n",
    "    results = sorted(list(results.items()), key=lambda x: x[1], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "00060-7b8590ee-afcd-44ee-b551-3938924f8c30",
    "deepnote_cell_height": 285.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 0,
    "execution_start": 1645186539699,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b550d15bdad28354c336020a00c33d56",
     "grade": true,
     "grade_id": "cell-5a83ac12ecde8578",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "54190022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive QL Results:\n",
      "Rank 0(0.2): A Report Writer For COBOL...\n",
      "Rank 1(0.2): A CRT Report Generating System...\n",
      "Rank 2(0.17): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(0.17): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(0.14): ALGOL Sub-Committee Report - Extensions...\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "test_naiveql = naive_ql_search(\"report\", index_set=1)[:5]\n",
    "print(f\"Naive QL Results:\")\n",
    "print_results(test_naiveql)\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "00061-82ac6743-087a-40be-8e13-c83e9cc51509",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 30,
    "execution_start": 1645186539742,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "799df1d81c63fe90edbb6c218fc707fb",
     "grade": true,
     "grade_id": "cell-80f4bf2137f997bb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "00062-17e1b311-2247-4c85-9402-b644f1f66b12",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244764,
    "execution_start": 1645186539743,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "875a4a517d27e20625d41783cebec118",
     "grade": true,
     "grade_id": "cell-5ce2993458a8ce51",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": "00063-21abc448-96e9-40fc-82a7-478035610266",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244759,
    "execution_start": 1645186539750,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5c4e1c3852e71a46f32825b122f1b71",
     "grade": true,
     "grade_id": "cell-7753bdb54e292f3d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": "00064-47b977bf-c1c9-4960-8ecc-f146211b3336",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244752,
    "execution_start": 1645186539809,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4d4332d4356e89ce0240f6b80e1899a",
     "grade": true,
     "grade_id": "cell-54e476e2f96e64bb",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00065-1a6eeeea-9611-4e55-bf52-1adfe9cd668f",
    "deepnote_cell_height": 156.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d739dc91a22bd48897f603885f95a74",
     "grade": false,
     "grade_id": "cell-5414dfd69dab8b94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "#### 3.3.2 QL (20 points)\n",
    "Now, let's implement a QL model that handles the issues with the naive version. In particular, you will implement a QL model with Jelinek-Mercer Smoothing. That means an interpolated score is computed per word - one term is the same as the previous naive version, and the second term comes from a unigram language model. In addition, you should accumulate the scores by summing the **log** (smoothed) probability which leads to better numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": "00066-3fb59861-7bc5-497f-951b-c221eb02258c",
    "deepnote_cell_height": 1125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 11244761,
    "execution_start": 1645186539809,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8c6abf937ad333e628f1db891f2e29e",
     "grade": false,
     "grade_id": "cell-bb1f506409771257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "2f2ddee4"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (20 points)\n",
    "\n",
    "\n",
    "def ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using a QL model\n",
    "    with Jelinek-Mercer Smoothing (set smoothing=0.1).\n",
    "\n",
    "    Note #1: You have to use the `get_index` (and get_doc_lengths) function\n",
    "        created in the previous cells\n",
    "    Note #2: You might have to create some variables beforehand and\n",
    "        use them in this function\n",
    "\n",
    "    Input:\n",
    "        query - a (unprocessed) query\n",
    "        index_set - the index to use\n",
    "    Output: a list of (document_id, score), sorted in descending relevance\n",
    "        to the given query\n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # total number of words in the collection\n",
    "    C = sum(list(doc_lengths.values()))\n",
    "    # \"(set smoothing=0.1)\"\n",
    "    lambd = 0.1\n",
    "    results = {}\n",
    "    for token in processed_query:\n",
    "        # skip tokens not in docs\n",
    "        if not index[token]:\n",
    "            continue\n",
    "        # mapping from to doc_id to count for this token\n",
    "        doc_to_count = {}\n",
    "        # total count of token across the collection\n",
    "        total_tok_count = 0\n",
    "        for doc, tok_count in index[token]:\n",
    "            doc_to_count[doc] = tok_count\n",
    "            total_tok_count += tok_count\n",
    "\n",
    "        # check each document in our collection, to catch token counts of 0\n",
    "        for document_id, doc_length in doc_lengths.items():\n",
    "            if document_id in doc_to_count:\n",
    "                token_count = doc_to_count[document_id]\n",
    "            else:\n",
    "                token_count = 0\n",
    "            # page 257 of Croft et al.\n",
    "            p_qD = np.log(\n",
    "                (1 - lambd) * token_count / doc_lengths[document_id]\n",
    "                + lambd * total_tok_count / C\n",
    "            )\n",
    "            if document_id not in results:\n",
    "                results[document_id] = p_qD\n",
    "            else:\n",
    "                results[document_id] += p_qD\n",
    "\n",
    "    # convert documents to list and sort descending\n",
    "    results = sorted(list(results.items()), key=lambda x: x[1], reverse=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": "00067-490d8cb9-33a4-47fc-9c15-ad1b4c455132",
    "deepnote_cell_height": 422.0625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 121,
    "execution_start": 1645186539852,
    "is_code_hidden": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b12a7f3355193a257fd9f5f69a66562",
     "grade": true,
     "grade_id": "cell-850e9d6369bcec32",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "4e5f7dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(-1.7): A Report Writer For COBOL...\n",
      "Rank 1(-1.7): A CRT Report Generating System...\n",
      "Rank 2(-1.9): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(-1.9): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(-2.1): ALGOL Sub-Committee Report - Extensions...\n",
      "\n",
      "Rank 0(-1.7e+01): A Report Writer For COBOL...\n",
      "Rank 1(-1.7e+01): A CRT Report Generating System...\n",
      "Rank 2(-1.9e+01): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(-1.9e+01): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(-2.1e+01): ALGOL Sub-Committee Report - Extensions...\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "test_ql_results = ql_search(\"report\", index_set=1)[:5]\n",
    "print_results(test_ql_results)\n",
    "print()\n",
    "test_ql_results_long = ql_search(\"report \" * 10, index_set=1)[:5]\n",
    "print_results(test_ql_results_long)\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": "00068-095393c5-8e5b-4aef-9720-cfe9fae3b7c5",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244810,
    "execution_start": 1645186540003,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e40be645140389c115849856145f5b59",
     "grade": true,
     "grade_id": "cell-958cdcf6fd6899b7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cell_id": "00069-4cd600e6-d694-4c40-ab70-28deb209cf19",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244823,
    "execution_start": 1645186540042,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41d4aff001df17e7963ba79b45810b30",
     "grade": true,
     "grade_id": "cell-384dc23a0c251f6e",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_id": "00070-952cb008-6963-4ca8-89f4-302b5a3ff74f",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244838,
    "execution_start": 1645186540086,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "893e8c5a073abc8ebb763d267b91bc02",
     "grade": true,
     "grade_id": "cell-7218966cba5097cc",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_id": "00071-6752fe8b-7f1e-4fbc-a1c8-8a5f9876a4c4",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244853,
    "execution_start": 1645186540123,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99cb6f8b1f5830aaed8f06712ff846e",
     "grade": true,
     "grade_id": "cell-481ab073259ae53f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00072-927d2e01-1b15-4854-a903-2a2472ecb63b",
    "deepnote_cell_height": 127,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c02f14705d679579b1aa9f78f54779d5",
     "grade": false,
     "grade_id": "cell-f44088bfdac1dc90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Section 3.4: BM25 (20 points) <a class=\"anchor\" id=\"bm25\"></a>\n",
    "\n",
    "In this section, we will implement the BM25 scoring function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_id": "00073-22161fa2-0c00-4c01-af51-4968d6b78880",
    "deepnote_cell_height": 801,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 11244861,
    "execution_start": 1645186540177,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e57efe06ea92af1c83784a42eb3d86e0",
     "grade": false,
     "grade_id": "cell-15640fc9b5d00a3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "991aa048"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (20 points)\n",
    "def bm25_search(query, index_set):\n",
    "    \"\"\"\n",
    "    Perform a search over all documents with the given query using BM25.\n",
    "    Use k_1 = 1.5 and b = 0.75\n",
    "    Note #1: You have to use the `get_index` (and `get_doc_lengths`) function\n",
    "    created in the previous cells\n",
    "    Note #2: You might have to create some variables beforehand\n",
    "    and use them in this function\n",
    "    Input:\n",
    "        query - a (unprocessed) query\n",
    "        index_set - the index to use\n",
    "    Output: a list of (document_id, score), sorted in descending\n",
    "        relevance to the given query\n",
    "    \"\"\"\n",
    "\n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # hard coded values\n",
    "    k_1 = 1.5\n",
    "    b = 0.75\n",
    "    # initialize our result\n",
    "    documents = defaultdict(float)\n",
    "    # average doc length and number of docs\n",
    "    ave_dl = np.mean([value for _key, value in doc_lengths.items()])\n",
    "    N = len(docs)\n",
    "    for token in processed_query:\n",
    "        for document_id, token_count in index[token]:\n",
    "            idf = np.log(N / df[token])\n",
    "            second_term = (token_count * (k_1 + 1)) / (\n",
    "                token_count + k_1 * (1 - b + b * (doc_lengths[document_id] / ave_dl))\n",
    "            )\n",
    "            documents[document_id] += idf * second_term\n",
    "    # convert documents to list and sort descending\n",
    "    documents = sorted(list(documents.items()), key=lambda x: x[1], reverse=True)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cell_id": "00074-99930c5d-a5f8-4ead-b1d4-1bb2ada8b11b",
    "deepnote_cell_height": 246.9375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244850,
    "execution_start": 1645186540178,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4be9de5d4e94637960d83725422bea6c",
     "grade": true,
     "grade_id": "cell-d10536bca72c74b1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "e0c314c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(6.7): A Report Writer For COBOL...\n",
      "Rank 1(6.7): A CRT Report Generating System...\n",
      "Rank 2(6.6): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(6.6): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(6.5): ALGOL Sub-Committee Report - Extensions...\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "test_bm25_results = bm25_search(\"report\", index_set=1)[:5]\n",
    "print_results(test_bm25_results)\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_id": "00075-42c49004-74c6-4354-a713-ab682c96123e",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244838,
    "execution_start": 1645186540222,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b550d6a46ae4f8ede88788799ac2b9",
     "grade": true,
     "grade_id": "cell-60f6ec5052712d79",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cell_id": "00076-dda1edfe-5234-4b37-8700-30b331b5b71e",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244835,
    "execution_start": 1645186540223,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3da2ec16bfe781916e71755d65aa2983",
     "grade": true,
     "grade_id": "cell-5d17524043a5abcc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "cell_id": "00077-eb67834d-52f9-4385-a9cd-0ad481099542",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244835,
    "execution_start": 1645186540265,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7b563d54fa84c20909c0ae107010541",
     "grade": true,
     "grade_id": "cell-ff8e704eda1184e3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cell_id": "00078-4c9ec504-f3a1-44c6-b797-e96bf38a6d46",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244839,
    "execution_start": 1645186540266,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b013f90974b396630a8831d6f1d7e5f7",
     "grade": true,
     "grade_id": "cell-a52310500a2543cb",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00079-f0652d37-3014-4fc5-a239-c6d5371c8167",
    "deepnote_cell_height": 127,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fcf67cb7d5e8b26cb9bf1f0aa42c847",
     "grade": false,
     "grade_id": "cell-8b2b412c81d62f2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 3.5. Test Your Functions\n",
    "\n",
    "The widget below allows you to play with the search functions you've written so far. Use this to test your search functions and ensure that they work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cell_id": "00080-8469bb45-c42f-461c-b1dd-6fcd1ef23d8b",
    "deepnote_cell_height": 693,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11244825,
    "execution_start": 1645186540266,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfeb204b390acc0794dbdcac92b0cf2c",
     "grade": false,
     "grade_id": "cell-c9c2bb76354e8d97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "ff5eb03a"
   },
   "outputs": [],
   "source": [
    "#### Highlighter function\n",
    "# class for results\n",
    "ResultRow = namedtuple(\"ResultRow\", [\"doc_id\", \"snippet\", \"score\"])\n",
    "# doc_id -> doc\n",
    "docs_by_id = dict((d[0], d[1]) for d in docs)\n",
    "\n",
    "\n",
    "def highlight_text(document, query, tol=17):\n",
    "    import re\n",
    "\n",
    "    tokens = tokenize(query)\n",
    "    regex = \"|\".join(f\"(\\\\b{t}\\\\b)\" for t in tokens)\n",
    "    regex = re.compile(regex, flags=re.IGNORECASE)\n",
    "    output = \"\"\n",
    "    i = 0\n",
    "    for m in regex.finditer(document):\n",
    "        start_idx = max(0, m.start() - tol)\n",
    "        end_idx = min(len(document), m.end() + tol)\n",
    "        output += \"\".join(\n",
    "            [\n",
    "                \"...\",\n",
    "                document[start_idx : m.start()],\n",
    "                \"<strong>\",\n",
    "                document[m.start() : m.end()],\n",
    "                \"</strong>\",\n",
    "                document[m.end() : end_idx],\n",
    "                \"...\",\n",
    "            ]\n",
    "        )\n",
    "    return output.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def make_results(query, search_fn, index_set):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query, index_set):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_id": "00081-0f79ea92-6b27-476d-838a-7353712fe308",
    "deepnote_cell_height": 753,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11244922,
    "execution_start": 1645186540312,
    "source_hash": "52b13204"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b6bc238dd647a8a112bad3b0e44445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Set this to the function you want to test!\n",
    "SEARCH_FN_NAME = \"bm25\"\n",
    "# this function should take in a query (string)\n",
    "# and return a sorted list of (doc_id, score)\n",
    "# with the most relevant document in the first position\n",
    "search_fn_dict = {\n",
    "    \"bow\": bow_search,\n",
    "    \"tfidf\": tfidf_search,\n",
    "    \"naive_ql\": naive_ql_search,\n",
    "    \"ql\": ql_search,\n",
    "    \"bm25\": bm25_search,\n",
    "}\n",
    "\n",
    "search_fn = search_fn_dict[SEARCH_FN_NAME]\n",
    "index_set = 1\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "def handle_submit(sender):\n",
    "    print(f\"Searching for: '{sender.value}'\")\n",
    "\n",
    "    results = make_results(sender.value, search_fn, index_set)\n",
    "\n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "\n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00082-cd38c091-8362-48a6-b6f6-e2c167049828",
    "deepnote_cell_height": 331.140625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "019b1ff878dc6339dd068e2d48d19904",
     "grade": false,
     "grade_id": "cell-8d46fe8e4f3d8cdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 4: Evaluation (40 points) <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "In order to analyze the effectiveness of retrieval algorithms, we first have to learn how to evaluate such a system. In particular, we will work with offline evaluation metrics. These metrics are computed on a dataset with known relevance judgements.\n",
    "\n",
    "Implement the following evaluation metrics.\n",
    "\n",
    "1. Precision (7 points)\n",
    "2. Recall (7 points)\n",
    "3. Mean Average Precision (13 points)\n",
    "4. Expected Reciprocal Rank (13 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00083-dfad5784-4ddc-451d-9394-08c63666f402",
    "deepnote_cell_height": 123.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e46f54c7f81d88bbc950b0fae14c4ca5",
     "grade": false,
     "grade_id": "cell-3419fd3bc663d7cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.1 Read relevance labels\n",
    "\n",
    "Let's take a look at the `qrels.text` file, which contains the ground truth relevance scores. The relevance labels for CACM are binary - either 0 or 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cell_id": "00084-1316ed27-3c82-43e0-9359-b9e3a9d64256",
    "deepnote_cell_height": 293.875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 380,
    "execution_start": 1645186540313,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c11025f5a222796f2882c73c1634799",
     "grade": false,
     "grade_id": "cell-6b738366059dde9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "4ba3f3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 1410  0 0\n",
      "01 1572  0 0\n",
      "01 1605  0 0\n",
      "01 2020  0 0\n",
      "01 2358  0 0\n",
      "02 2434  0 0\n",
      "02 2863  0 0\n",
      "02 3078  0 0\n",
      "03 1134  0 0\n",
      "03 1613  0 0\n"
     ]
    }
   ],
   "source": [
    "!head ./datasets/qrels.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00085-d6878bd5-2637-4397-a653-79961f1e8bde",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ce95245c1597183320d7254afde5c8e",
     "grade": false,
     "grade_id": "cell-10e16bff2753ffbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The first column is the query_id and the second column is the document_id. We can safely ignore the 3rd and 4th columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_id": "00086-5ab2237b-8b49-4a73-9063-9fc776502761",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186540745,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000c6d59dce08dba0ba1e8d691dbbc2e",
     "grade": false,
     "grade_id": "cell-ee5253a4ef602fce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "c9cbc0ff"
   },
   "outputs": [],
   "source": [
    "# https://piazza.com/class/kyiksrdfk0b6te?cid=40_f1\n",
    "def read_qrels(root_folder=\"./datasets/\"):\n",
    "    \"\"\"\n",
    "    Reads the qrels.text file.\n",
    "    Output: A dictionary: query_id -> [list of relevant documents]\n",
    "    \"\"\"\n",
    "    with open(os.path.join(root_folder, \"qrels.text\")) as reader:\n",
    "        lines = reader.readlines()\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    relevant_docs = defaultdict(set)\n",
    "    for line in lines:\n",
    "        query_id, doc_id, _, _ = line.split()\n",
    "        relevant_docs[str(int(query_id))].add(doc_id)\n",
    "    return relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_id": "00087-b2ca4d34-5c5f-4392-85ed-a178aeee2e30",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 59,
    "execution_start": 1645186540746,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d60caeba85c2a97d2211184a5ae91fd1",
     "grade": false,
     "grade_id": "cell-72215605fbe24f65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "23ca292a"
   },
   "outputs": [],
   "source": [
    "#### Function check\n",
    "qrels = read_qrels()\n",
    "\n",
    "assert len(qrels) == 52, \"There should be 52 queries with relevance judgements\"\n",
    "assert (\n",
    "    sum(len(j) for j in qrels.values()) == 796\n",
    "), \"There should be a total of 796 Relevance Judgements\"\n",
    "\n",
    "assert np.min(np.array([len(j) for j in qrels.values()])) == 1\n",
    "assert np.max(np.array([len(j) for j in qrels.values()])) == 51\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00088-14f1066c-7068-49a9-910c-c81e820e1a63",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c9e7428a52e291a2cdf92a379730d4c",
     "grade": false,
     "grade_id": "cell-176a6fb2939d0420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "**Note:** For a given query `query_id`, you can assume that documents *not* in `qrels[query_id]` are not relevant to `query_id`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00089-e42c5a24-37db-4b0f-9db5-56563253fb35",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26a818c7b4f7ad490e00b35ea0edd69",
     "grade": false,
     "grade_id": "cell-bd8341b72cdd89bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.2 Precision (7 points)\n",
    "Implement the `precision@k` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_id": "00090-10b53f18-7e8d-43d4-b563-680628c40545",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186540806,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43dea1979ebdec24ffcfeff71c670433",
     "grade": false,
     "grade_id": "cell-494bd0cce108ed67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "b26a2b3c"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (7 points)\n",
    "def precision_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Compute Precision@K\n",
    "    Input:\n",
    "        results: A sorted list of 2-tuples (document_id, score),\n",
    "                with the most relevant document in the first position\n",
    "        relevant_docs: A set of relevant documents.\n",
    "        k: the cut-off\n",
    "    Output: Precision@K\n",
    "    \"\"\"\n",
    "    if k > len(results):\n",
    "        k = len(results)\n",
    "    # YOUR CODE HERE\n",
    "    return np.mean([doc_id in relevant_docs for doc_id, _score in results[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cell_id": "00091-fa6b1685-64b1-424e-af93-8f763660db0f",
    "deepnote_cell_height": 296.5625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 320,
    "execution_start": 1645186540809,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9222e35582b1840ffb60fd02fb0b60c3",
     "grade": true,
     "grade_id": "cell-e7ff0d91c319ca64",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "1417a891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What articles exist which deal with TSS (Time Sharing System), an\n",
      "operating system for IBM computers?\n",
      "precision@10 = 0.2\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "qid = queries[0][0]\n",
    "qtext = queries[0][1]\n",
    "print(f\"query:{qtext}\")\n",
    "results = bm25_search(qtext, 2)\n",
    "precision = precision_k(results, qrels[qid], 10)\n",
    "print(f\"precision@10 = {precision}\")\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00092-573df961-c83e-4116-af98-2954707eb21e",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fd3b3998197c7097a40348500affb68",
     "grade": false,
     "grade_id": "cell-afd95f865bc7191e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.3 Recall (7 points)\n",
    "Implement the `recall@k` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cell_id": "00093-73affea1-1e53-4344-8a1f-55a1c3a18966",
    "deepnote_cell_height": 495,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 1,
    "execution_start": 1645186541031,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2020e5741ae03b3fe35817ed8f4ccaa",
     "grade": false,
     "grade_id": "cell-c323fc8c3f8a7cf8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "7a605edf"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (7 points)\n",
    "def recall_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Compute Recall@K\n",
    "    Input:\n",
    "        results: A sorted list of 2-tuples (document_id, score),\n",
    "            with the most relevant document in the first position\n",
    "        relevant_docs: A set of relevant documents.\n",
    "        k: the cut-off\n",
    "    Output: Recall@K\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    tp = 0.0\n",
    "    fn = 0.0\n",
    "    for i, (doc_id, _score) in enumerate(results, 1):\n",
    "        if doc_id in relevant_docs:\n",
    "            if i <= k:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    try:\n",
    "        return tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": "00094-bf429fa0-2840-4cae-bab1-cb99f0a3d3d3",
    "deepnote_cell_height": 258.375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 98,
    "execution_start": 1645186541033,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56b6e0b8522f8b2dffbfb3206b2efa84",
     "grade": true,
     "grade_id": "cell-b25172161aef165c",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "a5ebd603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: SETL, Very High Level Languages\n",
      "recall@10 = 0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "qid = queries[10][0]\n",
    "qtext = queries[10][1]\n",
    "print(f\"query:{qtext}\")\n",
    "results = bm25_search(qtext, 2)\n",
    "recall = recall_k(results, qrels[qid], 10)\n",
    "print(f\"recall@10 = {recall}\")\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00095-1445fa1d-3d88-4eb1-9592-5a6cba32701b",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3d3c7bd1cd977cd07ef5df7d3fbf159",
     "grade": false,
     "grade_id": "cell-77fd2e7a39a74739",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.4 Mean Average Precision (13 points)\n",
    "Implement the `map` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cell_id": "00096-6935fc09-3410-4008-ab25-df992be775e4",
    "deepnote_cell_height": 387,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 1,
    "execution_start": 1645186541058,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aae2c62f2ffd76f5b6c004e9519b9f14",
     "grade": false,
     "grade_id": "cell-e50925fa9093a30d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "9a3733da"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (12 points)\n",
    "def average_precision(results, relevant_docs):\n",
    "    \"\"\"\n",
    "    Compute Average Precision (for a single query - the results are\n",
    "    averaged across queries to get MAP in the next few cells)\n",
    "    Hint: You can use the recall_k and precision_k functions here!\n",
    "    Input:\n",
    "        results: A sorted list of 2-tuples (document_id, score), with the most\n",
    "                relevant document in the first position\n",
    "        relevant_docs: A set of relevant documents.\n",
    "    Output: Average Precision\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    relevances = np.array(\n",
    "        [doc_id in relevant_docs for doc_id, _score in results]\n",
    "    ).astype(np.float_)\n",
    "\n",
    "    last_relevance = np.argmax(relevances[::-1]) + 1\n",
    "    # dont need to check beyond last relevance\n",
    "    results = results[: -last_relevance + 1]\n",
    "    # can now get precisions\n",
    "    N = len(results)\n",
    "    precisions = np.array(\n",
    "        [precision_k(results, relevant_docs, n) for n in range(1, N + 1)]\n",
    "    )\n",
    "    relevances = relevances[: -last_relevance + 1]\n",
    "    ave_p = np.sum((precisions * relevances)) / len(relevant_docs)\n",
    "    return ave_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "cell_id": "00097-d194398d-53a0-4cd3-a940-4d78e7ce289a",
    "deepnote_cell_height": 278.5625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 1266,
    "execution_start": 1645186541145,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b00e147c2fa146fa59f179b7c9cab75",
     "grade": true,
     "grade_id": "cell-8a1f7ec98571e58b",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "501861e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: computational complexity, intractability, class-complete reductions,\n",
      "algorithms and efficiency\n",
      "MAP = 0.1724040411055945\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "qid = queries[20][0]\n",
    "qtext = queries[20][1]\n",
    "print(f\"query:{qtext}\")\n",
    "results = bm25_search(qtext, 2)\n",
    "mean_ap = average_precision(results, qrels[qid])\n",
    "print(f\"MAP = {mean_ap}\")\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00098-ff07922a-b997-4d0a-b0b2-16a258d55e09",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36f85f45ef52d9467ba9a717d6d99ff2",
     "grade": false,
     "grade_id": "cell-1da18f0fe6f6d7be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.5 Expected Reciprocal Rank (13 points)\n",
    "Implement the `err` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "cell_id": "00099-6f85eb2c-52dd-4893-9795-701a871bbb68",
    "deepnote_cell_height": 459,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 39,
    "execution_start": 1645186542452,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ac94db728e23ea1f5dc0d509473c6fb",
     "grade": false,
     "grade_id": "cell-64262889f9b267ea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "337046c"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (12 points)\n",
    "def err(results, relevant_docs):\n",
    "    \"\"\"\n",
    "    Compute the expected reciprocal rank.\n",
    "    Hint: https://dl.acm.org/doi/pdf/10.1145/1645953.1646033?download=true\n",
    "    Input:\n",
    "        results: A sorted list of 2-tuples (document_id, score), with the most\n",
    "            relevant document in the first position\n",
    "        relevant_docs: A set of relevant documents.\n",
    "    Output: ERR (float)\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    exp_rec_rank = 0\n",
    "    p = 1\n",
    "    for rank, (doc_id, score) in enumerate(results, 1):\n",
    "        grade = 1 if doc_id in relevant_docs else 0\n",
    "        relevance_prob = (2**grade - 1) / 2\n",
    "        exp_rec_rank += p * (relevance_prob / rank)\n",
    "        p *= 1 - relevance_prob\n",
    "    return exp_rec_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_id": "00100-d301d6c2-210d-4182-8817-b2c392d7d10e",
    "deepnote_cell_height": 359.3125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 223,
    "execution_start": 1645186542501,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7d201de0990b69d5f38704668665d87",
     "grade": true,
     "grade_id": "cell-071e3970ff1afae4",
     "locked": true,
     "points": 13,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "c244fd0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qPuery: I'd like to find articles describing the use of singular value decomposition\n",
      "in digital image processing.  Applications include finding approximations\n",
      "to the original image and restoring images that are subject to noise. An\n",
      "article on the subject is H.C. Andrews and C.L. Patterson \"Outer product\n",
      "expansions and their uses in digital image processing\", American Mathematical\n",
      "Monthly, vol. 82.\n",
      "ERR = 0.625\n"
     ]
    }
   ],
   "source": [
    "#### Function check\n",
    "qid = queries[30][0]\n",
    "qtext = queries[30][1]\n",
    "print(f\"qPuery:{qtext}\")\n",
    "results = bm25_search(qtext, 2)\n",
    "ERR = err(results, qrels[qid])\n",
    "print(f\"ERR = {ERR}\")\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00101-5c45197a-8f43-4e13-b24d-0ef1ad533eef",
    "deepnote_cell_height": 101.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bd94caf77cfa5f34675df758d91002d",
     "grade": false,
     "grade_id": "cell-43709a765f353946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### 4.6 Evaluate Search Functions\n",
    "\n",
    "Let's define some metrics@k using [partial functions](https://docs.python.org/3/library/functools.html#functools.partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "cell_id": "00102-442bc886-57e2-4c21-b7ad-b01e86ff2f2b",
    "deepnote_cell_height": 423,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 1,
    "execution_start": 1645186542781,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49ccc158e5fb7340ace55e90eeb9d62a",
     "grade": false,
     "grade_id": "cell-dab560e18e340da8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "984c969a"
   },
   "outputs": [],
   "source": [
    "#### metrics@k functions\n",
    "\n",
    "recall_at_1 = partial(recall_k, k=1)\n",
    "recall_at_5 = partial(recall_k, k=5)\n",
    "recall_at_10 = partial(recall_k, k=10)\n",
    "precision_at_1 = partial(precision_k, k=1)\n",
    "precision_at_5 = partial(precision_k, k=5)\n",
    "precision_at_10 = partial(precision_k, k=10)\n",
    "\n",
    "\n",
    "list_of_metrics = [\n",
    "    (\"ERR\", err),\n",
    "    (\"MAP\", average_precision),\n",
    "    (\"Recall@1\", recall_at_1),\n",
    "    (\"Recall@5\", recall_at_5),\n",
    "    (\"Recall@10\", recall_at_10),\n",
    "    (\"Precision@1\", precision_at_1),\n",
    "    (\"Precision@5\", precision_at_5),\n",
    "    (\"Precision@10\", precision_at_10),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00103-62e2b5c1-7f8b-4b73-8459-45dac6ed6b05",
    "deepnote_cell_height": 91,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb541002c03221b453b8936290020ea5",
     "grade": false,
     "grade_id": "cell-580a2bdc66d03b47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The following function evaluates a `search_fn` using the `metric_fn`. Note that the final number is averaged over all the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cell_id": "00104-cc282062-26b4-45c1-8dfa-9b8ca0fc9ed5",
    "deepnote_cell_height": 783,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1645186542825,
    "lines_to_next_cell": 2,
    "source_hash": "647a95c2"
   },
   "outputs": [],
   "source": [
    "#### Evaluate a search function\n",
    "\n",
    "list_of_search_fns = [\n",
    "    (\"BOW\", bow_search),\n",
    "    (\"TF-IDF\", tfidf_search),\n",
    "    (\"NaiveQL\", naive_ql_search),\n",
    "    (\"QL\", ql_search),\n",
    "    (\"BM25\", bm25_search),\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate_search_fn(search_fn, metric_fns, index_set=None):\n",
    "    # build a dict query_id -> query\n",
    "    queries_by_id = dict((q[0], q[1]) for q in queries)\n",
    "\n",
    "    metrics = {}\n",
    "    for metric, metric_fn in metric_fns:\n",
    "        metrics[metric] = np.zeros(len(qrels), dtype=np.float32)\n",
    "\n",
    "    # original version\n",
    "    for i, (query_id, relevant_docs) in enumerate(qrels.items()):\n",
    "        query = queries_by_id[query_id]\n",
    "        if index_set:\n",
    "            results = search_fn(query, index_set)\n",
    "        else:\n",
    "            results = search_fn(query)\n",
    "\n",
    "        for metric, metric_fn in metric_fns:\n",
    "            metrics[metric][i] = metric_fn(results, relevant_docs)\n",
    "\n",
    "    final_dict = {}\n",
    "    for metric, metric_vals in metrics.items():\n",
    "        final_dict[metric] = metric_vals.mean()\n",
    "\n",
    "    # fast version for debugging plot\n",
    "    # final_dict = {}\n",
    "    # for metric, metric_vals in metrics.items():\n",
    "    #     final_dict[metric] = metric_vals.mean() + 0.5\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00105-ba71254a-76a2-4a05-a0a0-148bcf0d753f",
    "deepnote_cell_height": 411.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ea67534f74a8f81e1f504794f641709",
     "grade": false,
     "grade_id": "cell-b156d83a0649cbb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 5: Analysis (30 points) <a class=\"anchor\" id=\"analysis\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "In the final section of Part1, we will compare the different term-based IR algorithms and different preprocessing configurations and analyze their advantages and disadvantages.\n",
    "\n",
    "### Section 5.1: Plot (20 points)\n",
    "\n",
    "First, gather the results. The results should consider the index set, the different search functions and different metrics. Plot the results in bar charts, per metric, with clear labels.\n",
    "\n",
    "**Rubric:**\n",
    "- Each Metric is plotted: 7 points\n",
    "- Each Method is plotted: 7 points\n",
    "- Clear titles, x label, y labels and legends (if applicable): 6 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cell_id": "00106-7e245371-4141-4e15-a142-53d98c682cb7",
    "deepnote_cell_height": 729,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     470.984375
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186542869,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e2588a925d13ddf588abe8311dc9cfc",
     "grade": true,
     "grade_id": "cell-46fda42a25863a04",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "1e18f015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index set 1:\n",
      "\tBOW\n",
      "{'ERR': 0.055224963,\n",
      " 'MAP': 0.03090453,\n",
      " 'Precision@1': 0.03846154,\n",
      " 'Precision@10': 0.028846154,\n",
      " 'Precision@5': 0.034615386,\n",
      " 'Recall@1': 0.0030982906,\n",
      " 'Recall@10': 0.046087656,\n",
      " 'Recall@5': 0.037126765}\n",
      "\tTF-IDF\n",
      "{'ERR': 0.30517504,\n",
      " 'MAP': 0.17810398,\n",
      " 'Precision@1': 0.3846154,\n",
      " 'Precision@10': 0.17500001,\n",
      " 'Precision@5': 0.21153846,\n",
      " 'Recall@1': 0.07476607,\n",
      " 'Recall@10': 0.22000195,\n",
      " 'Recall@5': 0.1473746}\n",
      "\tNaiveQL\n",
      "{'ERR': 0.02187399,\n",
      " 'MAP': 0.007967688,\n",
      " 'Precision@1': 0.03846154,\n",
      " 'Precision@10': 0.0076923077,\n",
      " 'Precision@5': 0.015384615,\n",
      " 'Recall@1': 0.0037774725,\n",
      " 'Recall@10': 0.008585164,\n",
      " 'Recall@5': 0.008585164}\n",
      "\tQL\n",
      "{'ERR': 0.30951288,\n",
      " 'MAP': 0.16616207,\n",
      " 'Precision@1': 0.34615386,\n",
      " 'Precision@10': 0.19423078,\n",
      " 'Precision@5': 0.25384614,\n",
      " 'Recall@1': 0.046651527,\n",
      " 'Recall@10': 0.21684042,\n",
      " 'Recall@5': 0.17031717}\n",
      "\tBM25\n",
      "{'ERR': 0.37286478,\n",
      " 'MAP': 0.22088145,\n",
      " 'Precision@1': 0.44230768,\n",
      " 'Precision@10': 0.24038464,\n",
      " 'Precision@5': 0.2846154,\n",
      " 'Recall@1': 0.066907376,\n",
      " 'Recall@10': 0.30646548,\n",
      " 'Recall@5': 0.20312355}\n",
      "\n",
      "index set 2:\n",
      "\tBOW\n",
      "{'ERR': 0.11996831,\n",
      " 'MAP': 0.0657566,\n",
      " 'Precision@1': 0.07692308,\n",
      " 'Precision@10': 0.07307692,\n",
      " 'Precision@5': 0.080769226,\n",
      " 'Recall@1': 0.010193701,\n",
      " 'Recall@10': 0.08793031,\n",
      " 'Recall@5': 0.048788056}\n",
      "\tTF-IDF\n",
      "{'ERR': 0.4148428,\n",
      " 'MAP': 0.25480694,\n",
      " 'Precision@1': 0.53846157,\n",
      " 'Precision@10': 0.25,\n",
      " 'Precision@5': 0.33846155,\n",
      " 'Recall@1': 0.10014636,\n",
      " 'Recall@10': 0.29629084,\n",
      " 'Recall@5': 0.23532662}\n",
      "\tNaiveQL\n",
      "{'ERR': 0.06400872,\n",
      " 'MAP': 0.019428182,\n",
      " 'Precision@1': 0.115384616,\n",
      " 'Precision@10': 0.025000002,\n",
      " 'Precision@5': 0.042307694,\n",
      " 'Recall@1': 0.009656762,\n",
      " 'Recall@10': 0.022477273,\n",
      " 'Recall@5': 0.01766958}\n",
      "\tQL\n",
      "{'ERR': 0.40624025,\n",
      " 'MAP': 0.24890317,\n",
      " 'Precision@1': 0.5192308,\n",
      " 'Precision@10': 0.29807693,\n",
      " 'Precision@5': 0.3692308,\n",
      " 'Recall@1': 0.07068591,\n",
      " 'Recall@10': 0.3002048,\n",
      " 'Recall@5': 0.21136688}\n",
      "\tBM25\n",
      "{'ERR': 0.426171,\n",
      " 'MAP': 0.3003765,\n",
      " 'Precision@1': 0.5192308,\n",
      " 'Precision@10': 0.31923077,\n",
      " 'Precision@5': 0.40384614,\n",
      " 'Recall@1': 0.110182874,\n",
      " 'Recall@10': 0.34614927,\n",
      " 'Recall@5': 0.25962994}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# YOUR CODE HERE\n",
    "# takes roughly 5 mins to run\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# need this to make side by side bars\n",
    "N = len(list_of_search_fns)\n",
    "method_loc = np.arange(N)\n",
    "bar_width = 0.25\n",
    "\n",
    "for j, (index_set) in enumerate([1, 2]):\n",
    "    print(f\"\\nindex set {index_set}:\")\n",
    "    results = {}\n",
    "\n",
    "    for search_alg, search_fn in list_of_search_fns:\n",
    "        results[search_alg] = evaluate_search_fn(\n",
    "            search_fn, list_of_metrics, index_set=index_set\n",
    "        )\n",
    "        print(f\"\\t{search_alg}\")\n",
    "        pprint(results[search_alg])\n",
    "\n",
    "    for i, (metric_name, _metric_fn) in enumerate(list_of_metrics):\n",
    "        metric_results = {k: v[metric_name] for k, v in results.items()}\n",
    "        labels = list(metric_results.keys())\n",
    "        values = [metric_results[label] for label in labels]\n",
    "\n",
    "        axes[i].grid(True, which=\"major\", axis=\"y\", alpha=0.35)\n",
    "        if i % 4 == 0:\n",
    "            axes[i].set_ylabel(\"Average Metric Value\")\n",
    "        if j == 0:\n",
    "            axes[i].bar(method_loc, values, bar_width, label=f\"index set {index_set}\")\n",
    "        else:\n",
    "            axes[i].bar(\n",
    "                method_loc + bar_width,\n",
    "                values,\n",
    "                bar_width,\n",
    "                label=f\"index set {index_set}\",\n",
    "            )\n",
    "            axes[i].set_xticks(method_loc + bar_width / 2)\n",
    "            axes[i].set_xticklabels(labels)\n",
    "            axes[i].set_title(metric_name)\n",
    "            if i == 7:\n",
    "                axes[i].legend()\n",
    "\n",
    "fig.suptitle(\"Comparison of different term-based IR algorithms across various Metrics\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00107-1573dd7e-069e-42e6-9991-2e09c5ca522c",
    "deepnote_cell_height": 146.140625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e88c444a0acf4e398c65e289169b75f7",
     "grade": false,
     "grade_id": "cell-8aabe3bcf265deb0",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "---\n",
    "### Section 5.2: Summary (10 points)\n",
    "Write a summary of what you observe in the results.\n",
    "Your summary should compare results across the 2 indices and the methods being used. State what you expected to see in the results, followed by either supporting evidence *or* justify why the results did not support your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00108-6173a881-f376-4ab8-afa5-feefc85830a5",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "1. Regardless of the algorithm used results are universally better across all\n",
    "   the metrics when using preprocessing - in particular stemming and stop-word\n",
    "   removal. This is in line with expectations based on large body of existing\n",
    "   literature in the field of Information retrieval.\n",
    "2. BOW performs much worse than expected. Intuitively while not a great method\n",
    "   word count for each token in the query should indicate relative importance of\n",
    "   terms in a document. We demonstrate empirically, however, that token count\n",
    "   alone is a very poor predictor of a document's relevance to a query.\n",
    "3. The NaiveQL model does not work because of the naive unigram language model\n",
    "   assumption - it's unlikely that any single document would contain all query\n",
    "   terms and therefore the probability for most documents given a search query\n",
    "   will be zero resulting in a random subset of documents being returned for\n",
    "   each query.\n",
    "4. The QL model solves the 0 probability issues of the nave model and in fact\n",
    "   comes close to being the best performing model which confirms that a\n",
    "   probabilistic approach based on likelihood works well.\n",
    "5. TODO explain why BM25 performs best or is close to being the best for all\n",
    "   metrics.\n",
    "6. TODO maybe finally we can compare TF-IDF, QL, BM25 across the different\n",
    "   metrics and highlight which ones are better given different scenarios. Also\n",
    "   which ones are better when we're not using preprocessing.\n",
    "\n",
    "## Notes Giulio\n",
    "\n",
    "- \"This is in line with expectations based on large body of existing literature\n",
    "  in the field of Information retrieval.\"\n",
    "  - i think we should also try to justify it in our words, for e.g. stemming\n",
    "    collapses index size, or stop-word removal allows models to \"focus\" on more\n",
    "    relevant words, or something else.\n",
    "- I think in our discussion we should also speak about what methods do better in\n",
    "  precision or in recall at different k's, as this is relevant to the type of\n",
    "  information retrieval one is after -- remember we had some discussion about\n",
    "  this in one of the lectures so I imagine they're expecting some discussion\n",
    "  about this here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00109-6235ead6-3d31-4a02-b36d-704dfc8e6efb",
    "deepnote_cell_height": 679.140625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3eb77be74eecca205fc7b47316d1627",
     "grade": false,
     "grade_id": "cell-bb60dd5c092d0f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "---\n",
    "# Part 2: Semantic-based Matching (85 points) <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "We will now experiment with methods that go beyond lexical methods like TF-IDF, which operate at the word level and are high dimensional and sparse, and look at methods which constructs low dimensional dense representations of queries and documents.\n",
    "\n",
    "Since these low-dimensional methods have a higher time complexity, they are typically used in conjunction with methods like BM-25. That is, instead of searching through potentially million documents to find matches using low dimensional vectors, a list of K documents are retrieved using BM25, and then **re-ranked** using the other method. This is the method that is going to be applied in the following exercises.\n",
    "\n",
    "LSI/LDA takes documents that are similar on a semantic level - for instance, if they are describing the same topic - and projects them into nearby vectors, despite having low lexical overlap.\n",
    "\n",
    "In this assignment, you will use `gensim` to create LSI/LDA models and use them in re-ranking.\n",
    "\n",
    "**Note**: The following exercises only uses `doc_repr_2` and `config_2`\n",
    "\n",
    "Table of contents:\n",
    "- [Section 6: LSI](#lsi) (15 points)\n",
    "- [Section 7: LDA](#lda) (10 points)\n",
    "- [Section 8: Word2Vec/Doc2Vec](#2vec) (20 points)\n",
    "- [Section 8: Re-ranking](#reranking) (10 points)\n",
    "- [Section 9: Re-ranking Evaluation](#reranking_eval) (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00110-5bcb1bc8-cec9-41c8-af84-5814c41bcace",
    "deepnote_cell_height": 204.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7c7b2cab82f576ed0acf836ca57171c",
     "grade": false,
     "grade_id": "cell-6b2c81e7a8abd180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 6: Latent Semantic Indexing (LSI) (15 points) <a class=\"anchor\" id=\"lsi\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "LSI is one of the methods to embed the queries and documents into vectors. It is based on a method similar to Principal Component Analysis (PCA) for obtaining a dense concept matrix out of the sparse term-document matrix.\n",
    "\n",
    "See [wikipedia](https://en.wikipedia.org/wiki/Latent_semantic_analysis), particularly [#Mathematics_of_LSI](https://en.wikipedia.org/wiki/Latent_semantic_analysis#Mathematics_of_LSI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "cell_id": "00111-09fa8f16-3577-43a0-902e-8a9dffdf4d2a",
    "deepnote_cell_height": 189,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 735,
    "execution_start": 1645186542920,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c17ee75319cb517e2bf48ec3d9efc329",
     "grade": false,
     "grade_id": "cell-59913daee47f680d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "a97e055a"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import downloader as g_downloader\n",
    "\n",
    "# gensim uses logging, so set it up\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00112-b7a2dfe3-d382-44dd-a7a6-e2f4a6feee5c",
    "deepnote_cell_height": 235.875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fce140c546759b54a9fc060901ae77c",
     "grade": false,
     "grade_id": "cell-3644faff4976598a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### Section 6.1: Cosine Similarity (5 points)<a class=\"anchor\" id=\"cosing_sim\"></a>\n",
    "Before we begin, let us first define our method of similarity for the LSI model, the cosine similarity:\n",
    "\n",
    "$$\\text{similarity} = \\cos(\\theta) = {\\mathbf{A} \\cdot \\mathbf{B} \\over \\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} = \\frac{ \\sum\\limits_{i=1}^{n}{A_i  B_i} }{ \\sqrt{\\sum\\limits_{i=1}^{n}{A_i^2}}  \\sqrt{\\sum\\limits_{i=1}^{n}{B_i^2}} }$$\n",
    "\n",
    "Since we are using gensim, the types of vectors returned by their classes are of the form defined below (they are not just simple vectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cell_id": "00113-b48d2608-3784-4f64-9344-fe76553f9aaf",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 16,
    "execution_start": 1645186543665,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e340e1a1d546f430c018fd0760e707a",
     "grade": false,
     "grade_id": "cell-3995a50f951314d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "214da9c9"
   },
   "outputs": [],
   "source": [
    "# 1, 2, 3 are either latent dimensions (LSI), or topics (LDA)\n",
    "# The second value in each tuple is a number (LSI) or a probability (LDA)\n",
    "example_vec_1 = [(1, 0.2), (2, 0.3), (3, 0.4)]\n",
    "example_vec_2 = [(1, 0.2), (2, 0.7), (3, 0.4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00114-5b3ead96-66da-40ac-9080-3669fc2631f3",
    "deepnote_cell_height": 75.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20832fd4f579f49ae204b0efee02edd1",
     "grade": false,
     "grade_id": "cell-5e54d581858dc8f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "**Implementation (2+3 points):**\n",
    "Now, implement the `dot product` operation on these types of vectors and using this operator, implement the `cosine similarity` (don't forget: two functions to implement!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cell_id": "00115-d8dc29b5-3912-471e-90a3-6a9db763c917",
    "deepnote_cell_height": 531,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 10,
    "execution_start": 1645186543706,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06a712ee75fc213a21c5f0067fd8fe28",
     "grade": false,
     "grade_id": "cell-0e8189f5f93de33f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "f02e6495"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (2 points)\n",
    "def dot(vec_1, vec_2):\n",
    "    \"\"\"\n",
    "    vec_1 and vec_2 are of the form: [(int, float), (int, float), ...]\n",
    "    Return the dot product of two such vectors, computed only on the floats\n",
    "    You can assume that the lengths of the vectors are the same, and the dimensions are aligned\n",
    "        i.e you won't get: vec_1 = [(1, 0.2)] ; vec_2 = [(2, 0.3)]\n",
    "                            (dimensions are unaligned and lengths are different)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return np.dot([x[1] for x in vec_1], [y[1] for y in vec_2])\n",
    "\n",
    "\n",
    "# TODO: Implement this! (3 points)\n",
    "def cosine_sim(vec_1, vec_2):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # check for empty or 0-vectored vectors\n",
    "    if np.all([el == 0 for dim, el in vec_1]) or np.all([el == 0 for dim, el in vec_2]):\n",
    "        return 0\n",
    "    \n",
    "    # # Adding a custom function to compute the modulus\n",
    "    def mod(\n",
    "        vec,\n",
    "    ):\n",
    "        # Note: This still assumes that the vector is in the form :\n",
    "        # [(int, float), (int, float), ...]\n",
    "        return np.sqrt(sum(x[1] ** 2 for x in vec))\n",
    "    \n",
    "    # actually compute similarity\n",
    "    return dot(vec_1, vec_2) / (mod(vec_1) * mod(vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_id": "00116-d4733e51-dfd0-4e9c-9240-9382dd06a589",
    "deepnote_cell_height": 224.5625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11246808,
    "execution_start": 1645186543759,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d22a4a7325ba7815a808390388f534a1",
     "grade": true,
     "grade_id": "cell-b25d04ed6b79fd35",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "f54a94bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors: ([(1, 0.2), (2, 0.3), (3, 0.4)], [(1, 0.2), (2, 0.7), (3, 0.4)])\n",
      "dot product = 0.41000000000000003\n",
      "cosine similarity = 0.9165587597202866\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "print(f\"vectors: {(example_vec_1,example_vec_2)}\")\n",
    "print(f\"dot product = {dot(example_vec_1,example_vec_2)}\")\n",
    "print(f\"cosine similarity = {cosine_sim(example_vec_1,example_vec_2)}\")\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cell_id": "00117-1b58cb35-2d08-4e28-8f2b-6de011617cf4",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11246825,
    "execution_start": 1645186543833,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0744131724ce76b1b3f163b4bae5f700",
     "grade": true,
     "grade_id": "cell-ae3c4466866ace77",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00118-a369a32d-5d88-4db7-b799-15d230e97a18",
    "deepnote_cell_height": 123.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b123f599f9ea372d14676e23f1c6a52",
     "grade": false,
     "grade_id": "cell-4b2534067c44fcdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### Section 6.2: LSI Retrieval (10 points)<a class=\"anchor\" id=\"lsi_retrieval\"></a>\n",
    "LSI retrieval is simply ranking the documents based on their cosine similarity to the query vector.\n",
    "First, let's write a parent class for vector-based retrieval models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cell_id": "00119-814ff936-077e-4cc4-993b-e4228ac65973",
    "deepnote_cell_height": 1017,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11246845,
    "execution_start": 1645186543834,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecc111d58182570e2252b8ef5d6b02af",
     "grade": false,
     "grade_id": "cell-937936cea18711ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "c421a787"
   },
   "outputs": [],
   "source": [
    "class VectorSpaceRetrievalModel:\n",
    "    \"\"\"\n",
    "    Parent class for Dense Vector Retrieval models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, doc_repr):\n",
    "        \"\"\"\n",
    "        document_collection:\n",
    "            [\n",
    "                (doc_id_1, [token 1, token 2, ...]),\n",
    "                (doc_id_2, [token 1, token 2, ....])\n",
    "                ...\n",
    "            ]\n",
    "\n",
    "        \"\"\"\n",
    "        self.doc_repr = doc_repr\n",
    "        self.documents = [_[1] for _ in self.doc_repr]\n",
    "\n",
    "        # construct a dictionary\n",
    "        self.dictionary = Dictionary(self.documents)\n",
    "        # Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "        self.dictionary.filter_extremes(no_below=10)\n",
    "        self.corpus = [self.dictionary.doc2bow(doc) for doc in self.documents]\n",
    "\n",
    "        # Make a index to word dictionary.\n",
    "        temp = self.dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "        self.id2word = self.dictionary.id2token\n",
    "\n",
    "        # this is set by the train_model function\n",
    "        self.model = None\n",
    "\n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "        Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        vectors = {}\n",
    "        for (doc_id, _), cc in zip(self.doc_repr, self.corpus):\n",
    "            vectors[doc_id] = self.model[cc]\n",
    "        return vectors\n",
    "\n",
    "    def vectorize_query(self, query):\n",
    "        # Note the use of config_2 here!\n",
    "        query = process_text(query, **config_2)\n",
    "        query_vector = self.dictionary.doc2bow(query)\n",
    "        return self.model[query_vector]\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Trains a model and sets the 'self.model' variable.\n",
    "        Make sure to use the variables created in the __init__ method.\n",
    "        e.g the variables which may be useful: {corpus, dictionary, id2word}\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00120-41460ee2-1ba5-4e9b-8779-fc6d4bfda152",
    "deepnote_cell_height": 181,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff161eefd9b81b768cd6361bc1a502b0",
     "grade": false,
     "grade_id": "cell-704a18c2f80cd60c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "**Implementation (5 points):**\n",
    "Implement the `train_model` method in the following class (note that this is only one line of code in `gensim`!). Ensure that the parameters defined in the `__init__` method are not changed, and are *used in the `train_method` function*. Normally, the hyperaparameter space will be searched using grid search / other methods - in this assignment we have provided the hyperparameters for you.\n",
    "\n",
    "The last two lines of code train an LSI model on the list of documents which have been stemmed, lower-cased and have stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cell_id": "00121-9056c69d-5f3f-4d7d-bdd1-1593996f65a1",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645186543877,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e90eedc27c248bc1ae050518a46a46c",
     "grade": false,
     "grade_id": "cell-307682c9089f15d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "bab726fa"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "class LsiRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "\n",
    "        self.num_topics = 100\n",
    "        self.chunksize = 2000\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = LsiModel(\n",
    "            corpus=self.corpus,\n",
    "            id2word=self.id2word,\n",
    "            num_topics=self.num_topics,\n",
    "            chunksize=self.chunksize,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cell_id": "00122-3bd0788f-3ce1-4afe-8344-6361027be847",
    "deepnote_cell_height": 1451,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 2220,
    "execution_start": 1645186543878,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00399cfe13d60cb4beed1271e36004b0",
     "grade": true,
     "grade_id": "cell-5ce512650c1b2dfb",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "31499d4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:52:15,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 11:52:15,681 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115969 corpus positions)\n",
      "2022-02-22 11:52:15,688 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2022-02-22 11:52:15,689 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2022-02-22 11:52:15,692 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2022-02-22 11:52:15,804 : INFO : using serial LSI version on this node\n",
      "2022-02-22 11:52:15,805 : INFO : updating model with new documents\n",
      "2022-02-22 11:52:15,806 : INFO : preparing a new chunk of documents\n",
      "2022-02-22 11:52:15,823 : INFO : using 100 extra samples and 2 power iterations\n",
      "2022-02-22 11:52:15,825 : INFO : 1st phase: constructing (1197, 200) action matrix\n",
      "2022-02-22 11:52:15,854 : INFO : orthonormalizing (1197, 200) action matrix\n",
      "2022-02-22 11:52:15,940 : INFO : 2nd phase: running dense svd on (200, 2000) matrix\n",
      "2022-02-22 11:52:16,006 : INFO : computing the final decomposition\n",
      "2022-02-22 11:52:16,006 : INFO : keeping 100 factors (discarding 13.474% of energy spectrum)\n",
      "2022-02-22 11:52:16,012 : INFO : processed documents up to #2000\n",
      "2022-02-22 11:52:16,018 : INFO : topic #0(152.127): 0.741*\",\" + 0.342*\"-\" + 0.211*\"system\" + 0.204*\"program\" + 0.192*\"comput\" + 0.146*\"(\" + 0.127*\"languag\" + 0.108*\")\" + 0.084*\"gener\" + 0.083*\"data\"\n",
      "2022-02-22 11:52:16,018 : INFO : topic #1(60.600): -0.607*\"(\" + -0.434*\")\" + -0.366*\"algorithm\" + -0.300*\"-\" + 0.237*\",\" + 0.213*\"system\" + 0.132*\"comput\" + -0.096*\"[\" + 0.093*\"program\" + -0.084*\"])\"\n",
      "2022-02-22 11:52:16,020 : INFO : topic #2(57.438): -0.744*\"-\" + 0.452*\",\" + -0.263*\"system\" + 0.214*\"(\" + 0.166*\")\" + -0.107*\"time\" + -0.105*\"program\" + 0.094*\"algorithm\" + -0.068*\"comput\" + -0.067*\"share\"\n",
      "2022-02-22 11:52:16,022 : INFO : topic #3(48.370): -0.483*\"system\" + -0.375*\"program\" + -0.367*\"comput\" + 0.363*\"-\" + 0.308*\",\" + -0.212*\"(\" + -0.168*\")\" + -0.147*\"algorithm\" + 0.144*\"languag\" + -0.119*\"time\"\n",
      "2022-02-22 11:52:16,024 : INFO : topic #4(45.710): 0.489*\"comput\" + -0.475*\"languag\" + -0.428*\"program\" + 0.238*\"method\" + 0.141*\"problem\" + -0.121*\"system\" + -0.109*\")\" + 0.107*\"equat\" + 0.100*\"algorithm\" + -0.099*\"(\"\n",
      "2022-02-22 11:52:16,025 : INFO : preparing a new chunk of documents\n",
      "2022-02-22 11:52:16,040 : INFO : using 100 extra samples and 2 power iterations\n",
      "2022-02-22 11:52:16,041 : INFO : 1st phase: constructing (1197, 200) action matrix\n",
      "2022-02-22 11:52:16,057 : INFO : orthonormalizing (1197, 200) action matrix\n",
      "2022-02-22 11:52:16,163 : INFO : 2nd phase: running dense svd on (200, 1204) matrix\n",
      "2022-02-22 11:52:16,214 : INFO : computing the final decomposition\n",
      "2022-02-22 11:52:16,215 : INFO : keeping 100 factors (discarding 14.020% of energy spectrum)\n",
      "2022-02-22 11:52:16,219 : INFO : merging projections: (1197, 100) + (1197, 100)\n",
      "2022-02-22 11:52:16,246 : INFO : keeping 100 factors (discarding 8.162% of energy spectrum)\n",
      "2022-02-22 11:52:16,254 : INFO : processed documents up to #3204\n",
      "2022-02-22 11:52:16,258 : INFO : topic #0(225.136): 0.759*\",\" + 0.337*\"-\" + 0.196*\"system\" + 0.186*\"program\" + 0.166*\"comput\" + 0.139*\"(\" + 0.103*\")\" + 0.103*\"algorithm\" + 0.099*\"languag\" + 0.087*\"time\"\n",
      "2022-02-22 11:52:16,260 : INFO : topic #1(87.805): 0.613*\"-\" + -0.399*\",\" + 0.399*\"(\" + 0.326*\"algorithm\" + 0.293*\")\" + -0.129*\"system\" + -0.107*\"program\" + 0.085*\"method\" + 0.077*\"time\" + 0.062*\"1\"\n",
      "2022-02-22 11:52:16,263 : INFO : topic #2(81.909): 0.550*\"-\" + -0.434*\"(\" + 0.355*\"system\" + -0.321*\")\" + -0.291*\",\" + -0.266*\"algorithm\" + 0.146*\"program\" + 0.123*\"comput\" + 0.078*\"time\" + -0.064*\"[\"\n",
      "2022-02-22 11:52:16,266 : INFO : topic #3(72.433): -0.693*\"program\" + 0.339*\",\" + 0.279*\"-\" + -0.251*\"(\" + -0.221*\"system\" + -0.214*\"languag\" + -0.204*\")\" + -0.160*\"comput\" + -0.099*\"data\" + -0.056*\"execut\"\n",
      "2022-02-22 11:52:16,268 : INFO : topic #4(68.523): -0.673*\"system\" + 0.453*\"program\" + 0.254*\"languag\" + 0.212*\"-\" + -0.179*\"comput\" + -0.165*\"(\" + -0.121*\")\" + -0.115*\"model\" + 0.101*\",\" + -0.098*\"algorithm\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.015215571230771226),\n",
       " (1, -0.016276379347661116),\n",
       " (2, -0.00018141372459350375),\n",
       " (3, -0.0017740576718364527),\n",
       " (4, -0.0094288369780088),\n",
       " (5, -0.004690644035269737),\n",
       " (6, 0.02706946166952292),\n",
       " (7, 0.016702213145885502),\n",
       " (8, -0.03196674639908027),\n",
       " (9, -0.0005586204565600304),\n",
       " (10, 0.0023940529151850595),\n",
       " (11, -0.017625237564370386),\n",
       " (12, 0.0001536740473226158),\n",
       " (13, 0.0014489036613997515),\n",
       " (14, 0.00391552513059162),\n",
       " (15, 0.005052924722397616),\n",
       " (16, 0.004775183809057235),\n",
       " (17, 0.0030319917990967744),\n",
       " (18, -0.017223232029373127),\n",
       " (19, 0.019675666730120507),\n",
       " (20, -0.009540177987547268),\n",
       " (21, -0.013395594945587116),\n",
       " (22, 0.04712434796314014),\n",
       " (23, 0.026709246528141814),\n",
       " (24, -0.01043594207122951),\n",
       " (25, -0.009684639174185824),\n",
       " (26, 0.006496616357848553),\n",
       " (27, 0.07583193744513074),\n",
       " (28, -0.06354376475986062),\n",
       " (29, 0.029496738632796317),\n",
       " (30, 0.04263417557924737),\n",
       " (31, 0.048166466714057214),\n",
       " (32, -0.06593155751740158),\n",
       " (33, 0.05190117463381394),\n",
       " (34, -0.030457825712275424),\n",
       " (35, 0.0639039797041952),\n",
       " (36, 0.03959359245735868),\n",
       " (37, -0.006600862243799818),\n",
       " (38, -0.059283692332032054),\n",
       " (39, 0.017604634021945363),\n",
       " (40, -0.04619915732928497),\n",
       " (41, -0.03421535358863647),\n",
       " (42, 0.024174179618305404),\n",
       " (43, 0.01560704921656233),\n",
       " (44, 0.027850872619639165),\n",
       " (45, 0.0541166342625572),\n",
       " (46, -0.0080334111597614),\n",
       " (47, 0.005949314257311508),\n",
       " (48, 0.011074449641718243),\n",
       " (49, 0.03130234554350121),\n",
       " (50, 0.01605027405318041),\n",
       " (51, 0.047819346619620846),\n",
       " (52, -0.01283061613569579),\n",
       " (53, 0.007887131644346243),\n",
       " (54, 0.04424843569793022),\n",
       " (55, 0.020087319220436734),\n",
       " (56, -0.01750713165857982),\n",
       " (57, -0.017780238554681867),\n",
       " (58, -0.007874593158124204),\n",
       " (59, 0.04181498195837319),\n",
       " (60, -0.015881720652584634),\n",
       " (61, -0.0417098545958072),\n",
       " (62, -0.017858846602324594),\n",
       " (63, 0.03830297090068184),\n",
       " (64, -0.04793063370793797),\n",
       " (65, 0.04390012616460325),\n",
       " (66, 0.010228041803381402),\n",
       " (67, -0.07046231347449364),\n",
       " (68, 0.006343801441229011),\n",
       " (69, -0.04364069093188543),\n",
       " (70, 0.037256568835091694),\n",
       " (71, -0.019018776729676334),\n",
       " (72, -0.07350468664510225),\n",
       " (73, 0.058862202459043445),\n",
       " (74, -0.06838402036333947),\n",
       " (75, 0.025708712107890032),\n",
       " (76, 0.00047901101722750816),\n",
       " (77, 0.004293465151735315),\n",
       " (78, 0.049204220679165654),\n",
       " (79, 0.03822902305291484),\n",
       " (80, -0.01967029229947097),\n",
       " (81, -0.0003570718035565239),\n",
       " (82, 0.039527204969687535),\n",
       " (83, 0.020427151135428527),\n",
       " (84, -0.0584179115315471),\n",
       " (85, -0.031148551589590748),\n",
       " (86, -0.024439733144157403),\n",
       " (87, -0.05152024412005968),\n",
       " (88, -0.04318084723573332),\n",
       " (89, -0.0662965055072651),\n",
       " (90, -0.017713285733618377),\n",
       " (91, 0.057991512039528535),\n",
       " (92, 0.01746207928431976),\n",
       " (93, -0.0011086571658836426),\n",
       " (94, 0.05767776550546464),\n",
       " (95, -0.01549171163866083),\n",
       " (96, -0.012292554674373402),\n",
       " (97, -0.028216381907548195),\n",
       " (98, 0.023192787505680303),\n",
       " (99, -0.00674794185523683)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Function check\n",
    "lsi = LsiRetrievalModel(doc_repr_2)\n",
    "lsi.train_model()\n",
    "\n",
    "# you can now get an LSI vector for a given query in the following way:\n",
    "lsi.vectorize_query(\"report\")\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00123-e372e3ee-50ec-4225-ab44-bb4d14ac8190",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7116bb9f576c5bb04934e1d59c51d729",
     "grade": false,
     "grade_id": "cell-4c5eeb557b4fca2f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00124-d9fd321a-609f-4da5-8d2d-584c9ed530d3",
    "deepnote_cell_height": 73,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26e2ff3c413745e633d99f66c041d6b1",
     "grade": false,
     "grade_id": "cell-c4e50296cd17a555",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "**Implementation (5 points):**\n",
    " Next, implement a basic ranking class for vector space retrieval (used for all semantic methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cell_id": "00125-826a2865-fd5c-4886-96fd-21c5894bcd77",
    "deepnote_cell_height": 765,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 1,
    "execution_start": 1645186546165,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a8389d2f0635c3405e2b0b27ed9f327",
     "grade": false,
     "grade_id": "cell-250515d288e80cdc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "eb69cddb"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "class DenseRetrievalRanker:\n",
    "    def __init__(self, vsrm, similarity_fn):\n",
    "        \"\"\"\n",
    "        vsrm: instance of `VectorSpaceRetrievalModel`\n",
    "        similarity_fn: function instance that takes in two vectors\n",
    "                        and returns a similarity score e.g cosine_sim defined earlier\n",
    "        \"\"\"\n",
    "        self.vsrm = vsrm\n",
    "        self.vectorized_documents = self.vsrm.vectorize_documents()\n",
    "        self.similarity_fn = similarity_fn\n",
    "\n",
    "    def _compute_sim(self, query_vector):\n",
    "        \"\"\"\n",
    "        Compute the similarity of `query_vector` to documents in\n",
    "        `self.vectorized_documents` using `self.similarity_fn`\n",
    "        Returns a list of (doc_id, score) tuples\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for doc_id, doc in self.vectorized_documents.items():\n",
    "            result.append((doc_id, self.similarity_fn(query_vector, doc)))\n",
    "        return result\n",
    "\n",
    "    def search(self, query):\n",
    "        scores = self._compute_sim(self.vsrm.vectorize_query(query))\n",
    "        scores.sort(key=lambda _: -_[1])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "cell_id": "00126-61a00dcc-2fd6-4dc9-9bdd-24f69e74576b",
    "deepnote_cell_height": 248.9375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     97.9375
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 2654,
    "execution_start": 1645186546166,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f237dd1ef6c1783c06797f4b514421f5",
     "grade": true,
     "grade_id": "cell-b73068b3e77a8e31",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "d95413f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('599', 0.8014783147512464),\n",
       " ('947', 0.5830225421002823),\n",
       " ('53', 0.49792155729590953),\n",
       " ('1339', 0.4666920679738261),\n",
       " ('3160', 0.4420270547172813)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Function check\n",
    "drm_lsi = DenseRetrievalRanker(lsi, cosine_sim)\n",
    "drm_lsi.search(\"report\")[:5]\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00127-61d1bfa7-3b4f-4bae-9849-3abf43008fb7",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b3f19fdcaa585d263706d5a26038799",
     "grade": false,
     "grade_id": "cell-034c755a6502b868",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00128-76ede674-a982-4ad0-abe7-680c64dc6488",
    "deepnote_cell_height": 75.796875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcafef6e037033c46304b914f7c78bdf",
     "grade": false,
     "grade_id": "cell-d1df23f497d5ed6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Now, you can test your LSI model in the following cell: try finding queries which are lexically different to documents, but semantically similar - does LSI work well for these queries?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "cell_id": "00129-e8052686-38ce-490b-8725-f62afa5b6285",
    "deepnote_cell_height": 663,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 45,
    "execution_start": 1645186548831,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11734bc7674377b340ad51297a8e8bb5",
     "grade": false,
     "grade_id": "cell-efd1d08dfc04ec3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "15e4943e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb5f45f4c464c3b81b1ec86e7448a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test your LSI model\n",
    "search_fn = drm_lsi.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "def make_results_2(query, search_fn):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n",
    "\n",
    "\n",
    "def handle_submit_2(sender):\n",
    "    print(f\"Searching for: '{sender.value}' (SEARCH FN: {search_fn})\")\n",
    "\n",
    "    results = make_results_2(sender.value, search_fn)\n",
    "\n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "\n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00130-70ac6c5f-a513-4253-abde-f31df522d92d",
    "deepnote_cell_height": 190.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d074ce1ca48384cdda78742741c938be",
     "grade": false,
     "grade_id": "cell-3a86cef264d8f6cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 7: Latent Dirichlet Allocation (LDA) (10 points) <a class=\"anchor\" id=\"lda\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "The specifics of LDA is out of the scope of this assignment, but we will use the `gensim` implementation to perform search using LDA over our small document collection. The key thing to remember is that LDA, unlike LSI, outputs a topic **distribution**, not a vector. With that in mind, let's first define a similarity measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00131-ec0e884b-e164-4ba8-9ed6-c767c87825c3",
    "deepnote_cell_height": 182.59375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db01092373b18f0c9dfed1bb17db4ad9",
     "grade": false,
     "grade_id": "cell-6b78ad22c2d60ba7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### Section 7.1: Jenson-Shannon divergence (5 points) <a class=\"anchor\" id=\"js_sim\"></a>\n",
    "\n",
    "The Jenson-Shannon divergence is a symmetric and finite measure on two probability distributions (unlike the KL, which is neither). For identical distributions, the JSD is equal to 0, and since our code uses 0 as irrelevant and higher scores as relevant, we use `(1 - JSD)` as the score or 'similarity' in our setup\n",
    "\n",
    "**Note**: the JSD is bounded to \\[0,1\\] only if we use log base 2. So please ensure that you're using `np.log2` instead of `np.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "cell_id": "00132-ccb9488f-e93e-484d-891a-5260b0b3ba46",
    "deepnote_cell_height": 783,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 14,
    "execution_start": 1645186548888,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a579e6cd7a24a3516bc9a84528b392d3",
     "grade": false,
     "grade_id": "cell-d2376a85a4841e98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "887f6708"
   },
   "outputs": [],
   "source": [
    "## TODO: Implement this! (5 points)\n",
    "def jenson_shannon_divergence(vec_1, vec_2, assert_prob=False):\n",
    "    \"\"\"\n",
    "    Computes the Jensen-Shannon divergence between two probability distributions.\n",
    "    NOTE: DO NOT RETURN 1 - JSD here, that is handled by the next function which is already implemented!\n",
    "    The inputs are *gensim* vectors - same as the vectors for the cosine_sim function\n",
    "    assert_prob is a flag that checks if the inputs are proper probability distributions\n",
    "        i.e they sum to 1 and are positive - use this to check your inputs if needed.\n",
    "            (This is optional to implement, but recommended -\n",
    "            you can the default to False to save a few ms off the runtime)\n",
    "    \"\"\"\n",
    "\n",
    "    # --------- Define a custom KL divergence function --------\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a, dtype=np.float)\n",
    "        b = np.asarray(b, dtype=np.float)\n",
    "\n",
    "        return np.sum(np.where(a != 0, a * np.log2(a / b), 0))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    vec_1_probs = np.array([x[1] for x in vec_1])  # extracting the probabily values\n",
    "    vec_2_probs = np.array([y[1] for y in vec_2])  # extracting the probabily values\n",
    "\n",
    "    # if flag=True, assert that the inputs are proper probability distributions\n",
    "    if assert_prob:\n",
    "        assert np.sum(vec_1_probs) == 1 and all(\n",
    "            vec_1_probs > 0\n",
    "        ), \"Values of vector1 must sum to 1 and be positive\"\n",
    "        assert np.sum(vec_2_probs) == 1 and all(\n",
    "            vec_2_probs > 0\n",
    "        ), \"Values of vector2 must sum to 1 and be positive\"\n",
    "\n",
    "    # If inputs are valid, compute divergence\n",
    "    m = 0.5 * (vec_1_probs + vec_2_probs)\n",
    "    return 0.5 * KL(vec_1_probs, m) + 0.5 * KL(vec_2_probs, m)\n",
    "\n",
    "\n",
    "def jenson_shannon_sim(vec_1, vec_2, assert_prob=False):\n",
    "    return 1 - jenson_shannon_divergence(vec_1, vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "cell_id": "00133-062a3052-2e16-413b-bac4-d476558e3866",
    "deepnote_cell_height": 190.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 70,
    "execution_start": 1645186548917,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab340aa941c9fb5c89b3fd0a9139e246",
     "grade": true,
     "grade_id": "cell-487c6d2933f38053",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "74ec8119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251064410358459"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Function check\n",
    "vec_1 = [(1, 0.3), (2, 0.4), (3, 0.3)]\n",
    "vec_2 = [(1, 0.1), (2, 0.7), (3, 0.2)]\n",
    "jenson_shannon_sim(vec_1, vec_2, assert_prob=True)\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00134-b1b00101-4499-4c42-a48c-f90f9f37d7e9",
    "deepnote_cell_height": 227.375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a1583a5f23e3390038331cce67f5d8e",
     "grade": false,
     "grade_id": "cell-4535cc67a50b80fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "### Section 7.2: LDA retrieval (5 points) <a class=\"anchor\" id=\"lda_ret\"></a>\n",
    "\n",
    "Implement the `train_model` method in the following class (note that this is only one line of code in `gensim`!). Ensure that the parameters defined in the `__init__` method are not changed, and are *used in the `train_method` function*. You do not need to set this. Normally, the hyperaparameter space will be searched using grid search / other methods. Note that training the LDA model might take some time\n",
    "\n",
    "The last two lines of code train an LDA model on the list of documents which have been stemmed, lower-cased and have stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "cell_id": "00135-c9620a32-0d75-44b0-9b91-6223cae5d6d9",
    "deepnote_cell_height": 603,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 1,
    "execution_start": 1645186548985,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27de8e4fa85536bb396b73bfc51b3f50",
     "grade": false,
     "grade_id": "cell-021a48dff4a8bb91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "a2398658"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "class LdaRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "\n",
    "        # use these parameters in the train_model method\n",
    "        self.num_topics = 100\n",
    "        self.chunksize = 2000\n",
    "        self.passes = 20\n",
    "        self.iterations = 400\n",
    "        self.eval_every = 10\n",
    "        # this is need to get full vectors\n",
    "        self.minimum_probability = 0.0\n",
    "        self.alpha = \"auto\"\n",
    "        self.eta = \"auto\"\n",
    "\n",
    "    def train_model(self):\n",
    "        # YOUR CODE HERE\n",
    "        self.model = LdaModel(\n",
    "            corpus=self.corpus,\n",
    "            id2word=self.id2word,\n",
    "            num_topics=self.num_topics,\n",
    "            chunksize=self.chunksize,\n",
    "            passes=self.passes,\n",
    "            iterations=self.iterations,\n",
    "            eval_every=self.eval_every,\n",
    "            minimum_probability=self.minimum_probability,\n",
    "            alpha=self.alpha,\n",
    "            eta=self.eta,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cell_id": "00136-7336885c-d6be-4e5e-8515-a71905b8c1df",
    "deepnote_cell_height": 219.796875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 116845,
    "execution_start": 1645186548986,
    "is_output_hidden": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be70fcb8098d0b6ce64cd2a10e6a05b7",
     "grade": true,
     "grade_id": "cell-86750b715f0345fd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "25223581",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:52:17,779 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 11:52:17,937 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115969 corpus positions)\n",
      "2022-02-22 11:52:17,947 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2022-02-22 11:52:17,948 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2022-02-22 11:52:17,953 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2022-02-22 11:52:18,036 : INFO : using autotuned alpha, starting with [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "2022-02-22 11:52:18,040 : INFO : using serial LDA version on this node\n",
      "2022-02-22 11:52:18,058 : INFO : running online (multi-pass) LDA training, 100 topics, 20 passes over the supplied corpus of 3204 documents, updating model once every 2000 documents, evaluating perplexity every 3204 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2022-02-22 11:52:18,069 : INFO : PROGRESS: pass 0, at document #2000/3204\n",
      "2022-02-22 11:52:19,744 : INFO : optimized alpha [0.0098137995, 0.009953315, 0.009839965, 0.009778122, 0.009829464, 0.009808842, 0.009990614, 0.009813751, 0.009803843, 0.00979864, 0.00986588, 0.009778048, 0.009829749, 0.009897512, 0.009861336, 0.009829347, 0.009845158, 0.00981896, 0.009865836, 0.009835092, 0.009818922, 0.009906033, 0.00986613, 0.009855311, 0.009787988, 0.009772908, 0.00980353, 0.009886836, 0.009849606, 0.00977272, 0.009772762, 0.009793516, 0.009902344, 0.009793304, 0.00981908, 0.009853462, 0.009793351, 0.009876644, 0.009819286, 0.00979353, 0.009834727, 0.009788035, 0.009824282, 0.009819522, 0.009819251, 0.009772917, 0.00987628, 0.009855589, 0.009834479, 0.009886792, 0.009829203, 0.009829615, 0.009783006, 0.009814102, 0.009819584, 0.009943309, 0.009813825, 0.009912792, 0.009933568, 0.009767563, 0.009881974, 0.0097777285, 0.009798783, 0.009798601, 0.009792801, 0.009897556, 0.009840117, 0.009782987, 0.009891365, 0.009803885, 0.009803811, 0.009819198, 0.009855536, 0.009798539, 0.009793209, 0.009860951, 0.009798557, 0.009793151, 0.009793221, 0.009798563, 0.009819419, 0.009824222, 0.009798514, 0.0098969815, 0.0098350085, 0.009774504, 0.009819513, 0.009809119, 0.00983004, 0.009803905, 0.009814273, 0.0098399995, 0.009881164, 0.009793368, 0.009824552, 0.009845781, 0.009783034, 0.009829654, 0.009803765, 0.00983434]\n",
      "2022-02-22 11:52:19,753 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:19,762 : INFO : topic #30 (0.010): 0.079*\"logic\" + 0.049*\"tabl\" + 0.040*\"system\" + 0.040*\",\" + 0.036*\"algorithm\" + 0.030*\"solv\" + 0.020*\"elimin\" + 0.020*\"express\" + 0.020*\"special\" + 0.020*\"linear\"\n",
      "2022-02-22 11:52:19,763 : INFO : topic #29 (0.010): 0.045*\"retriev\" + 0.045*\"inform\" + 0.045*\"system\" + 0.045*\",\" + 0.034*\"evalu\" + 0.034*\"(\" + 0.022*\"machin\" + 0.022*\"mechan\" + 0.022*\"experi\" + 0.022*\"actual\"\n",
      "2022-02-22 11:52:19,765 : INFO : topic #65 (0.010): 0.082*\",\" + 0.024*\"-\" + 0.022*\"system\" + 0.020*\"algorithm\" + 0.020*\"comput\" + 0.019*\"program\" + 0.012*\"'\" + 0.011*\"invers\" + 0.010*\"\"\" + 0.009*\"problem\"\n",
      "2022-02-22 11:52:19,769 : INFO : topic #1 (0.010): 0.055*\"-\" + 0.045*\",\" + 0.041*\"(\" + 0.027*\")\" + 0.021*\"program\" + 0.020*\"algorithm\" + 0.015*\"solut\" + 0.014*\"processor\" + 0.012*\"gener\" + 0.012*\"time\"\n",
      "2022-02-22 11:52:19,771 : INFO : topic #6 (0.010): 0.078*\",\" + 0.036*\"system\" + 0.028*\"-\" + 0.023*\"comput\" + 0.019*\"(\" + 0.017*\"program\" + 0.013*\")\" + 0.013*\"method\" + 0.012*\"algorithm\" + 0.009*\"gener\"\n",
      "2022-02-22 11:52:19,773 : INFO : topic diff=82.155556, rho=1.000000\n",
      "2022-02-22 11:52:20,806 : INFO : -7.311 per-word bound, 158.8 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:20,807 : INFO : PROGRESS: pass 0, at document #3204/3204\n",
      "2022-02-22 11:52:21,663 : INFO : optimized alpha [0.009678713, 0.010022945, 0.009963633, 0.009995479, 0.009982984, 0.010032105, 0.010072798, 0.009930418, 0.009963263, 0.0098635005, 0.009960795, 0.009849316, 0.009954635, 0.009981267, 0.010015978, 0.009741067, 0.009945154, 0.009747542, 0.009782064, 0.010152928, 0.009812236, 0.010168246, 0.010009212, 0.009914312, 0.009846103, 0.010236183, 0.009779276, 0.0100600645, 0.010113552, 0.00985491, 0.009807986, 0.009936115, 0.009872227, 0.01020397, 0.010242208, 0.010251189, 0.009956765, 0.009984191, 0.009902265, 0.010080857, 0.010035151, 0.009794374, 0.009881757, 0.009955497, 0.00988376, 0.009914896, 0.010392319, 0.009878933, 0.009833877, 0.010053847, 0.009776193, 0.009930018, 0.009835495, 0.009920419, 0.010098438, 0.010127724, 0.009865932, 0.010314719, 0.010167176, 0.009906596, 0.010031756, 0.009690226, 0.010176571, 0.010127973, 0.009950845, 0.0100286435, 0.00997021, 0.009800484, 0.009837406, 0.009903765, 0.010203768, 0.010043507, 0.010074385, 0.009780308, 0.009827382, 0.010087378, 0.009786332, 0.00980466, 0.009856503, 0.009897701, 0.0102420645, 0.009911972, 0.009687625, 0.010009632, 0.009918634, 0.009891212, 0.010119654, 0.010038819, 0.009938099, 0.010121844, 0.009974343, 0.010259828, 0.010081714, 0.009858112, 0.009783654, 0.01022044, 0.009864662, 0.009929209, 0.009897298, 0.009903753]\n",
      "2022-02-22 11:52:21,672 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:21,682 : INFO : topic #61 (0.010): 0.149*\"(\" + 0.136*\"algorithm\" + 0.119*\")\" + 0.109*\"block\" + 0.097*\"minim\" + 0.076*\"complex\" + 0.076*\"function\" + 0.071*\"[\" + 0.027*\"e4\" + 0.020*\"real\"\n",
      "2022-02-22 11:52:21,683 : INFO : topic #0 (0.010): 0.070*\"manag\" + 0.065*\"subset\" + 0.051*\"languag\" + 0.048*\"comput\" + 0.042*\",\" + 0.040*\"data\" + 0.029*\"form\" + 0.023*\"(\" + 0.022*\"system\" + 0.020*\"report\"\n",
      "2022-02-22 11:52:21,685 : INFO : topic #34 (0.010): 0.131*\"tree\" + 0.082*\"search\" + 0.034*\"sampl\" + 0.032*\"binari\" + 0.032*\",\" + 0.028*\"algorithm\" + 0.024*\"shown\" + 0.021*\"-\" + 0.020*\"mean\" + 0.018*\"structur\"\n",
      "2022-02-22 11:52:21,689 : INFO : topic #57 (0.010): 0.094*\"program\" + 0.069*\",\" + 0.050*\"languag\" + 0.020*\"-\" + 0.015*\"system\" + 0.014*\"paper\" + 0.012*\"comput\" + 0.011*\"implement\" + 0.011*\"structur\" + 0.011*\"gener\"\n",
      "2022-02-22 11:52:21,690 : INFO : topic #46 (0.010): 0.058*\",\" + 0.053*\"-\" + 0.040*\"system\" + 0.027*\"time\" + 0.027*\"cost\" + 0.023*\"comput\" + 0.023*\"node\" + 0.022*\"tree\" + 0.022*\"structur\" + 0.021*\"averag\"\n",
      "2022-02-22 11:52:21,691 : INFO : topic diff=0.723790, rho=0.707107\n",
      "2022-02-22 11:52:21,704 : INFO : PROGRESS: pass 1, at document #2000/3204\n",
      "2022-02-22 11:52:22,712 : INFO : optimized alpha [0.009600049, 0.009923421, 0.0099585615, 0.009922653, 0.0099481335, 0.0099663865, 0.009980514, 0.010084293, 0.010037898, 0.0098437155, 0.009884149, 0.009853204, 0.009875391, 0.00987504, 0.009943895, 0.009741747, 0.00985254, 0.009729227, 0.009717108, 0.010074372, 0.009885442, 0.010072931, 0.009947755, 0.009809211, 0.010054536, 0.010214929, 0.009807053, 0.009970374, 0.0104985, 0.009939568, 0.009762465, 0.00994714, 0.009789753, 0.010199271, 0.010228549, 0.01020347, 0.009887171, 0.009901747, 0.009810699, 0.010091429, 0.01001542, 0.009854078, 0.009845437, 0.009923646, 0.009898089, 0.009955077, 0.010271876, 0.009785682, 0.00985061, 0.010034539, 0.009768045, 0.009861918, 0.00975018, 0.009891254, 0.010026597, 0.010036217, 0.009856859, 0.010338701, 0.01009166, 0.009895752, 0.009964656, 0.009932669, 0.010175465, 0.010108638, 0.009908034, 0.009977635, 0.0098854, 0.009833798, 0.009760665, 0.009838213, 0.010150546, 0.010111019, 0.0100001395, 0.009753763, 0.009823136, 0.010004871, 0.009723125, 0.010419014, 0.009959234, 0.009850699, 0.010190883, 0.009856817, 0.009702047, 0.009915777, 0.009893923, 0.009960163, 0.010047015, 0.00997611, 0.009982323, 0.010029634, 0.0099747265, 0.010189272, 0.010001899, 0.009928159, 0.009762614, 0.010137648, 0.009883662, 0.009881878, 0.009860771, 0.009915393]\n",
      "2022-02-22 11:52:22,718 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:22,725 : INFO : topic #0 (0.010): 0.068*\"subset\" + 0.058*\"languag\" + 0.056*\"comput\" + 0.045*\",\" + 0.041*\"manag\" + 0.037*\"data\" + 0.034*\"form\" + 0.031*\"report\" + 0.024*\"user\" + 0.023*\"system\"\n",
      "2022-02-22 11:52:22,726 : INFO : topic #18 (0.010): 0.092*\",\" + 0.046*\"algorithm\" + 0.034*\"comput\" + 0.026*\"formula\" + 0.024*\"project\" + 0.018*\"statist\" + 0.017*\"-\" + 0.016*\"languag\" + 0.016*\"integr\" + 0.015*\"relat\"\n",
      "2022-02-22 11:52:22,726 : INFO : topic #57 (0.010): 0.098*\"program\" + 0.068*\",\" + 0.057*\"languag\" + 0.023*\"-\" + 0.016*\"system\" + 0.013*\"paper\" + 0.012*\"process\" + 0.012*\"comput\" + 0.011*\"gener\" + 0.011*\"text\"\n",
      "2022-02-22 11:52:22,727 : INFO : topic #77 (0.010): 0.203*\"algorithm\" + 0.198*\"(\" + 0.138*\"[\" + 0.118*\"])\" + 0.076*\")\" + 0.024*\"-\" + 0.022*\"polynomi\" + 0.016*\"random\" + 0.016*\"gener\" + 0.013*\"chain\"\n",
      "2022-02-22 11:52:22,729 : INFO : topic #28 (0.010): 0.194*\")\" + 0.191*\"(\" + 0.128*\"algorithm\" + 0.027*\"equat\" + 0.026*\"interpol\" + 0.026*\"solut\" + 0.019*\"invers\" + 0.019*\"-\" + 0.014*\"order\" + 0.013*\"stabil\"\n",
      "2022-02-22 11:52:22,730 : INFO : topic diff=0.310924, rho=0.526900\n",
      "2022-02-22 11:52:23,851 : INFO : -6.911 per-word bound, 120.3 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:23,851 : INFO : PROGRESS: pass 1, at document #3204/3204\n",
      "2022-02-22 11:52:25,038 : INFO : optimized alpha [0.009579574, 0.009937002, 0.0100775575, 0.010111762, 0.010093509, 0.010199522, 0.010011052, 0.010259057, 0.010295721, 0.009896959, 0.009916413, 0.01003813, 0.0100173475, 0.009894641, 0.009992737, 0.009727171, 0.0099236285, 0.009731356, 0.009677002, 0.010322703, 0.009946573, 0.010165368, 0.010054892, 0.009872367, 0.010202316, 0.010649417, 0.009889834, 0.0100775175, 0.010859963, 0.01016359, 0.0098463865, 0.010119823, 0.009766931, 0.010694981, 0.0106132785, 0.010394728, 0.010075369, 0.009969558, 0.009909141, 0.010343432, 0.010160956, 0.010034219, 0.009897984, 0.0100339465, 0.009994499, 0.010158479, 0.010568029, 0.009796854, 0.0098768715, 0.010172496, 0.00984796, 0.009977176, 0.009873172, 0.010036668, 0.010236124, 0.010182968, 0.009922669, 0.010658378, 0.010239801, 0.010126397, 0.010036294, 0.010152274, 0.010547476, 0.010360756, 0.0100611085, 0.010030912, 0.009987517, 0.009877542, 0.0097638015, 0.009921918, 0.010552594, 0.010332844, 0.010114596, 0.009750952, 0.009953269, 0.010205203, 0.009849821, 0.010644141, 0.010084049, 0.009986199, 0.010501759, 0.00993148, 0.00975703, 0.010004908, 0.010027313, 0.010082015, 0.010330801, 0.01015299, 0.010160875, 0.010299962, 0.010107524, 0.010507108, 0.010156139, 0.0100638885, 0.009778378, 0.010369895, 0.01001014, 0.010030745, 0.010044112, 0.010037212]\n",
      "2022-02-22 11:52:25,047 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:25,055 : INFO : topic #0 (0.010): 0.085*\"subset\" + 0.081*\"manag\" + 0.068*\"languag\" + 0.058*\"comput\" + 0.046*\"data\" + 0.041*\"form\" + 0.040*\",\" + 0.037*\"report\" + 0.032*\"system\" + 0.024*\":\"\n",
      "2022-02-22 11:52:25,056 : INFO : topic #18 (0.010): 0.092*\",\" + 0.057*\"algorithm\" + 0.035*\"project\" + 0.035*\"comput\" + 0.031*\"forward\" + 0.023*\"formula\" + 0.021*\"version\" + 0.020*\"relat\" + 0.019*\"statist\" + 0.018*\"-\"\n",
      "2022-02-22 11:52:25,056 : INFO : topic #77 (0.011): 0.226*\"algorithm\" + 0.204*\"(\" + 0.163*\"[\" + 0.110*\")\" + 0.062*\"])\" + 0.023*\"-\" + 0.019*\"polynomi\" + 0.015*\"probabl\" + 0.014*\"chain\" + 0.014*\"gener\"\n",
      "2022-02-22 11:52:25,057 : INFO : topic #33 (0.011): 0.189*\"]\" + 0.055*\"approxim\" + 0.051*\"solut\" + 0.050*\"comment\" + 0.050*\"problem\" + 0.043*\"equat\" + 0.037*\"method\" + 0.033*\"valu\" + 0.032*\"5\" + 0.027*\"differenti\"\n",
      "2022-02-22 11:52:25,059 : INFO : topic #28 (0.011): 0.221*\"(\" + 0.216*\")\" + 0.122*\"algorithm\" + 0.028*\"interpol\" + 0.025*\"equat\" + 0.023*\"solut\" + 0.020*\"stabil\" + 0.019*\"-\" + 0.014*\"order\" + 0.012*\"spline\"\n",
      "2022-02-22 11:52:25,061 : INFO : topic diff=0.423533, rho=0.526900\n",
      "2022-02-22 11:52:25,069 : INFO : PROGRESS: pass 2, at document #2000/3204\n",
      "2022-02-22 11:52:25,935 : INFO : optimized alpha [0.009560584, 0.009856855, 0.010106125, 0.010062879, 0.010102388, 0.010167946, 0.00993197, 0.010381221, 0.0104265595, 0.009903676, 0.009871759, 0.010097398, 0.009970971, 0.0098227775, 0.0099378945, 0.009756393, 0.009855272, 0.009824123, 0.009624961, 0.010258341, 0.010029927, 0.010080015, 0.010010391, 0.009788566, 0.010425019, 0.010647776, 0.009926093, 0.010013425, 0.011311361, 0.01030714, 0.009813634, 0.01013328, 0.009729794, 0.010725054, 0.01062157, 0.0103561515, 0.010036148, 0.009902928, 0.009843464, 0.010416108, 0.010154647, 0.010197321, 0.009871535, 0.010029232, 0.0100212665, 0.010252675, 0.01046094, 0.009754339, 0.009938755, 0.010191274, 0.009880184, 0.009940848, 0.009816705, 0.010045491, 0.010178352, 0.010137893, 0.009919325, 0.010724902, 0.010182598, 0.0101624755, 0.009992371, 0.010594387, 0.010554935, 0.010348527, 0.010029689, 0.010008184, 0.00992755, 0.009926109, 0.009714767, 0.00988602, 0.010507709, 0.010440264, 0.010049477, 0.009758939, 0.010018843, 0.0101527525, 0.009826241, 0.01129746, 0.010219955, 0.009949, 0.010462705, 0.009906986, 0.009844001, 0.009932566, 0.01002161, 0.010164353, 0.010295146, 0.010115761, 0.010261451, 0.010227674, 0.01011468, 0.010475736, 0.010087532, 0.010180842, 0.009814116, 0.010297237, 0.010099699, 0.010016702, 0.010050652, 0.0101371035]\n",
      "2022-02-22 11:52:25,942 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:25,947 : INFO : topic #0 (0.010): 0.079*\"subset\" + 0.072*\"languag\" + 0.060*\"comput\" + 0.051*\"manag\" + 0.044*\"form\" + 0.044*\",\" + 0.043*\"report\" + 0.043*\"data\" + 0.037*\"format\" + 0.030*\"system\"\n",
      "2022-02-22 11:52:25,949 : INFO : topic #18 (0.010): 0.097*\",\" + 0.050*\"algorithm\" + 0.038*\"comput\" + 0.033*\"formula\" + 0.031*\"project\" + 0.022*\"statist\" + 0.021*\"forward\" + 0.020*\"relat\" + 0.016*\"usual\" + 0.015*\"version\"\n",
      "2022-02-22 11:52:25,952 : INFO : topic #33 (0.011): 0.131*\"]\" + 0.064*\"approxim\" + 0.057*\"solut\" + 0.054*\"problem\" + 0.051*\"equat\" + 0.046*\"comment\" + 0.037*\"method\" + 0.032*\"differenti\" + 0.031*\"valu\" + 0.027*\"5\"\n",
      "2022-02-22 11:52:25,953 : INFO : topic #77 (0.011): 0.215*\"algorithm\" + 0.205*\"(\" + 0.177*\"[\" + 0.132*\"])\" + 0.070*\")\" + 0.026*\"polynomi\" + 0.022*\"-\" + 0.014*\"gener\" + 0.012*\"chain\" + 0.012*\"random\"\n",
      "2022-02-22 11:52:25,954 : INFO : topic #28 (0.011): 0.237*\"(\" + 0.233*\")\" + 0.142*\"algorithm\" + 0.025*\"interpol\" + 0.021*\"equat\" + 0.020*\"solut\" + 0.017*\"invers\" + 0.016*\"-\" + 0.015*\"matrix\" + 0.012*\"stabil\"\n",
      "2022-02-22 11:52:25,955 : INFO : topic diff=0.410639, rho=0.466151\n",
      "2022-02-22 11:52:26,946 : INFO : -6.788 per-word bound, 110.5 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:26,947 : INFO : PROGRESS: pass 2, at document #3204/3204\n",
      "2022-02-22 11:52:27,754 : INFO : optimized alpha [0.00957096, 0.009871224, 0.010243427, 0.010227414, 0.010275291, 0.010387733, 0.0099453395, 0.010544471, 0.010703925, 0.009970504, 0.009940909, 0.010274074, 0.010124877, 0.009834682, 0.0100021465, 0.009751996, 0.009911641, 0.009871701, 0.009622721, 0.010468176, 0.010075603, 0.010123181, 0.010133665, 0.0098804375, 0.010612301, 0.01104179, 0.010018689, 0.010132648, 0.0116372835, 0.010560145, 0.009904099, 0.010318928, 0.009719737, 0.011236522, 0.010993966, 0.010444554, 0.010235169, 0.009964122, 0.010005151, 0.010682549, 0.010316028, 0.010433673, 0.0099497, 0.0101622995, 0.010145906, 0.010458537, 0.01068839, 0.009762327, 0.009977471, 0.010313872, 0.009978002, 0.010101873, 0.009968792, 0.01022168, 0.010369278, 0.010292213, 0.010012924, 0.011042841, 0.010306495, 0.010424334, 0.010040903, 0.010962256, 0.010857891, 0.010573776, 0.010189518, 0.010075778, 0.010015079, 0.0099687725, 0.0097501585, 0.009984124, 0.010887457, 0.010679408, 0.010147577, 0.009780433, 0.010192599, 0.010363182, 0.010011939, 0.011537816, 0.010357784, 0.010081357, 0.010741195, 0.009969867, 0.009930894, 0.010008774, 0.010156092, 0.010288166, 0.010557391, 0.010304974, 0.010460833, 0.010501607, 0.010204792, 0.010785571, 0.0102332, 0.010301004, 0.009893945, 0.010492082, 0.010231749, 0.010176528, 0.010233642, 0.010292244]\n",
      "2022-02-22 11:52:27,768 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:27,774 : INFO : topic #0 (0.010): 0.084*\"manag\" + 0.082*\"subset\" + 0.074*\"languag\" + 0.059*\"comput\" + 0.048*\"report\" + 0.045*\"form\" + 0.043*\"data\" + 0.039*\",\" + 0.039*\":\" + 0.037*\"system\"\n",
      "2022-02-22 11:52:27,777 : INFO : topic #18 (0.010): 0.097*\",\" + 0.057*\"algorithm\" + 0.042*\"project\" + 0.042*\"comput\" + 0.037*\"forward\" + 0.034*\"formula\" + 0.028*\"version\" + 0.023*\"relat\" + 0.023*\"previou\" + 0.022*\"statist\"\n",
      "2022-02-22 11:52:27,778 : INFO : topic #33 (0.011): 0.183*\"]\" + 0.073*\"solut\" + 0.058*\"comment\" + 0.058*\"equat\" + 0.057*\"problem\" + 0.054*\"approxim\" + 0.034*\"differenti\" + 0.032*\"5\" + 0.032*\"method\" + 0.031*\"valu\"\n",
      "2022-02-22 11:52:27,779 : INFO : topic #77 (0.012): 0.226*\"algorithm\" + 0.203*\"[\" + 0.202*\"(\" + 0.097*\")\" + 0.085*\"])\" + 0.021*\"-\" + 0.021*\"polynomi\" + 0.014*\"gener\" + 0.012*\"chain\" + 0.011*\"random\"\n",
      "2022-02-22 11:52:27,780 : INFO : topic #28 (0.012): 0.259*\"(\" + 0.244*\")\" + 0.122*\"algorithm\" + 0.029*\"interpol\" + 0.021*\"equat\" + 0.019*\"solut\" + 0.018*\"stabil\" + 0.016*\"-\" + 0.014*\"matrix\" + 0.013*\"order\"\n",
      "2022-02-22 11:52:27,781 : INFO : topic diff=0.545736, rho=0.466151\n",
      "2022-02-22 11:52:27,791 : INFO : PROGRESS: pass 3, at document #2000/3204\n",
      "2022-02-22 11:52:28,667 : INFO : optimized alpha [0.009575628, 0.009807501, 0.01028876, 0.01018028, 0.010311062, 0.010388349, 0.009888773, 0.010695927, 0.010859845, 0.009993976, 0.009926946, 0.01035156, 0.010106153, 0.009788917, 0.009972897, 0.009806443, 0.009859691, 0.010036432, 0.009596156, 0.0104152355, 0.010185796, 0.010045876, 0.010115077, 0.009814, 0.010849506, 0.011064581, 0.01007292, 0.010085647, 0.011988954, 0.010714262, 0.009889572, 0.010336759, 0.009700566, 0.011282865, 0.011019066, 0.010383267, 0.010211416, 0.009917941, 0.00996444, 0.010779378, 0.010351248, 0.010599196, 0.009939026, 0.01016832, 0.010172185, 0.010555311, 0.010599361, 0.009748618, 0.010046901, 0.010337266, 0.010038871, 0.010083261, 0.009927749, 0.010248215, 0.01031808, 0.010266266, 0.010016284, 0.011127956, 0.010263633, 0.01048869, 0.010015219, 0.011574238, 0.010873622, 0.01056552, 0.010162586, 0.010075009, 0.009970085, 0.010026091, 0.009723744, 0.009964727, 0.010865552, 0.01078597, 0.010097827, 0.009807199, 0.010309774, 0.01034533, 0.01000424, 0.012141734, 0.010495298, 0.010053851, 0.010714779, 0.009950486, 0.010063029, 0.009955131, 0.010168047, 0.010387093, 0.010531921, 0.01028342, 0.010572296, 0.010444761, 0.010183165, 0.010763306, 0.010177571, 0.010438612, 0.009947678, 0.010431895, 0.010348147, 0.010180368, 0.010253711, 0.010426889]\n",
      "2022-02-22 11:52:28,673 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:28,679 : INFO : topic #18 (0.010): 0.100*\",\" + 0.052*\"algorithm\" + 0.045*\"comput\" + 0.041*\"formula\" + 0.038*\"project\" + 0.027*\"forward\" + 0.024*\"statist\" + 0.023*\"relat\" + 0.021*\"version\" + 0.018*\"usual\"\n",
      "2022-02-22 11:52:28,680 : INFO : topic #0 (0.010): 0.076*\"languag\" + 0.076*\"subset\" + 0.058*\"comput\" + 0.056*\"manag\" + 0.052*\"report\" + 0.044*\"form\" + 0.043*\"data\" + 0.043*\",\" + 0.042*\"format\" + 0.034*\":\"\n",
      "2022-02-22 11:52:28,681 : INFO : topic #61 (0.012): 0.270*\"(\" + 0.254*\")\" + 0.243*\"algorithm\" + 0.064*\"function\" + 0.058*\"complex\" + 0.022*\"real\" + 0.019*\"minim\" + 0.018*\"number\" + 0.015*\"[\" + 0.011*\"block\"\n",
      "2022-02-22 11:52:28,682 : INFO : topic #28 (0.012): 0.263*\"(\" + 0.248*\")\" + 0.131*\"algorithm\" + 0.027*\"interpol\" + 0.019*\"matrix\" + 0.019*\"equat\" + 0.018*\"solut\" + 0.016*\"invers\" + 0.014*\"-\" + 0.013*\"'\"\n",
      "2022-02-22 11:52:28,683 : INFO : topic #77 (0.012): 0.214*\"algorithm\" + 0.208*\"[\" + 0.201*\"(\" + 0.142*\"])\" + 0.060*\")\" + 0.024*\"polynomi\" + 0.020*\"-\" + 0.013*\"gener\" + 0.012*\"coeffici\" + 0.011*\"chain\"\n",
      "2022-02-22 11:52:28,684 : INFO : topic diff=0.561364, rho=0.422502\n",
      "2022-02-22 11:52:29,619 : INFO : -6.705 per-word bound, 104.3 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:29,619 : INFO : PROGRESS: pass 3, at document #3204/3204\n",
      "2022-02-22 11:52:30,378 : INFO : optimized alpha [0.009592928, 0.009836511, 0.0104249185, 0.010334088, 0.010494747, 0.010582232, 0.0099167675, 0.010886217, 0.011189493, 0.010072634, 0.01000107, 0.010520368, 0.010257309, 0.009776984, 0.010053353, 0.009806439, 0.009925981, 0.010092509, 0.0096333455, 0.010625405, 0.010258949, 0.0100866845, 0.010242092, 0.009933207, 0.011051291, 0.011430089, 0.010185445, 0.010183846, 0.012188481, 0.010962761, 0.010000206, 0.010513818, 0.009720684, 0.011790464, 0.011367909, 0.010471682, 0.010404128, 0.0099814925, 0.010108929, 0.011066712, 0.010528205, 0.010858115, 0.010024661, 0.010307625, 0.010307396, 0.010759082, 0.010792538, 0.009788414, 0.010092644, 0.010437999, 0.010173731, 0.010248165, 0.010119366, 0.010460233, 0.01048915, 0.010428864, 0.010108828, 0.011417849, 0.01038056, 0.010752061, 0.010053091, 0.012113454, 0.0111410925, 0.01076798, 0.010319224, 0.010158318, 0.010060982, 0.010075542, 0.009767245, 0.010058115, 0.01123232, 0.011017308, 0.010202017, 0.009837728, 0.010497566, 0.010570994, 0.010160218, 0.012374558, 0.010616777, 0.010195868, 0.010970425, 0.0100012105, 0.0101522235, 0.010071468, 0.010312201, 0.01052186, 0.010806351, 0.010474876, 0.010743813, 0.010711095, 0.0102656605, 0.011029147, 0.01031433, 0.010558654, 0.010037776, 0.010587377, 0.010490086, 0.010329916, 0.0104390355, 0.010586478]\n",
      "2022-02-22 11:52:30,385 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:30,393 : INFO : topic #0 (0.010): 0.080*\"manag\" + 0.079*\"subset\" + 0.076*\"languag\" + 0.058*\"comput\" + 0.056*\"report\" + 0.047*\":\" + 0.045*\"form\" + 0.040*\",\" + 0.040*\"system\" + 0.039*\"data\"\n",
      "2022-02-22 11:52:30,394 : INFO : topic #18 (0.010): 0.102*\",\" + 0.056*\"algorithm\" + 0.055*\"project\" + 0.049*\"comput\" + 0.039*\"formula\" + 0.037*\"forward\" + 0.030*\"version\" + 0.027*\"previou\" + 0.027*\"relat\" + 0.023*\"statist\"\n",
      "2022-02-22 11:52:30,395 : INFO : topic #61 (0.012): 0.278*\"(\" + 0.258*\")\" + 0.256*\"algorithm\" + 0.060*\"complex\" + 0.055*\"function\" + 0.021*\"minim\" + 0.017*\"real\" + 0.016*\"number\" + 0.012*\"[\" + 0.009*\"block\"\n",
      "2022-02-22 11:52:30,396 : INFO : topic #28 (0.012): 0.273*\"(\" + 0.254*\")\" + 0.110*\"algorithm\" + 0.032*\"interpol\" + 0.020*\"equat\" + 0.020*\"stabil\" + 0.018*\"solut\" + 0.018*\"matrix\" + 0.015*\"-\" + 0.013*\"order\"\n",
      "2022-02-22 11:52:30,397 : INFO : topic #77 (0.012): 0.231*\"[\" + 0.220*\"algorithm\" + 0.198*\"(\" + 0.098*\"])\" + 0.084*\")\" + 0.020*\"-\" + 0.019*\"polynomi\" + 0.013*\"gener\" + 0.011*\"chain\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:52:30,399 : INFO : topic diff=0.676637, rho=0.422502\n",
      "2022-02-22 11:52:30,409 : INFO : PROGRESS: pass 4, at document #2000/3204\n",
      "2022-02-22 11:52:31,290 : INFO : optimized alpha [0.009611374, 0.009779579, 0.010491162, 0.010288186, 0.010543746, 0.010592156, 0.009878033, 0.0110655045, 0.011370316, 0.010122219, 0.009994614, 0.010604363, 0.010247583, 0.009742709, 0.010050666, 0.0098766135, 0.009888894, 0.010266142, 0.009628685, 0.010598338, 0.010393365, 0.010013468, 0.0102369245, 0.009876143, 0.011294061, 0.011468589, 0.010241457, 0.010140928, 0.012401174, 0.011113006, 0.010008227, 0.0105564855, 0.009709885, 0.011838397, 0.01140391, 0.010411873, 0.010385202, 0.0099339625, 0.010073114, 0.011183907, 0.010599594, 0.011042668, 0.010013145, 0.0103208395, 0.0103414925, 0.010863328, 0.010724792, 0.009784267, 0.010173157, 0.010469978, 0.0102596255, 0.0102444235, 0.010092306, 0.010498074, 0.010447533, 0.0104247695, 0.010119949, 0.011516046, 0.010349463, 0.010831468, 0.010034327, 0.012912704, 0.011155889, 0.010759243, 0.01029588, 0.010167872, 0.010035833, 0.010142709, 0.009747754, 0.01005234, 0.011215177, 0.011133046, 0.0101646315, 0.009863065, 0.010641143, 0.010565564, 0.010160501, 0.0129373735, 0.010753156, 0.01017215, 0.010950531, 0.00998612, 0.010279445, 0.010028232, 0.01033496, 0.010640281, 0.010793406, 0.010484697, 0.010847309, 0.010664916, 0.0102461, 0.011008637, 0.010268981, 0.010707535, 0.010099454, 0.010539819, 0.010622856, 0.010335092, 0.010473099, 0.010724436]\n",
      "2022-02-22 11:52:31,296 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:31,302 : INFO : topic #0 (0.010): 0.077*\"languag\" + 0.073*\"subset\" + 0.059*\"comput\" + 0.057*\"report\" + 0.056*\"manag\" + 0.048*\"form\" + 0.046*\"format\" + 0.043*\",\" + 0.040*\":\" + 0.039*\"data\"\n",
      "2022-02-22 11:52:31,304 : INFO : topic #18 (0.010): 0.103*\",\" + 0.051*\"formula\" + 0.051*\"algorithm\" + 0.051*\"comput\" + 0.049*\"project\" + 0.029*\"forward\" + 0.025*\"relat\" + 0.024*\"statist\" + 0.024*\"version\" + 0.019*\"usual\"\n",
      "2022-02-22 11:52:31,305 : INFO : topic #28 (0.012): 0.267*\"(\" + 0.248*\")\" + 0.116*\"algorithm\" + 0.032*\"interpol\" + 0.024*\"matrix\" + 0.020*\"equat\" + 0.019*\"solut\" + 0.017*\"'\" + 0.017*\"invers\" + 0.016*\"stabil\"\n",
      "2022-02-22 11:52:31,306 : INFO : topic #77 (0.013): 0.227*\"[\" + 0.212*\"algorithm\" + 0.200*\"(\" + 0.148*\"])\" + 0.054*\")\" + 0.020*\"polynomi\" + 0.019*\"-\" + 0.012*\"coeffici\" + 0.011*\"gener\" + 0.011*\"s14\"\n",
      "2022-02-22 11:52:31,306 : INFO : topic #61 (0.013): 0.293*\"(\" + 0.278*\")\" + 0.253*\"algorithm\" + 0.048*\"function\" + 0.048*\"complex\" + 0.018*\"real\" + 0.016*\"number\" + 0.015*\"minim\" + 0.007*\"e4\" + 0.007*\"[\"\n",
      "2022-02-22 11:52:31,307 : INFO : topic diff=0.654491, rho=0.389191\n",
      "2022-02-22 11:52:32,297 : INFO : -6.648 per-word bound, 100.3 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:32,298 : INFO : PROGRESS: pass 4, at document #3204/3204\n",
      "2022-02-22 11:52:33,173 : INFO : optimized alpha [0.009653171, 0.009820544, 0.010627672, 0.010427587, 0.010724993, 0.010769105, 0.009902003, 0.011264058, 0.011741597, 0.010201675, 0.01006055, 0.0107508125, 0.010391292, 0.009752737, 0.0101386085, 0.009886451, 0.009944419, 0.010326942, 0.00968585, 0.010797464, 0.010467007, 0.010046025, 0.010355001, 0.010009435, 0.011504085, 0.011823609, 0.010358972, 0.010232212, 0.012585629, 0.011367505, 0.01012398, 0.0107246395, 0.009745482, 0.012344738, 0.011746614, 0.010483888, 0.010567686, 0.010000191, 0.0102302795, 0.011493642, 0.010788575, 0.011303787, 0.010109146, 0.010453315, 0.010463658, 0.011085157, 0.010908052, 0.009847418, 0.01022515, 0.010549513, 0.010408061, 0.010397726, 0.010287173, 0.010767438, 0.010613309, 0.010592915, 0.010215656, 0.0117994035, 0.010451393, 0.011078068, 0.01008014, 0.013652701, 0.01139481, 0.010940584, 0.010454816, 0.010258752, 0.010133658, 0.010195002, 0.009801506, 0.0101423245, 0.011596554, 0.011374763, 0.010278127, 0.009904552, 0.01082983, 0.010789777, 0.010312206, 0.013152849, 0.010861832, 0.010310691, 0.011185425, 0.010046675, 0.010388351, 0.010166122, 0.010468867, 0.010782415, 0.011057166, 0.010673255, 0.011010252, 0.010934398, 0.010306089, 0.011267611, 0.010402951, 0.010821521, 0.010202493, 0.010677393, 0.010771633, 0.010480614, 0.010645401, 0.010893258]\n",
      "2022-02-22 11:52:33,181 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:33,190 : INFO : topic #0 (0.010): 0.076*\"subset\" + 0.074*\"languag\" + 0.074*\"manag\" + 0.063*\"report\" + 0.058*\"comput\" + 0.054*\":\" + 0.048*\"form\" + 0.045*\"system\" + 0.039*\",\" + 0.037*\"format\"\n",
      "2022-02-22 11:52:33,191 : INFO : topic #18 (0.010): 0.109*\",\" + 0.068*\"project\" + 0.054*\"algorithm\" + 0.053*\"comput\" + 0.050*\"formula\" + 0.037*\"forward\" + 0.031*\"version\" + 0.030*\"previou\" + 0.028*\"relat\" + 0.022*\"statist\"\n",
      "2022-02-22 11:52:33,194 : INFO : topic #28 (0.013): 0.274*\"(\" + 0.252*\")\" + 0.100*\"algorithm\" + 0.036*\"interpol\" + 0.022*\"matrix\" + 0.021*\"stabil\" + 0.021*\"equat\" + 0.018*\"solut\" + 0.016*\"'\" + 0.015*\"incomplet\"\n",
      "2022-02-22 11:52:33,200 : INFO : topic #77 (0.013): 0.253*\"[\" + 0.212*\"algorithm\" + 0.197*\"(\" + 0.108*\"])\" + 0.071*\")\" + 0.020*\"-\" + 0.017*\"polynomi\" + 0.011*\"chain\" + 0.011*\"gener\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:52:33,202 : INFO : topic #61 (0.014): 0.297*\"(\" + 0.280*\")\" + 0.262*\"algorithm\" + 0.049*\"complex\" + 0.042*\"function\" + 0.016*\"minim\" + 0.015*\"number\" + 0.013*\"real\" + 0.006*\"e4\" + 0.006*\"[\"\n",
      "2022-02-22 11:52:33,210 : INFO : topic diff=0.716275, rho=0.389191\n",
      "2022-02-22 11:52:33,228 : INFO : PROGRESS: pass 5, at document #2000/3204\n",
      "2022-02-22 11:52:34,682 : INFO : optimized alpha [0.009674446, 0.009777819, 0.010691549, 0.010386473, 0.0107782055, 0.010783571, 0.009861766, 0.011452339, 0.011943304, 0.010252017, 0.010075409, 0.010847263, 0.010383756, 0.00972579, 0.010134452, 0.009959962, 0.009912524, 0.010509939, 0.00968909, 0.0107751, 0.010606976, 0.009983349, 0.010355893, 0.009958024, 0.011748141, 0.011857287, 0.010418821, 0.010202062, 0.012789022, 0.011534276, 0.01014436, 0.010773931, 0.009741575, 0.012410792, 0.011788824, 0.010433031, 0.010554911, 0.009964074, 0.010205694, 0.011632709, 0.010878955, 0.011483079, 0.0101040555, 0.010478717, 0.010504985, 0.011182808, 0.010878446, 0.009862061, 0.0103121605, 0.010583546, 0.010509506, 0.010403206, 0.0102683185, 0.010817222, 0.010579838, 0.010594345, 0.010227997, 0.011904133, 0.010430387, 0.011155833, 0.010065373, 0.014551595, 0.011415682, 0.010933652, 0.010440102, 0.010271559, 0.010112304, 0.010269327, 0.0097894315, 0.010144521, 0.011583403, 0.011493658, 0.010245266, 0.009930514, 0.010975157, 0.010803292, 0.010313881, 0.01369211, 0.010994237, 0.010288262, 0.011171434, 0.010046068, 0.010510235, 0.010132991, 0.010513074, 0.010901712, 0.011053372, 0.010695516, 0.011117371, 0.010895175, 0.010273358, 0.011244528, 0.010368215, 0.010975823, 0.01027706, 0.010632963, 0.01091255, 0.010498376, 0.010684471, 0.011033217]\n",
      "2022-02-22 11:52:34,689 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:34,696 : INFO : topic #0 (0.010): 0.073*\"languag\" + 0.072*\"subset\" + 0.066*\"report\" + 0.058*\"comput\" + 0.055*\"manag\" + 0.051*\"format\" + 0.047*\"form\" + 0.047*\":\" + 0.042*\",\" + 0.041*\"system\"\n",
      "2022-02-22 11:52:34,697 : INFO : topic #13 (0.010): 0.101*\",\" + 0.054*\"program\" + 0.053*\"(\" + 0.036*\")\" + 0.034*\"rule\" + 0.030*\"instruct\" + 0.025*\"\"\" + 0.022*\"-\" + 0.020*\";\" + 0.013*\"comput\"\n",
      "2022-02-22 11:52:34,698 : INFO : topic #28 (0.013): 0.268*\"(\" + 0.247*\")\" + 0.110*\"algorithm\" + 0.035*\"interpol\" + 0.026*\"matrix\" + 0.020*\"'\" + 0.019*\"equat\" + 0.018*\"invers\" + 0.018*\"solut\" + 0.017*\"stabil\"\n",
      "2022-02-22 11:52:34,699 : INFO : topic #77 (0.014): 0.243*\"[\" + 0.208*\"algorithm\" + 0.198*\"(\" + 0.153*\"])\" + 0.045*\")\" + 0.019*\"-\" + 0.017*\"polynomi\" + 0.012*\"coeffici\" + 0.012*\"s14\" + 0.010*\"normal\"\n",
      "2022-02-22 11:52:34,700 : INFO : topic #61 (0.015): 0.306*\"(\" + 0.294*\")\" + 0.257*\"algorithm\" + 0.041*\"complex\" + 0.039*\"function\" + 0.015*\"number\" + 0.014*\"real\" + 0.013*\"minim\" + 0.006*\"e4\" + 0.004*\"[\"\n",
      "2022-02-22 11:52:34,703 : INFO : topic diff=0.652274, rho=0.362690\n",
      "2022-02-22 11:52:35,835 : INFO : -6.605 per-word bound, 97.3 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:35,836 : INFO : PROGRESS: pass 5, at document #3204/3204\n",
      "2022-02-22 11:52:36,710 : INFO : optimized alpha [0.0097228065, 0.009843985, 0.010839318, 0.010511058, 0.010952196, 0.010959699, 0.009891372, 0.01166379, 0.012314602, 0.010342049, 0.010165236, 0.010984653, 0.01050604, 0.009754359, 0.010232766, 0.009975395, 0.009965278, 0.010568916, 0.009760617, 0.0109658325, 0.01067189, 0.0100150835, 0.010473187, 0.01009236, 0.011967708, 0.012198572, 0.010529057, 0.0103003755, 0.012895258, 0.011782735, 0.01026233, 0.010932061, 0.0097874645, 0.012909215, 0.012128936, 0.010516977, 0.010739331, 0.010032849, 0.010372356, 0.011945359, 0.011080509, 0.011758843, 0.0101973135, 0.010596769, 0.010635547, 0.011426556, 0.011047434, 0.009924586, 0.0103730345, 0.010651814, 0.010664789, 0.010556842, 0.010458283, 0.01110205, 0.010726061, 0.010765646, 0.010321068, 0.012162107, 0.010532667, 0.011399333, 0.010102828, 0.01550181, 0.011640973, 0.011094158, 0.0105927, 0.010366281, 0.010216873, 0.010324479, 0.009843242, 0.010238369, 0.011936033, 0.01172578, 0.010367601, 0.009975535, 0.011159653, 0.011041433, 0.010453541, 0.013888336, 0.011109072, 0.010421722, 0.01140316, 0.010103204, 0.0106185675, 0.010284267, 0.010635589, 0.011041714, 0.011316066, 0.010896081, 0.01127391, 0.011169761, 0.010330256, 0.011499278, 0.010494293, 0.011078804, 0.010382838, 0.010775144, 0.01107552, 0.01065737, 0.010859363, 0.011208672]\n",
      "2022-02-22 11:52:36,716 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:36,723 : INFO : topic #13 (0.010): 0.097*\",\" + 0.056*\"(\" + 0.050*\"program\" + 0.045*\"rule\" + 0.036*\")\" + 0.033*\"instruct\" + 0.023*\"\"\" + 0.022*\"-\" + 0.020*\";\" + 0.015*\"student\"\n",
      "2022-02-22 11:52:36,726 : INFO : topic #0 (0.010): 0.074*\"subset\" + 0.070*\"report\" + 0.070*\"languag\" + 0.070*\"manag\" + 0.060*\":\" + 0.058*\"comput\" + 0.049*\"system\" + 0.048*\"form\" + 0.042*\"format\" + 0.039*\",\"\n",
      "2022-02-22 11:52:36,728 : INFO : topic #33 (0.013): 0.168*\"]\" + 0.130*\"solut\" + 0.081*\"equat\" + 0.070*\"problem\" + 0.063*\"comment\" + 0.047*\"approxim\" + 0.044*\"differenti\" + 0.030*\"5\" + 0.027*\"valu\" + 0.024*\"function\"\n",
      "2022-02-22 11:52:36,729 : INFO : topic #77 (0.014): 0.272*\"[\" + 0.208*\"algorithm\" + 0.194*\"(\" + 0.117*\"])\" + 0.055*\")\" + 0.019*\"-\" + 0.015*\"polynomi\" + 0.012*\"s14\" + 0.012*\"chebyshev\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:52:36,733 : INFO : topic #61 (0.016): 0.311*\"(\" + 0.298*\")\" + 0.259*\"algorithm\" + 0.043*\"complex\" + 0.034*\"function\" + 0.014*\"minim\" + 0.013*\"number\" + 0.011*\"real\" + 0.005*\"e4\" + 0.003*\"[\"\n",
      "2022-02-22 11:52:36,735 : INFO : topic diff=0.674072, rho=0.362690\n",
      "2022-02-22 11:52:36,746 : INFO : PROGRESS: pass 6, at document #2000/3204\n",
      "2022-02-22 11:52:37,702 : INFO : optimized alpha [0.009748336, 0.009809636, 0.010933093, 0.010472428, 0.011011498, 0.01097653, 0.009858161, 0.011857769, 0.012520887, 0.010398602, 0.0101863565, 0.011079897, 0.010502451, 0.00973328, 0.010237782, 0.010062506, 0.009934283, 0.010743698, 0.009772328, 0.010953333, 0.010817781, 0.009964623, 0.010481278, 0.010045544, 0.012204395, 0.01223041, 0.010589245, 0.010270513, 0.013039801, 0.011947943, 0.010281474, 0.010983951, 0.009786159, 0.012977637, 0.01218555, 0.010478877, 0.01073921, 0.010011624, 0.010355736, 0.012091771, 0.011177515, 0.011936393, 0.010196181, 0.010627877, 0.010676265, 0.011518636, 0.011045753, 0.009937101, 0.010466302, 0.01068797, 0.010786468, 0.010576153, 0.010445064, 0.011170685, 0.010699877, 0.010781127, 0.010332805, 0.012269314, 0.010514883, 0.011478219, 0.0100968, 0.016547926, 0.0116596045, 0.011089013, 0.010581995, 0.010380264, 0.010207392, 0.010405694, 0.009829074, 0.01024064, 0.011924881, 0.011842299, 0.010349075, 0.010008964, 0.011299936, 0.01106249, 0.010454854, 0.014391942, 0.011227379, 0.010402125, 0.011390595, 0.010106653, 0.010743505, 0.010257938, 0.010686442, 0.011181454, 0.011310811, 0.010921916, 0.011369489, 0.011136526, 0.0103127565, 0.0114757465, 0.010463407, 0.011225752, 0.01046587, 0.010736849, 0.011217371, 0.010670036, 0.010897571, 0.011355272]\n",
      "2022-02-22 11:52:37,708 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:37,715 : INFO : topic #13 (0.010): 0.101*\",\" + 0.056*\"(\" + 0.053*\"program\" + 0.043*\"rule\" + 0.037*\")\" + 0.034*\"instruct\" + 0.022*\"\"\" + 0.021*\"-\" + 0.018*\";\" + 0.013*\"test\"\n",
      "2022-02-22 11:52:37,716 : INFO : topic #1 (0.010): 0.103*\"-\" + 0.050*\",\" + 0.046*\"case\" + 0.023*\"number\" + 0.022*\"(\" + 0.021*\"decreas\" + 0.020*\"convert\" + 0.019*\"larg\" + 0.018*\"time\" + 0.018*\"1\"\n",
      "2022-02-22 11:52:37,717 : INFO : topic #28 (0.013): 0.257*\"(\" + 0.237*\")\" + 0.113*\"algorithm\" + 0.039*\"interpol\" + 0.031*\"matrix\" + 0.025*\"'\" + 0.022*\"polynomi\" + 0.019*\"invers\" + 0.019*\"stabil\" + 0.018*\"incomplet\"\n",
      "2022-02-22 11:52:37,718 : INFO : topic #77 (0.014): 0.258*\"[\" + 0.206*\"algorithm\" + 0.197*\"(\" + 0.159*\"])\" + 0.034*\")\" + 0.018*\"-\" + 0.015*\"polynomi\" + 0.013*\"s14\" + 0.012*\"coeffici\" + 0.012*\"chebyshev\"\n",
      "2022-02-22 11:52:37,719 : INFO : topic #61 (0.017): 0.320*\"(\" + 0.308*\")\" + 0.252*\"algorithm\" + 0.037*\"complex\" + 0.031*\"function\" + 0.013*\"number\" + 0.011*\"real\" + 0.011*\"minim\" + 0.006*\"e4\" + 0.002*\"[\"\n",
      "2022-02-22 11:52:37,720 : INFO : topic diff=0.594478, rho=0.340958\n",
      "2022-02-22 11:52:38,848 : INFO : -6.574 per-word bound, 95.3 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:38,848 : INFO : PROGRESS: pass 6, at document #3204/3204\n",
      "2022-02-22 11:52:39,732 : INFO : optimized alpha [0.009805439, 0.009881165, 0.011079484, 0.010602429, 0.0111798905, 0.011146877, 0.009889829, 0.012099599, 0.012908825, 0.010480888, 0.010286033, 0.011213185, 0.010621131, 0.009763986, 0.010339745, 0.010079812, 0.009987627, 0.010801561, 0.009848479, 0.011140795, 0.010887567, 0.0099985525, 0.010589357, 0.010178691, 0.012420616, 0.012554071, 0.0107084615, 0.010372623, 0.0131281195, 0.012199104, 0.010396226, 0.01113392, 0.009832858, 0.013482628, 0.012515203, 0.010576636, 0.010914295, 0.010082845, 0.010534799, 0.01238874, 0.011366464, 0.012214372, 0.010273053, 0.01075469, 0.01079694, 0.011748294, 0.011228237, 0.010007952, 0.010526501, 0.010752588, 0.010940056, 0.010728042, 0.010643486, 0.011469294, 0.010844945, 0.010962571, 0.010423917, 0.012508515, 0.010627113, 0.011694376, 0.0101444395, 0.017634433, 0.0118706, 0.011247579, 0.010729709, 0.010478928, 0.010321232, 0.010460645, 0.009886021, 0.010332608, 0.01227989, 0.01207729, 0.010468107, 0.010060229, 0.011481672, 0.011314913, 0.0105873225, 0.014570943, 0.011345387, 0.010525693, 0.011620833, 0.010166815, 0.010873264, 0.010398489, 0.010802445, 0.011333135, 0.011574359, 0.01110343, 0.011520984, 0.01140167, 0.010367019, 0.011714894, 0.010594935, 0.011316213, 0.010574698, 0.010856196, 0.01138493, 0.0108209355, 0.011060476, 0.011528376]\n",
      "2022-02-22 11:52:39,738 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:39,746 : INFO : topic #32 (0.010): 0.120*\"grammar\" + 0.064*\"free\" + 0.053*\"-\" + 0.038*\"context\" + 0.037*\"pars\" + 0.036*\"sentenc\" + 0.028*\",\" + 0.024*\"gener\" + 0.022*\"languag\" + 0.021*\"natur\"\n",
      "2022-02-22 11:52:39,747 : INFO : topic #13 (0.010): 0.098*\",\" + 0.058*\"(\" + 0.052*\"rule\" + 0.051*\"program\" + 0.036*\")\" + 0.034*\"instruct\" + 0.022*\"-\" + 0.020*\"\"\" + 0.018*\"test\" + 0.017*\";\"\n",
      "2022-02-22 11:52:39,750 : INFO : topic #33 (0.013): 0.164*\"]\" + 0.144*\"solut\" + 0.087*\"equat\" + 0.075*\"problem\" + 0.063*\"comment\" + 0.046*\"differenti\" + 0.045*\"approxim\" + 0.029*\"5\" + 0.026*\"valu\" + 0.024*\",\"\n",
      "2022-02-22 11:52:39,751 : INFO : topic #77 (0.015): 0.289*\"[\" + 0.204*\"algorithm\" + 0.192*\"(\" + 0.126*\"])\" + 0.041*\")\" + 0.019*\"-\" + 0.014*\"chebyshev\" + 0.013*\"polynomi\" + 0.013*\"s14\" + 0.012*\"coeffici\"\n",
      "2022-02-22 11:52:39,752 : INFO : topic #61 (0.018): 0.323*\"(\" + 0.310*\")\" + 0.253*\"algorithm\" + 0.039*\"complex\" + 0.027*\"function\" + 0.012*\"number\" + 0.012*\"minim\" + 0.009*\"real\" + 0.005*\"e4\" + 0.001*\"[\"\n",
      "2022-02-22 11:52:39,753 : INFO : topic diff=0.599503, rho=0.340958\n",
      "2022-02-22 11:52:39,762 : INFO : PROGRESS: pass 7, at document #2000/3204\n",
      "2022-02-22 11:52:40,906 : INFO : optimized alpha [0.009839515, 0.009845862, 0.011187119, 0.010565737, 0.01123971, 0.011167788, 0.009857765, 0.012311907, 0.013118528, 0.010540038, 0.010304448, 0.011309525, 0.010615895, 0.009746481, 0.010359766, 0.0101746265, 0.009965497, 0.010983433, 0.009872604, 0.011129993, 0.0110344095, 0.009952024, 0.010607462, 0.010132485, 0.012659563, 0.012588601, 0.010776076, 0.010349608, 0.013242381, 0.012369671, 0.010419366, 0.011193954, 0.009833692, 0.0135558285, 0.012573526, 0.010542532, 0.010911858, 0.010069797, 0.010525192, 0.012538712, 0.01147196, 0.012385214, 0.010270616, 0.010789339, 0.01084258, 0.011851064, 0.011235458, 0.010029883, 0.010619027, 0.01078372, 0.011063672, 0.010754799, 0.010636883, 0.011541245, 0.010823371, 0.010978489, 0.010433489, 0.012614699, 0.010620749, 0.011769136, 0.010150844, 0.018776324, 0.011887419, 0.011244068, 0.0107244635, 0.010499171, 0.010323965, 0.010545049, 0.00987312, 0.010343333, 0.0122645125, 0.01218638, 0.010459012, 0.010095563, 0.01161794, 0.011342958, 0.0105901025, 0.015066773, 0.01146584, 0.010505346, 0.011611338, 0.010173715, 0.010999996, 0.010380011, 0.010859673, 0.011478231, 0.01157152, 0.0111328345, 0.011615825, 0.011377611, 0.010351133, 0.011691098, 0.010562058, 0.0114552695, 0.010662577, 0.010828774, 0.011530144, 0.010830779, 0.011099959, 0.011668987]\n",
      "2022-02-22 11:52:40,912 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:40,927 : INFO : topic #13 (0.010): 0.102*\",\" + 0.058*\"(\" + 0.055*\"program\" + 0.051*\"rule\" + 0.036*\")\" + 0.035*\"instruct\" + 0.021*\"-\" + 0.020*\"\"\" + 0.017*\"test\" + 0.015*\";\"\n",
      "2022-02-22 11:52:40,928 : INFO : topic #32 (0.010): 0.118*\"grammar\" + 0.063*\"free\" + 0.052*\"-\" + 0.044*\"sentenc\" + 0.036*\"context\" + 0.035*\"pars\" + 0.028*\",\" + 0.025*\"gener\" + 0.022*\"procedur\" + 0.021*\"languag\"\n",
      "2022-02-22 11:52:40,929 : INFO : topic #33 (0.014): 0.152*\"solut\" + 0.133*\"]\" + 0.091*\"equat\" + 0.076*\"problem\" + 0.060*\"comment\" + 0.050*\"differenti\" + 0.045*\"approxim\" + 0.026*\"5\" + 0.025*\",\" + 0.025*\"valu\"\n",
      "2022-02-22 11:52:40,934 : INFO : topic #77 (0.015): 0.269*\"[\" + 0.204*\"algorithm\" + 0.196*\"(\" + 0.163*\"])\" + 0.026*\")\" + 0.018*\"-\" + 0.014*\"chebyshev\" + 0.014*\"s14\" + 0.013*\"polynomi\" + 0.012*\"coeffici\"\n",
      "2022-02-22 11:52:40,936 : INFO : topic #61 (0.019): 0.330*\"(\" + 0.318*\")\" + 0.247*\"algorithm\" + 0.034*\"complex\" + 0.026*\"function\" + 0.012*\"number\" + 0.010*\"minim\" + 0.009*\"real\" + 0.005*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:40,938 : INFO : topic diff=0.521810, rho=0.322715\n",
      "2022-02-22 11:52:42,249 : INFO : -6.551 per-word bound, 93.8 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:42,249 : INFO : PROGRESS: pass 7, at document #3204/3204\n",
      "2022-02-22 11:52:43,138 : INFO : optimized alpha [0.009888742, 0.009927679, 0.011326992, 0.010689836, 0.011400536, 0.011330665, 0.009896724, 0.012534601, 0.013532006, 0.010629777, 0.010408054, 0.011442741, 0.010743406, 0.00977904, 0.010468359, 0.010199142, 0.010022219, 0.011037552, 0.009953216, 0.011300155, 0.011100132, 0.00999338, 0.010713479, 0.010273222, 0.012884015, 0.012903878, 0.01089269, 0.010455344, 0.013300694, 0.012618035, 0.010537338, 0.011349344, 0.009886593, 0.014051552, 0.012894751, 0.01063885, 0.011085045, 0.010143477, 0.010707971, 0.01283201, 0.011662406, 0.012663519, 0.010346813, 0.01091906, 0.010948816, 0.012084534, 0.01142836, 0.010102927, 0.010684726, 0.010842514, 0.011234296, 0.010905725, 0.010838367, 0.0118699, 0.010973623, 0.011158093, 0.010520459, 0.012858102, 0.010736553, 0.011973085, 0.010202098, 0.019994427, 0.012086176, 0.011395526, 0.010879929, 0.010599005, 0.010421425, 0.010602877, 0.0099356575, 0.01043116, 0.012600219, 0.012422034, 0.01056984, 0.010144523, 0.011788698, 0.011607263, 0.010716601, 0.01523437, 0.01156886, 0.010620499, 0.011847518, 0.01024503, 0.011126714, 0.010522764, 0.010979109, 0.011650684, 0.011830837, 0.011312754, 0.0117636025, 0.011641482, 0.010400481, 0.011926474, 0.010699009, 0.011553202, 0.01076055, 0.0109398, 0.0116934795, 0.010986554, 0.011252532, 0.011840775]\n",
      "2022-02-22 11:52:43,143 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:43,156 : INFO : topic #13 (0.010): 0.099*\",\" + 0.059*\"(\" + 0.059*\"rule\" + 0.053*\"program\" + 0.036*\"instruct\" + 0.035*\")\" + 0.023*\"-\" + 0.022*\"test\" + 0.017*\"\"\" + 0.014*\"execut\"\n",
      "2022-02-22 11:52:43,158 : INFO : topic #0 (0.010): 0.081*\"report\" + 0.072*\"subset\" + 0.067*\":\" + 0.066*\"languag\" + 0.066*\"manag\" + 0.060*\"system\" + 0.056*\"comput\" + 0.048*\"form\" + 0.046*\"format\" + 0.037*\",\"\n",
      "2022-02-22 11:52:43,159 : INFO : topic #33 (0.014): 0.162*\"]\" + 0.155*\"solut\" + 0.095*\"equat\" + 0.078*\"problem\" + 0.063*\"comment\" + 0.048*\"differenti\" + 0.042*\"approxim\" + 0.028*\"5\" + 0.024*\",\" + 0.023*\"valu\"\n",
      "2022-02-22 11:52:43,161 : INFO : topic #77 (0.015): 0.300*\"[\" + 0.204*\"algorithm\" + 0.189*\"(\" + 0.132*\"])\" + 0.030*\")\" + 0.018*\"-\" + 0.016*\"chebyshev\" + 0.014*\"s14\" + 0.012*\"polynomi\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:52:43,164 : INFO : topic #61 (0.020): 0.333*\"(\" + 0.319*\")\" + 0.248*\"algorithm\" + 0.036*\"complex\" + 0.024*\"function\" + 0.011*\"minim\" + 0.011*\"number\" + 0.007*\"real\" + 0.004*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:43,167 : INFO : topic diff=0.521345, rho=0.322715\n",
      "2022-02-22 11:52:43,175 : INFO : PROGRESS: pass 8, at document #2000/3204\n",
      "2022-02-22 11:52:44,187 : INFO : optimized alpha [0.00992012, 0.0099006165, 0.011433959, 0.010654794, 0.011462863, 0.011357213, 0.009868513, 0.012759781, 0.013743997, 0.010691381, 0.010433703, 0.011533494, 0.010738223, 0.0097736055, 0.010502137, 0.010293486, 0.010006361, 0.011206474, 0.009982508, 0.011292882, 0.011245058, 0.00995476, 0.010735762, 0.010233653, 0.01312017, 0.012939231, 0.010964163, 0.010435119, 0.013412494, 0.012780901, 0.010557747, 0.011425999, 0.009892434, 0.014129861, 0.0129432175, 0.010606643, 0.011087239, 0.010132965, 0.010696418, 0.012988205, 0.0117690405, 0.012832505, 0.0103432285, 0.010952005, 0.010990778, 0.012180966, 0.01144173, 0.010122509, 0.0107736895, 0.010872683, 0.011374084, 0.010925959, 0.010841177, 0.011946986, 0.010957888, 0.0111762555, 0.01053303, 0.012951655, 0.010735487, 0.012044368, 0.01020552, 0.021230202, 0.012103393, 0.011391882, 0.010877867, 0.0106249545, 0.010430641, 0.01068894, 0.009925279, 0.0104432395, 0.01258693, 0.012536121, 0.010567762, 0.010187918, 0.011919894, 0.011640128, 0.0107174525, 0.015719073, 0.011682902, 0.010597748, 0.011846399, 0.010256676, 0.011248809, 0.01050482, 0.011039104, 0.011806801, 0.011830238, 0.011340408, 0.011858209, 0.011618759, 0.010395564, 0.011902449, 0.010680626, 0.011690662, 0.010849929, 0.010922307, 0.01184443, 0.011002361, 0.0112917395, 0.011978144]\n",
      "2022-02-22 11:52:44,193 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:44,203 : INFO : topic #13 (0.010): 0.102*\",\" + 0.060*\"rule\" + 0.058*\"(\" + 0.056*\"program\" + 0.038*\"instruct\" + 0.035*\")\" + 0.022*\"-\" + 0.020*\"test\" + 0.017*\"\"\" + 0.014*\"execut\"\n",
      "2022-02-22 11:52:44,207 : INFO : topic #6 (0.010): 0.113*\",\" + 0.085*\"system\" + 0.048*\"-\" + 0.038*\"teach\" + 0.034*\"student\" + 0.030*\"oper\" + 0.030*\"rout\" + 0.027*\"comput\" + 0.026*\"criteria\" + 0.023*\"conflict\"\n",
      "2022-02-22 11:52:44,209 : INFO : topic #33 (0.014): 0.164*\"solut\" + 0.133*\"]\" + 0.100*\"equat\" + 0.081*\"problem\" + 0.060*\"comment\" + 0.051*\"differenti\" + 0.043*\"approxim\" + 0.026*\",\" + 0.026*\"5\" + 0.024*\"continu\"\n",
      "2022-02-22 11:52:44,210 : INFO : topic #77 (0.016): 0.276*\"[\" + 0.204*\"algorithm\" + 0.194*\"(\" + 0.166*\"])\" + 0.019*\")\" + 0.018*\"-\" + 0.016*\"chebyshev\" + 0.015*\"s14\" + 0.013*\"polynomi\" + 0.012*\"coeffici\"\n",
      "2022-02-22 11:52:44,213 : INFO : topic #61 (0.021): 0.338*\"(\" + 0.324*\")\" + 0.242*\"algorithm\" + 0.033*\"complex\" + 0.023*\"function\" + 0.011*\"number\" + 0.009*\"minim\" + 0.008*\"real\" + 0.005*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:44,215 : INFO : topic diff=0.451493, rho=0.307119\n",
      "2022-02-22 11:52:45,419 : INFO : -6.530 per-word bound, 92.4 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:45,420 : INFO : PROGRESS: pass 8, at document #3204/3204\n",
      "2022-02-22 11:52:46,344 : INFO : optimized alpha [0.009969923, 0.00998691, 0.011571009, 0.010779245, 0.011632151, 0.011519464, 0.009906431, 0.012987678, 0.014149193, 0.010777306, 0.010546636, 0.011667037, 0.0108633535, 0.009810389, 0.010614421, 0.010322042, 0.010063587, 0.01125454, 0.01007261, 0.011462186, 0.011313028, 0.009987307, 0.010842962, 0.010371355, 0.0133500425, 0.013244337, 0.011075911, 0.010547442, 0.013446783, 0.0130175995, 0.010670904, 0.011581238, 0.00994596, 0.014621849, 0.013250873, 0.010707301, 0.0112592485, 0.01020902, 0.0108805215, 0.0132793, 0.011958606, 0.0131252585, 0.010416347, 0.011093376, 0.011098276, 0.012403359, 0.011668922, 0.010205652, 0.010839146, 0.010931937, 0.0115470085, 0.011079442, 0.011043588, 0.0122792935, 0.011096563, 0.011348875, 0.010619128, 0.013189676, 0.010843935, 0.012237576, 0.010254991, 0.022543095, 0.012306793, 0.011540185, 0.011027112, 0.010720711, 0.010540359, 0.010746858, 0.009982824, 0.0105328625, 0.012911909, 0.012766948, 0.010674087, 0.010240032, 0.012083959, 0.011910923, 0.0108333295, 0.015884446, 0.0117812455, 0.010708188, 0.012073945, 0.010327676, 0.011384677, 0.010647314, 0.011144971, 0.011994009, 0.012086549, 0.011522371, 0.011999969, 0.011870377, 0.010445925, 0.012122779, 0.010823138, 0.011784088, 0.01094645, 0.011037279, 0.012013493, 0.011149177, 0.011440985, 0.012143228]\n",
      "2022-02-22 11:52:46,353 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:46,360 : INFO : topic #13 (0.010): 0.101*\",\" + 0.065*\"rule\" + 0.059*\"(\" + 0.054*\"program\" + 0.038*\"instruct\" + 0.034*\")\" + 0.025*\"test\" + 0.023*\"-\" + 0.016*\"execut\" + 0.015*\").\"\n",
      "2022-02-22 11:52:46,361 : INFO : topic #6 (0.010): 0.111*\",\" + 0.085*\"system\" + 0.049*\"-\" + 0.039*\"teach\" + 0.037*\"student\" + 0.034*\"rout\" + 0.030*\"oper\" + 0.027*\"conflict\" + 0.027*\"criteria\" + 0.026*\"comput\"\n",
      "2022-02-22 11:52:46,361 : INFO : topic #33 (0.015): 0.165*\"solut\" + 0.159*\"]\" + 0.104*\"equat\" + 0.082*\"problem\" + 0.063*\"comment\" + 0.049*\"differenti\" + 0.040*\"approxim\" + 0.028*\"5\" + 0.024*\",\" + 0.023*\"continu\"\n",
      "2022-02-22 11:52:46,362 : INFO : topic #77 (0.016): 0.307*\"[\" + 0.206*\"algorithm\" + 0.187*\"(\" + 0.136*\"])\" + 0.021*\")\" + 0.018*\"-\" + 0.018*\"chebyshev\" + 0.015*\"s14\" + 0.012*\"polynomi\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:52:46,363 : INFO : topic #61 (0.023): 0.341*\"(\" + 0.326*\")\" + 0.241*\"algorithm\" + 0.035*\"complex\" + 0.021*\"function\" + 0.010*\"minim\" + 0.010*\"number\" + 0.006*\"real\" + 0.004*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:46,364 : INFO : topic diff=0.451393, rho=0.307119\n",
      "2022-02-22 11:52:46,373 : INFO : PROGRESS: pass 9, at document #2000/3204\n",
      "2022-02-22 11:52:47,352 : INFO : optimized alpha [0.010006267, 0.009962707, 0.011688047, 0.010747259, 0.011684962, 0.011546238, 0.0098772235, 0.013222665, 0.014361772, 0.010841505, 0.010572771, 0.011766609, 0.010863025, 0.009808659, 0.010651478, 0.010428452, 0.010056298, 0.011419876, 0.010103807, 0.01145811, 0.011449935, 0.009955788, 0.010865996, 0.010342437, 0.013590207, 0.013280712, 0.011149637, 0.010532762, 0.013548657, 0.013185078, 0.010688788, 0.011668789, 0.009954858, 0.0146989925, 0.01329602, 0.010679835, 0.011262393, 0.010205247, 0.010875159, 0.013430462, 0.012065057, 0.0132892, 0.010416258, 0.011126441, 0.01114186, 0.012505223, 0.011687856, 0.010226108, 0.010937725, 0.010966077, 0.01169109, 0.0111067975, 0.011045532, 0.012363447, 0.011087804, 0.011369206, 0.010626609, 0.01328336, 0.010844548, 0.012309354, 0.010261733, 0.02386672, 0.012326148, 0.011536393, 0.011021532, 0.01075524, 0.010555368, 0.010837899, 0.009974773, 0.010541465, 0.012896985, 0.012872994, 0.01067684, 0.010285055, 0.0122125475, 0.011950226, 0.010834082, 0.0163593, 0.011887971, 0.010686416, 0.012084335, 0.01034369, 0.011502827, 0.010640831, 0.011196143, 0.0121578, 0.01208819, 0.011548427, 0.012089318, 0.011859371, 0.010443255, 0.012096827, 0.010802087, 0.011915297, 0.011037534, 0.01102058, 0.012170491, 0.011169016, 0.011476658, 0.0122761065]\n",
      "2022-02-22 11:52:47,357 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:47,367 : INFO : topic #13 (0.010): 0.104*\",\" + 0.066*\"rule\" + 0.058*\"program\" + 0.058*\"(\" + 0.040*\"instruct\" + 0.034*\")\" + 0.023*\"test\" + 0.022*\"-\" + 0.016*\"execut\" + 0.014*\"\"\"\n",
      "2022-02-22 11:52:47,371 : INFO : topic #6 (0.010): 0.113*\",\" + 0.087*\"system\" + 0.049*\"-\" + 0.039*\"teach\" + 0.036*\"student\" + 0.031*\"oper\" + 0.030*\"rout\" + 0.028*\"criteria\" + 0.026*\"comput\" + 0.024*\"conflict\"\n",
      "2022-02-22 11:52:47,372 : INFO : topic #33 (0.015): 0.172*\"solut\" + 0.132*\"]\" + 0.110*\"equat\" + 0.083*\"problem\" + 0.060*\"comment\" + 0.052*\"differenti\" + 0.041*\"approxim\" + 0.027*\",\" + 0.025*\"5\" + 0.024*\"continu\"\n",
      "2022-02-22 11:52:47,373 : INFO : topic #77 (0.016): 0.281*\"[\" + 0.206*\"algorithm\" + 0.193*\"(\" + 0.167*\"])\" + 0.017*\"-\" + 0.017*\"chebyshev\" + 0.016*\"s14\" + 0.013*\")\" + 0.012*\"polynomi\" + 0.012*\"coeffici\"\n",
      "2022-02-22 11:52:47,379 : INFO : topic #61 (0.024): 0.344*\"(\" + 0.330*\")\" + 0.238*\"algorithm\" + 0.032*\"complex\" + 0.021*\"function\" + 0.010*\"number\" + 0.009*\"minim\" + 0.007*\"real\" + 0.005*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:47,380 : INFO : topic diff=0.390578, rho=0.293585\n",
      "2022-02-22 11:52:48,436 : INFO : -6.513 per-word bound, 91.4 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:48,436 : INFO : PROGRESS: pass 9, at document #3204/3204\n",
      "2022-02-22 11:52:49,329 : INFO : optimized alpha [0.0100616235, 0.010055816, 0.011825876, 0.010867166, 0.011851367, 0.011708444, 0.009916731, 0.013450169, 0.014766641, 0.0109215025, 0.010689463, 0.011878061, 0.010986237, 0.0098565435, 0.010775471, 0.010473562, 0.010121569, 0.011468068, 0.01018566, 0.011615884, 0.011523009, 0.010002436, 0.010969246, 0.010482883, 0.013812826, 0.013589893, 0.011259943, 0.010646259, 0.013581447, 0.013414715, 0.0107977865, 0.011827275, 0.010006554, 0.015181501, 0.013594849, 0.010776887, 0.011428407, 0.010278604, 0.011061162, 0.013716957, 0.012251595, 0.013581021, 0.0104919365, 0.011268309, 0.011242569, 0.012739196, 0.011919811, 0.010301215, 0.0110191135, 0.011015088, 0.011869794, 0.011254984, 0.01124952, 0.012712377, 0.011221419, 0.011541599, 0.010709655, 0.013503824, 0.01095981, 0.01250505, 0.010312079, 0.025240595, 0.012525753, 0.011679431, 0.011173665, 0.0108474605, 0.010655942, 0.010896088, 0.0100328615, 0.010627868, 0.013222377, 0.013102941, 0.010776695, 0.0103352545, 0.012376696, 0.012228242, 0.0109458, 0.01651103, 0.0119910315, 0.010798157, 0.012316419, 0.010419773, 0.011639461, 0.010786201, 0.01132022, 0.01236283, 0.012339708, 0.01171862, 0.012216946, 0.012117865, 0.010492039, 0.01231866, 0.010944911, 0.012010597, 0.0111275865, 0.011123342, 0.0123398425, 0.011327137, 0.011623378, 0.012432288]\n",
      "2022-02-22 11:52:49,335 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:49,341 : INFO : topic #13 (0.010): 0.102*\",\" + 0.070*\"rule\" + 0.059*\"(\" + 0.057*\"program\" + 0.039*\"instruct\" + 0.034*\")\" + 0.029*\"test\" + 0.023*\"-\" + 0.017*\"execut\" + 0.015*\").\"\n",
      "2022-02-22 11:52:49,342 : INFO : topic #6 (0.010): 0.111*\",\" + 0.088*\"system\" + 0.049*\"-\" + 0.040*\"teach\" + 0.039*\"student\" + 0.035*\"rout\" + 0.030*\"oper\" + 0.028*\"criteria\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:52:49,343 : INFO : topic #33 (0.015): 0.174*\"solut\" + 0.158*\"]\" + 0.111*\"equat\" + 0.085*\"problem\" + 0.062*\"comment\" + 0.049*\"differenti\" + 0.038*\"approxim\" + 0.027*\"5\" + 0.025*\",\" + 0.024*\"continu\"\n",
      "2022-02-22 11:52:49,343 : INFO : topic #77 (0.017): 0.312*\"[\" + 0.206*\"algorithm\" + 0.186*\"(\" + 0.140*\"])\" + 0.019*\"chebyshev\" + 0.018*\"-\" + 0.016*\"s14\" + 0.014*\")\" + 0.011*\"coeffici\" + 0.011*\"normal\"\n",
      "2022-02-22 11:52:49,344 : INFO : topic #61 (0.025): 0.346*\"(\" + 0.330*\")\" + 0.237*\"algorithm\" + 0.034*\"complex\" + 0.020*\"function\" + 0.009*\"minim\" + 0.009*\"number\" + 0.005*\"real\" + 0.004*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:49,345 : INFO : topic diff=0.393010, rho=0.293585\n",
      "2022-02-22 11:52:49,355 : INFO : PROGRESS: pass 10, at document #2000/3204\n",
      "2022-02-22 11:52:50,284 : INFO : optimized alpha [0.010099686, 0.010038337, 0.011947769, 0.010837904, 0.011907202, 0.011738869, 0.009895027, 0.01370089, 0.01496807, 0.010994438, 0.010714567, 0.011981184, 0.01099047, 0.009862306, 0.010817308, 0.01060041, 0.0101206545, 0.011633596, 0.010215828, 0.011616526, 0.01166071, 0.009977092, 0.010985172, 0.010454787, 0.014043853, 0.013627315, 0.011328049, 0.010632091, 0.013686164, 0.013581394, 0.010816533, 0.011925396, 0.010016893, 0.015262072, 0.01362938, 0.010746, 0.011430912, 0.010284034, 0.011055307, 0.013863583, 0.012358183, 0.013736475, 0.010495059, 0.011299958, 0.011291038, 0.01283579, 0.011944093, 0.010326909, 0.011105397, 0.011051489, 0.012021665, 0.011281105, 0.011253799, 0.012796456, 0.01121447, 0.01156242, 0.010718561, 0.013590093, 0.010965029, 0.0125740385, 0.010327822, 0.026604928, 0.012540183, 0.011675533, 0.011169567, 0.010885479, 0.010665949, 0.010984309, 0.01002551, 0.010639292, 0.013209568, 0.013210818, 0.01077944, 0.010381839, 0.012503107, 0.01226857, 0.010946508, 0.016979124, 0.012092798, 0.010780292, 0.0123288985, 0.010441183, 0.0117556425, 0.010778119, 0.011388854, 0.012538289, 0.012343674, 0.011751685, 0.012303225, 0.012119558, 0.01049601, 0.012292594, 0.010927488, 0.012136206, 0.01121893, 0.01110738, 0.012497875, 0.011345868, 0.011657542, 0.012557685]\n",
      "2022-02-22 11:52:50,291 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:50,303 : INFO : topic #13 (0.010): 0.105*\",\" + 0.071*\"rule\" + 0.060*\"program\" + 0.058*\"(\" + 0.041*\"instruct\" + 0.033*\")\" + 0.027*\"test\" + 0.022*\"-\" + 0.017*\"execut\" + 0.014*\").\"\n",
      "2022-02-22 11:52:50,304 : INFO : topic #6 (0.010): 0.113*\",\" + 0.089*\"system\" + 0.050*\"-\" + 0.039*\"teach\" + 0.038*\"student\" + 0.032*\"oper\" + 0.031*\"rout\" + 0.029*\"criteria\" + 0.026*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:52:50,305 : INFO : topic #33 (0.015): 0.181*\"solut\" + 0.131*\"]\" + 0.118*\"equat\" + 0.086*\"problem\" + 0.059*\"comment\" + 0.052*\"differenti\" + 0.039*\"approxim\" + 0.027*\",\" + 0.025*\"continu\" + 0.024*\"5\"\n",
      "2022-02-22 11:52:50,306 : INFO : topic #77 (0.017): 0.285*\"[\" + 0.206*\"algorithm\" + 0.192*\"(\" + 0.169*\"])\" + 0.018*\"chebyshev\" + 0.017*\"-\" + 0.016*\"s14\" + 0.012*\"polynomi\" + 0.012*\"coeffici\" + 0.011*\"normal\"\n",
      "2022-02-22 11:52:50,306 : INFO : topic #61 (0.027): 0.348*\"(\" + 0.334*\")\" + 0.234*\"algorithm\" + 0.031*\"complex\" + 0.019*\"function\" + 0.009*\"number\" + 0.008*\"minim\" + 0.006*\"real\" + 0.005*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:50,307 : INFO : topic diff=0.340231, rho=0.281696\n",
      "2022-02-22 11:52:51,348 : INFO : -6.500 per-word bound, 90.5 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:51,349 : INFO : PROGRESS: pass 10, at document #3204/3204\n",
      "2022-02-22 11:52:52,147 : INFO : optimized alpha [0.010158007, 0.010137904, 0.012086772, 0.010956419, 0.012073979, 0.011904227, 0.00994533, 0.013925289, 0.015366378, 0.011079355, 0.010827536, 0.012088625, 0.011109587, 0.009915737, 0.010942486, 0.010640988, 0.010193463, 0.011682014, 0.010302186, 0.011763786, 0.011725306, 0.010022601, 0.011087588, 0.010600581, 0.014263295, 0.01391583, 0.011439923, 0.01074694, 0.013704589, 0.013814155, 0.010916756, 0.0120819155, 0.010069394, 0.015743427, 0.013913822, 0.010839921, 0.011588927, 0.010362349, 0.011233224, 0.014143014, 0.0125422785, 0.014014964, 0.010573263, 0.011439953, 0.011380439, 0.01307263, 0.012184079, 0.010411688, 0.011186431, 0.011104227, 0.01220934, 0.0114167575, 0.011457259, 0.013159756, 0.011346443, 0.011732299, 0.010803922, 0.013810644, 0.011081723, 0.012769675, 0.01038396, 0.028033258, 0.012739641, 0.011819414, 0.011324797, 0.010972028, 0.010768312, 0.011042841, 0.010081822, 0.010722862, 0.0135204205, 0.013434468, 0.010868303, 0.0104303155, 0.012659053, 0.012554576, 0.011057206, 0.01712203, 0.012195, 0.010883257, 0.012551406, 0.0105172675, 0.01189882, 0.01092404, 0.011506213, 0.012752625, 0.012594036, 0.011922319, 0.0124206375, 0.012379846, 0.010548392, 0.012498977, 0.011073587, 0.012227897, 0.011310958, 0.011206798, 0.0126621025, 0.011498953, 0.011799495, 0.012714585]\n",
      "2022-02-22 11:52:52,154 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:52,161 : INFO : topic #13 (0.010): 0.102*\",\" + 0.077*\"rule\" + 0.059*\"program\" + 0.059*\"(\" + 0.039*\"instruct\" + 0.034*\"test\" + 0.033*\")\" + 0.023*\"-\" + 0.019*\"execut\" + 0.015*\").\"\n",
      "2022-02-22 11:52:52,163 : INFO : topic #6 (0.010): 0.111*\",\" + 0.091*\"system\" + 0.050*\"-\" + 0.041*\"student\" + 0.040*\"teach\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.029*\"criteria\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:52:52,166 : INFO : topic #33 (0.016): 0.183*\"solut\" + 0.156*\"]\" + 0.116*\"equat\" + 0.088*\"problem\" + 0.062*\"comment\" + 0.050*\"differenti\" + 0.037*\"approxim\" + 0.026*\",\" + 0.025*\"5\" + 0.023*\"continu\"\n",
      "2022-02-22 11:52:52,170 : INFO : topic #77 (0.017): 0.314*\"[\" + 0.207*\"algorithm\" + 0.185*\"(\" + 0.142*\"])\" + 0.019*\"chebyshev\" + 0.017*\"-\" + 0.017*\"s14\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"polynomi\"\n",
      "2022-02-22 11:52:52,171 : INFO : topic #61 (0.028): 0.351*\"(\" + 0.335*\")\" + 0.232*\"algorithm\" + 0.032*\"complex\" + 0.018*\"function\" + 0.009*\"minim\" + 0.009*\"number\" + 0.005*\"real\" + 0.004*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:52,174 : INFO : topic diff=0.344927, rho=0.281696\n",
      "2022-02-22 11:52:52,184 : INFO : PROGRESS: pass 11, at document #2000/3204\n",
      "2022-02-22 11:52:53,161 : INFO : optimized alpha [0.010197801, 0.010119697, 0.012202188, 0.010925133, 0.012129409, 0.011936521, 0.009924895, 0.014188531, 0.015546428, 0.011144151, 0.010854736, 0.01218551, 0.011110583, 0.009928348, 0.01098444, 0.010777644, 0.010194212, 0.01183872, 0.010335633, 0.0117721455, 0.0118609555, 0.009998825, 0.011104567, 0.010576026, 0.014481904, 0.013952639, 0.011513654, 0.010734691, 0.013808306, 0.0139766885, 0.010936414, 0.0121822115, 0.010082423, 0.015825517, 0.013951551, 0.0108089335, 0.011595674, 0.0103706205, 0.011225437, 0.014289308, 0.012650929, 0.014160577, 0.010576476, 0.01147345, 0.0114289895, 0.013173191, 0.012216791, 0.010439532, 0.011273234, 0.01114129, 0.012370903, 0.011444979, 0.011465273, 0.013245716, 0.011341136, 0.011756796, 0.010811188, 0.013892002, 0.011094369, 0.012837868, 0.010400867, 0.029463934, 0.012759924, 0.01181541, 0.011318872, 0.011010427, 0.010783861, 0.0111360485, 0.0100736655, 0.010736914, 0.013504141, 0.013537122, 0.010869583, 0.010477059, 0.012780257, 0.012599452, 0.011059402, 0.01758398, 0.012295456, 0.0108661, 0.012574554, 0.010545266, 0.012020007, 0.010918918, 0.0115837855, 0.012943193, 0.012600115, 0.011958782, 0.012506032, 0.012390249, 0.010561247, 0.0124746375, 0.0110640135, 0.012350115, 0.011405873, 0.011191559, 0.012823211, 0.011516742, 0.011837108, 0.012839943]\n",
      "2022-02-22 11:52:53,169 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:53,176 : INFO : topic #6 (0.010): 0.112*\",\" + 0.092*\"system\" + 0.050*\"-\" + 0.040*\"student\" + 0.039*\"teach\" + 0.032*\"oper\" + 0.031*\"rout\" + 0.031*\"criteria\" + 0.025*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:52:53,176 : INFO : topic #13 (0.010): 0.104*\",\" + 0.078*\"rule\" + 0.063*\"program\" + 0.057*\"(\" + 0.041*\"instruct\" + 0.032*\"test\" + 0.031*\")\" + 0.022*\"-\" + 0.018*\"execut\" + 0.014*\").\"\n",
      "2022-02-22 11:52:53,177 : INFO : topic #33 (0.016): 0.190*\"solut\" + 0.130*\"]\" + 0.124*\"equat\" + 0.090*\"problem\" + 0.059*\"comment\" + 0.053*\"differenti\" + 0.037*\"approxim\" + 0.028*\",\" + 0.024*\"continu\" + 0.023*\"5\"\n",
      "2022-02-22 11:52:53,178 : INFO : topic #77 (0.018): 0.288*\"[\" + 0.207*\"algorithm\" + 0.192*\"(\" + 0.170*\"])\" + 0.018*\"chebyshev\" + 0.017*\"-\" + 0.017*\"s14\" + 0.012*\"coeffici\" + 0.012*\"polynomi\" + 0.011*\"normal\"\n",
      "2022-02-22 11:52:53,179 : INFO : topic #61 (0.029): 0.353*\"(\" + 0.337*\")\" + 0.230*\"algorithm\" + 0.029*\"complex\" + 0.017*\"function\" + 0.009*\"number\" + 0.008*\"minim\" + 0.005*\"real\" + 0.005*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:53,180 : INFO : topic diff=0.299420, rho=0.271143\n",
      "2022-02-22 11:52:54,211 : INFO : -6.487 per-word bound, 89.7 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:54,211 : INFO : PROGRESS: pass 11, at document #3204/3204\n",
      "2022-02-22 11:52:54,960 : INFO : optimized alpha [0.010247412, 0.010218537, 0.012348112, 0.011035153, 0.012297099, 0.012097232, 0.009973928, 0.014420096, 0.015948992, 0.011226387, 0.010971864, 0.012300532, 0.011231202, 0.009987073, 0.011108528, 0.010831065, 0.010271825, 0.01187687, 0.010421688, 0.011915157, 0.011928325, 0.01004334, 0.011203966, 0.01072245, 0.014705135, 0.014234152, 0.0116220955, 0.010843712, 0.013841884, 0.014206733, 0.011041108, 0.012337111, 0.010135772, 0.016303064, 0.014229067, 0.010900042, 0.011751814, 0.0104513075, 0.011411121, 0.014568827, 0.012835952, 0.014436106, 0.010654749, 0.011606791, 0.0115180835, 0.013407404, 0.012462539, 0.010526585, 0.011349058, 0.01119249, 0.012565081, 0.011589562, 0.011660985, 0.013615423, 0.011474257, 0.011921986, 0.010889091, 0.014116344, 0.011205186, 0.01301957, 0.010462531, 0.03090524, 0.012954002, 0.0119550405, 0.0114722885, 0.011094355, 0.010895531, 0.011195056, 0.010133019, 0.010822817, 0.013804724, 0.013758143, 0.01097069, 0.010524031, 0.012931567, 0.012885269, 0.011164301, 0.0177228, 0.012397076, 0.010973326, 0.012794082, 0.010623822, 0.012161705, 0.011063183, 0.011697519, 0.013155467, 0.012855738, 0.012124826, 0.012625389, 0.012652972, 0.010614591, 0.012683712, 0.011206004, 0.012435779, 0.011494815, 0.011288005, 0.012997288, 0.011668162, 0.011977544, 0.013000796]\n",
      "2022-02-22 11:52:54,966 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:54,974 : INFO : topic #6 (0.010): 0.110*\",\" + 0.093*\"system\" + 0.050*\"-\" + 0.042*\"student\" + 0.040*\"teach\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.030*\"criteria\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:52:54,975 : INFO : topic #13 (0.010): 0.102*\",\" + 0.082*\"rule\" + 0.061*\"program\" + 0.059*\"(\" + 0.040*\"instruct\" + 0.037*\"test\" + 0.031*\")\" + 0.023*\"-\" + 0.020*\"execut\" + 0.016*\").\"\n",
      "2022-02-22 11:52:54,976 : INFO : topic #33 (0.016): 0.192*\"solut\" + 0.154*\"]\" + 0.121*\"equat\" + 0.092*\"problem\" + 0.061*\"comment\" + 0.050*\"differenti\" + 0.036*\"approxim\" + 0.026*\",\" + 0.024*\"5\" + 0.023*\"continu\"\n",
      "2022-02-22 11:52:54,977 : INFO : topic #77 (0.018): 0.316*\"[\" + 0.207*\"algorithm\" + 0.185*\"(\" + 0.144*\"])\" + 0.020*\"chebyshev\" + 0.018*\"-\" + 0.017*\"s14\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"polynomi\"\n",
      "2022-02-22 11:52:54,978 : INFO : topic #61 (0.031): 0.355*\"(\" + 0.338*\")\" + 0.228*\"algorithm\" + 0.031*\"complex\" + 0.016*\"function\" + 0.009*\"minim\" + 0.008*\"number\" + 0.004*\"real\" + 0.004*\"e4\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:54,979 : INFO : topic diff=0.305356, rho=0.271143\n",
      "2022-02-22 11:52:54,987 : INFO : PROGRESS: pass 12, at document #2000/3204\n",
      "2022-02-22 11:52:55,883 : INFO : optimized alpha [0.010288916, 0.01020627, 0.012467204, 0.011006462, 0.012345843, 0.012134526, 0.009955963, 0.014683347, 0.016126482, 0.011293918, 0.011003881, 0.012403011, 0.011236489, 0.010002216, 0.011154999, 0.010978939, 0.010275439, 0.012033071, 0.01045421, 0.011921482, 0.0120638665, 0.010023571, 0.011224919, 0.010702548, 0.014917716, 0.014270513, 0.011692286, 0.010831849, 0.013950309, 0.0143693015, 0.011061567, 0.01243644, 0.010148667, 0.016395345, 0.014264469, 0.010873157, 0.011756459, 0.010458093, 0.011408915, 0.014713304, 0.012941844, 0.014583555, 0.0106580295, 0.011640648, 0.0115622645, 0.013499664, 0.01250845, 0.01055642, 0.011433622, 0.011230248, 0.012728443, 0.011615151, 0.011668101, 0.013706944, 0.011471985, 0.011948507, 0.010896309, 0.014206186, 0.011212924, 0.013087228, 0.01048057, 0.032377046, 0.012973023, 0.011950936, 0.011466188, 0.0111302985, 0.010916274, 0.011287503, 0.01012546, 0.010840833, 0.013781755, 0.013866868, 0.01097919, 0.010573704, 0.013051352, 0.0129363835, 0.0111678885, 0.018179325, 0.012494918, 0.010958186, 0.012817479, 0.0106552765, 0.012283232, 0.011057965, 0.011776093, 0.013358331, 0.012863838, 0.012164744, 0.012710088, 0.012675206, 0.01062881, 0.012662616, 0.011194966, 0.012558222, 0.011591828, 0.011279376, 0.013156788, 0.011692749, 0.012012271, 0.013119621]\n",
      "2022-02-22 11:52:55,890 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:55,901 : INFO : topic #6 (0.010): 0.112*\",\" + 0.094*\"system\" + 0.051*\"-\" + 0.041*\"student\" + 0.039*\"teach\" + 0.032*\"oper\" + 0.031*\"criteria\" + 0.031*\"rout\" + 0.025*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:52:55,926 : INFO : topic #13 (0.010): 0.105*\",\" + 0.082*\"rule\" + 0.064*\"program\" + 0.057*\"(\" + 0.042*\"instruct\" + 0.035*\"test\" + 0.030*\")\" + 0.022*\"-\" + 0.019*\"execut\" + 0.015*\").\"\n",
      "2022-02-22 11:52:55,936 : INFO : topic #33 (0.016): 0.199*\"solut\" + 0.130*\"]\" + 0.128*\"equat\" + 0.093*\"problem\" + 0.058*\"comment\" + 0.053*\"differenti\" + 0.036*\"approxim\" + 0.028*\",\" + 0.024*\"continu\" + 0.022*\"5\"\n",
      "2022-02-22 11:52:55,947 : INFO : topic #77 (0.018): 0.290*\"[\" + 0.207*\"algorithm\" + 0.192*\"(\" + 0.170*\"])\" + 0.019*\"chebyshev\" + 0.017*\"-\" + 0.017*\"s14\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"polynomi\"\n",
      "2022-02-22 11:52:55,954 : INFO : topic #61 (0.032): 0.356*\"(\" + 0.340*\")\" + 0.228*\"algorithm\" + 0.029*\"complex\" + 0.015*\"function\" + 0.008*\"number\" + 0.008*\"minim\" + 0.005*\"e4\" + 0.005*\"real\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:56,146 : INFO : topic diff=0.266542, rho=0.261694\n",
      "2022-02-22 11:52:57,294 : INFO : -6.478 per-word bound, 89.1 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:52:57,295 : INFO : PROGRESS: pass 12, at document #3204/3204\n",
      "2022-02-22 11:52:58,337 : INFO : optimized alpha [0.010348421, 0.010306923, 0.0126147615, 0.011113458, 0.012503836, 0.012293721, 0.010008312, 0.014915746, 0.016541202, 0.011386035, 0.011120223, 0.0125093, 0.011356315, 0.010061566, 0.011283124, 0.011030351, 0.010355479, 0.012072019, 0.010540153, 0.012063218, 0.0121288, 0.01007154, 0.011324108, 0.010847474, 0.015135564, 0.014545845, 0.011800202, 0.0109426165, 0.013982653, 0.014606484, 0.01116336, 0.012584632, 0.010200586, 0.016870229, 0.014541903, 0.010966564, 0.011908493, 0.010541226, 0.01159265, 0.0149870515, 0.013116843, 0.014856699, 0.010736523, 0.011770439, 0.011643718, 0.013722871, 0.012754856, 0.010645692, 0.011517057, 0.011275131, 0.0129266465, 0.011763592, 0.011864244, 0.014086881, 0.011606721, 0.012114723, 0.010972106, 0.014418808, 0.011330683, 0.013272758, 0.010542988, 0.03385824, 0.013173624, 0.012086863, 0.011618132, 0.011209452, 0.011029787, 0.011342129, 0.010187776, 0.010931484, 0.014078795, 0.014085823, 0.011072684, 0.010619323, 0.01320126, 0.013217098, 0.0112675205, 0.018302329, 0.012601611, 0.011064865, 0.013034624, 0.010731614, 0.012423843, 0.01120333, 0.011894379, 0.013574914, 0.013122392, 0.012329379, 0.012828882, 0.012935347, 0.0106808115, 0.012871896, 0.011345502, 0.012646578, 0.011678078, 0.011370724, 0.013326584, 0.01183769, 0.012148919, 0.013279016]\n",
      "2022-02-22 11:52:58,345 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:58,354 : INFO : topic #13 (0.010): 0.102*\",\" + 0.086*\"rule\" + 0.062*\"program\" + 0.058*\"(\" + 0.041*\"test\" + 0.040*\"instruct\" + 0.030*\")\" + 0.024*\"-\" + 0.020*\"execut\" + 0.016*\"featur\"\n",
      "2022-02-22 11:52:58,355 : INFO : topic #6 (0.010): 0.110*\",\" + 0.096*\"system\" + 0.051*\"-\" + 0.044*\"student\" + 0.040*\"teach\" + 0.034*\"rout\" + 0.032*\"criteria\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:52:58,356 : INFO : topic #33 (0.017): 0.200*\"solut\" + 0.153*\"]\" + 0.123*\"equat\" + 0.096*\"problem\" + 0.061*\"comment\" + 0.051*\"differenti\" + 0.035*\"approxim\" + 0.027*\",\" + 0.024*\"5\" + 0.023*\"continu\"\n",
      "2022-02-22 11:52:58,357 : INFO : topic #77 (0.018): 0.318*\"[\" + 0.207*\"algorithm\" + 0.185*\"(\" + 0.146*\"])\" + 0.020*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"g5\"\n",
      "2022-02-22 11:52:58,361 : INFO : topic #61 (0.034): 0.357*\"(\" + 0.341*\")\" + 0.227*\"algorithm\" + 0.031*\"complex\" + 0.015*\"function\" + 0.009*\"minim\" + 0.008*\"number\" + 0.004*\"e4\" + 0.004*\"real\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:58,363 : INFO : topic diff=0.273091, rho=0.261694\n",
      "2022-02-22 11:52:58,373 : INFO : PROGRESS: pass 13, at document #2000/3204\n",
      "2022-02-22 11:52:59,738 : INFO : optimized alpha [0.010396874, 0.010299046, 0.012742434, 0.011088519, 0.012557423, 0.012331341, 0.0099938, 0.015188612, 0.016720776, 0.011448974, 0.011152791, 0.012609359, 0.011362829, 0.010081555, 0.011331191, 0.011189433, 0.010361775, 0.012229537, 0.010571824, 0.012069172, 0.012261451, 0.0100542, 0.011344491, 0.0108291935, 0.015346329, 0.014581932, 0.011870101, 0.010933833, 0.014092183, 0.014773079, 0.011187473, 0.0126912845, 0.010215977, 0.01696892, 0.014576858, 0.010944915, 0.0119142, 0.010551975, 0.011591383, 0.015128031, 0.013218565, 0.015006389, 0.010741193, 0.011806235, 0.011692765, 0.013819586, 0.012805441, 0.01067344, 0.011604051, 0.011307782, 0.013093695, 0.011791239, 0.011872014, 0.014178866, 0.011604277, 0.012141715, 0.0109792985, 0.014502248, 0.011339616, 0.013338336, 0.010564793, 0.035371844, 0.0131982835, 0.012082728, 0.01161189, 0.011241689, 0.011058262, 0.0114381295, 0.010180716, 0.010951826, 0.014052977, 0.014193463, 0.011086666, 0.010671944, 0.0133165615, 0.013265962, 0.011268176, 0.018753858, 0.012698696, 0.011054403, 0.0130582545, 0.01076504, 0.012544306, 0.011203674, 0.011978702, 0.013788626, 0.013127466, 0.012369567, 0.012908129, 0.012959236, 0.010697657, 0.012850541, 0.011335901, 0.012771103, 0.011777318, 0.011359604, 0.013491416, 0.011865846, 0.012182541, 0.013398388]\n",
      "2022-02-22 11:52:59,747 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:52:59,760 : INFO : topic #6 (0.010): 0.111*\",\" + 0.096*\"system\" + 0.051*\"-\" + 0.044*\"student\" + 0.039*\"teach\" + 0.033*\"criteria\" + 0.032*\"oper\" + 0.031*\"rout\" + 0.025*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:52:59,762 : INFO : topic #21 (0.010): 0.122*\",\" + 0.076*\"-\" + 0.073*\"(\" + 0.046*\"=\" + 0.044*\").\" + 0.042*\"+\" + 0.037*\"1\" + 0.032*\"context\" + 0.024*\")\" + 0.020*\"),\"\n",
      "2022-02-22 11:52:59,767 : INFO : topic #33 (0.017): 0.208*\"solut\" + 0.130*\"equat\" + 0.128*\"]\" + 0.097*\"problem\" + 0.058*\"comment\" + 0.053*\"differenti\" + 0.036*\"approxim\" + 0.029*\",\" + 0.024*\"continu\" + 0.022*\"5\"\n",
      "2022-02-22 11:52:59,769 : INFO : topic #77 (0.019): 0.292*\"[\" + 0.208*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.017*\"-\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.010*\"polynomi\"\n",
      "2022-02-22 11:52:59,771 : INFO : topic #61 (0.035): 0.358*\"(\" + 0.342*\")\" + 0.227*\"algorithm\" + 0.028*\"complex\" + 0.013*\"function\" + 0.008*\"number\" + 0.008*\"minim\" + 0.005*\"e4\" + 0.004*\"real\" + 0.001*\"power\"\n",
      "2022-02-22 11:52:59,774 : INFO : topic diff=0.239896, rho=0.253169\n",
      "2022-02-22 11:53:00,956 : INFO : -6.469 per-word bound, 88.6 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:00,957 : INFO : PROGRESS: pass 13, at document #3204/3204\n",
      "2022-02-22 11:53:01,901 : INFO : optimized alpha [0.010450359, 0.010399413, 0.012889132, 0.011195153, 0.012711736, 0.01248159, 0.010047099, 0.015422558, 0.017148396, 0.011541137, 0.011278048, 0.012712715, 0.011484484, 0.010143691, 0.011451446, 0.011238932, 0.010444153, 0.012264163, 0.010655542, 0.012207444, 0.012329339, 0.010114004, 0.011443581, 0.010968367, 0.01555914, 0.014857756, 0.011975232, 0.01105108, 0.014147115, 0.015008656, 0.01128903, 0.012835904, 0.010266674, 0.017445216, 0.014848681, 0.011031364, 0.012065055, 0.010639765, 0.011778428, 0.015405953, 0.01339237, 0.015287214, 0.010824507, 0.011935306, 0.011774581, 0.014058793, 0.013058503, 0.010764977, 0.011677881, 0.011354015, 0.013290746, 0.01194624, 0.012066469, 0.014554748, 0.011720987, 0.012304073, 0.011053222, 0.014713254, 0.01145209, 0.013519552, 0.010623388, 0.03685413, 0.013394458, 0.012217794, 0.011757785, 0.011330715, 0.011173781, 0.011498294, 0.010239395, 0.011040169, 0.014341094, 0.014410771, 0.011184872, 0.01071636, 0.013465492, 0.013533483, 0.011365317, 0.018873656, 0.012799756, 0.01115831, 0.013276258, 0.010843924, 0.012692125, 0.011345651, 0.012088957, 0.014012878, 0.013375265, 0.012540887, 0.013018298, 0.013222753, 0.010755201, 0.013055072, 0.011490189, 0.012854108, 0.011863609, 0.011451139, 0.013668637, 0.012012388, 0.012310641, 0.013556667]\n",
      "2022-02-22 11:53:01,907 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:01,919 : INFO : topic #6 (0.010): 0.109*\",\" + 0.097*\"system\" + 0.051*\"-\" + 0.046*\"student\" + 0.039*\"teach\" + 0.034*\"rout\" + 0.033*\"criteria\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:53:01,920 : INFO : topic #21 (0.010): 0.123*\",\" + 0.075*\"-\" + 0.073*\"(\" + 0.048*\"=\" + 0.047*\"+\" + 0.045*\").\" + 0.039*\"1\" + 0.031*\"context\" + 0.024*\")\" + 0.022*\"),\"\n",
      "2022-02-22 11:53:01,922 : INFO : topic #33 (0.017): 0.208*\"solut\" + 0.151*\"]\" + 0.125*\"equat\" + 0.099*\"problem\" + 0.060*\"comment\" + 0.051*\"differenti\" + 0.035*\"approxim\" + 0.028*\",\" + 0.023*\"5\" + 0.023*\"continu\"\n",
      "2022-02-22 11:53:01,923 : INFO : topic #77 (0.019): 0.318*\"[\" + 0.209*\"algorithm\" + 0.184*\"(\" + 0.147*\"])\" + 0.020*\"chebyshev\" + 0.018*\"-\" + 0.018*\"s14\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:01,931 : INFO : topic #61 (0.037): 0.360*\"(\" + 0.343*\")\" + 0.226*\"algorithm\" + 0.030*\"complex\" + 0.013*\"function\" + 0.009*\"minim\" + 0.008*\"number\" + 0.004*\"e4\" + 0.003*\"real\" + 0.001*\"power\"\n",
      "2022-02-22 11:53:01,933 : INFO : topic diff=0.246139, rho=0.253169\n",
      "2022-02-22 11:53:01,943 : INFO : PROGRESS: pass 14, at document #2000/3204\n",
      "2022-02-22 11:53:02,966 : INFO : optimized alpha [0.01049906, 0.010402002, 0.013011188, 0.011168189, 0.012768474, 0.012514933, 0.010034574, 0.01570743, 0.017319612, 0.011608351, 0.011298574, 0.012807485, 0.011489256, 0.01017087, 0.011499694, 0.01140357, 0.010452913, 0.012417125, 0.010686479, 0.012219073, 0.012460841, 0.010098727, 0.011463431, 0.01095166, 0.015768275, 0.014891722, 0.012044962, 0.011043802, 0.014259604, 0.015162778, 0.011312526, 0.012949791, 0.010283165, 0.017545966, 0.014877976, 0.011010531, 0.012073241, 0.0106529435, 0.011776615, 0.015547483, 0.013491761, 0.015435528, 0.010829205, 0.011971535, 0.011831191, 0.014154779, 0.013112153, 0.01079606, 0.011760118, 0.011387531, 0.013460042, 0.011980248, 0.012076348, 0.014643677, 0.011721484, 0.012330054, 0.011060406, 0.014799871, 0.011462199, 0.013584858, 0.0106501, 0.03837014, 0.013414561, 0.012213584, 0.011754327, 0.011364965, 0.011212529, 0.011588022, 0.010235334, 0.01106543, 0.014319614, 0.014522882, 0.011197101, 0.010775741, 0.013579883, 0.01358201, 0.011367393, 0.019318167, 0.01289155, 0.011146784, 0.013298592, 0.010881929, 0.0128133325, 0.011352726, 0.012166897, 0.014230842, 0.013385756, 0.012586014, 0.0130956415, 0.013238452, 0.010770553, 0.01303035, 0.011477616, 0.012974481, 0.011963704, 0.011453135, 0.013830699, 0.012039563, 0.012343266, 0.013676803]\n",
      "2022-02-22 11:53:02,973 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:02,989 : INFO : topic #6 (0.010): 0.110*\",\" + 0.098*\"system\" + 0.052*\"-\" + 0.046*\"student\" + 0.039*\"teach\" + 0.034*\"criteria\" + 0.032*\"oper\" + 0.031*\"rout\" + 0.026*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:53:02,990 : INFO : topic #21 (0.010): 0.124*\",\" + 0.077*\"-\" + 0.076*\"(\" + 0.046*\"=\" + 0.045*\").\" + 0.041*\"+\" + 0.038*\"1\" + 0.029*\"context\" + 0.023*\")\" + 0.021*\"),\"\n",
      "2022-02-22 11:53:02,996 : INFO : topic #33 (0.018): 0.215*\"solut\" + 0.132*\"equat\" + 0.127*\"]\" + 0.100*\"problem\" + 0.057*\"comment\" + 0.054*\"differenti\" + 0.035*\"approxim\" + 0.030*\",\" + 0.024*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:02,997 : INFO : topic #77 (0.019): 0.293*\"[\" + 0.208*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.017*\"-\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:02,999 : INFO : topic #61 (0.038): 0.361*\"(\" + 0.345*\")\" + 0.226*\"algorithm\" + 0.028*\"complex\" + 0.012*\"function\" + 0.008*\"minim\" + 0.008*\"number\" + 0.005*\"e4\" + 0.003*\"real\" + 0.001*\"power\"\n",
      "2022-02-22 11:53:03,002 : INFO : topic diff=0.217731, rho=0.245426\n",
      "2022-02-22 11:53:04,900 : INFO : -6.461 per-word bound, 88.1 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:04,901 : INFO : PROGRESS: pass 14, at document #3204/3204\n",
      "2022-02-22 11:53:07,616 : INFO : optimized alpha [0.010546922, 0.010504413, 0.013165263, 0.0112791825, 0.012922035, 0.012666946, 0.010092926, 0.015955858, 0.017732, 0.011700671, 0.011423418, 0.012913371, 0.011610446, 0.0102336025, 0.0116195865, 0.011453523, 0.010537698, 0.012455255, 0.010768227, 0.01235921, 0.012524068, 0.010155162, 0.01156026, 0.011089951, 0.015976302, 0.015168608, 0.012150012, 0.011151541, 0.014304079, 0.015387614, 0.011407215, 0.013093867, 0.010332762, 0.018034888, 0.015144648, 0.011092666, 0.012220705, 0.010736485, 0.011959944, 0.015826812, 0.013667477, 0.015714893, 0.010915027, 0.012104997, 0.011911004, 0.014383874, 0.013377548, 0.010887746, 0.011834428, 0.011432736, 0.013664418, 0.012129528, 0.012271884, 0.01502774, 0.011847523, 0.012488972, 0.011134891, 0.015015636, 0.011581549, 0.01376495, 0.010711746, 0.039834224, 0.013603817, 0.012345591, 0.011894593, 0.011447226, 0.011330134, 0.011646525, 0.010292721, 0.011158538, 0.014605375, 0.014738954, 0.011297601, 0.010816788, 0.013730837, 0.013839573, 0.011466894, 0.01943114, 0.012990029, 0.011250519, 0.013514933, 0.010958925, 0.012957809, 0.01149165, 0.012277057, 0.014463025, 0.013628979, 0.012751193, 0.01320845, 0.013503, 0.01082908, 0.013227801, 0.011619134, 0.013044361, 0.012052662, 0.011547283, 0.014001406, 0.012187796, 0.012470887, 0.013839812]\n",
      "2022-02-22 11:53:07,637 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:07,653 : INFO : topic #6 (0.010): 0.108*\",\" + 0.099*\"system\" + 0.052*\"-\" + 0.049*\"student\" + 0.040*\"teach\" + 0.034*\"criteria\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:53:07,655 : INFO : topic #21 (0.010): 0.126*\",\" + 0.076*\"-\" + 0.075*\"(\" + 0.048*\"=\" + 0.047*\"+\" + 0.046*\").\" + 0.040*\"1\" + 0.027*\"context\" + 0.023*\"),\" + 0.023*\")\"\n",
      "2022-02-22 11:53:07,660 : INFO : topic #33 (0.018): 0.214*\"solut\" + 0.149*\"]\" + 0.128*\"equat\" + 0.101*\"problem\" + 0.060*\"comment\" + 0.052*\"differenti\" + 0.035*\"approxim\" + 0.028*\",\" + 0.023*\"5\" + 0.023*\"continu\"\n",
      "2022-02-22 11:53:07,663 : INFO : topic #77 (0.019): 0.319*\"[\" + 0.209*\"algorithm\" + 0.184*\"(\" + 0.148*\"])\" + 0.020*\"chebyshev\" + 0.018*\"-\" + 0.018*\"s14\" + 0.012*\"coeffici\" + 0.011*\"normal\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:07,667 : INFO : topic #61 (0.040): 0.363*\"(\" + 0.346*\")\" + 0.225*\"algorithm\" + 0.029*\"complex\" + 0.011*\"function\" + 0.009*\"minim\" + 0.007*\"number\" + 0.004*\"e4\" + 0.002*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:07,669 : INFO : topic diff=0.224331, rho=0.245426\n",
      "2022-02-22 11:53:07,680 : INFO : PROGRESS: pass 15, at document #2000/3204\n",
      "2022-02-22 11:53:10,083 : INFO : optimized alpha [0.010592141, 0.010508156, 0.0132882055, 0.011252911, 0.012971144, 0.012700742, 0.010085874, 0.016245764, 0.017901335, 0.011769217, 0.011446059, 0.01301233, 0.011616391, 0.010261514, 0.0116681345, 0.01162383, 0.0105476, 0.012605544, 0.010799794, 0.012371804, 0.0126546305, 0.010144251, 0.0115797, 0.011078668, 0.016187774, 0.0152006345, 0.012218238, 0.011141715, 0.014417666, 0.015540591, 0.011430163, 0.013210279, 0.010347831, 0.018139858, 0.015173958, 0.011079264, 0.012229786, 0.010746841, 0.011959007, 0.015965244, 0.013766337, 0.015861996, 0.010922281, 0.012138784, 0.011967875, 0.0144826835, 0.013435948, 0.010923336, 0.011919196, 0.011467081, 0.0138346115, 0.012156737, 0.012283843, 0.015113674, 0.011846426, 0.012514019, 0.0111446865, 0.015099962, 0.011589926, 0.01383012, 0.010740547, 0.041371435, 0.013622957, 0.012342809, 0.01189244, 0.011480729, 0.011371936, 0.0117373485, 0.010290236, 0.011179237, 0.014577714, 0.014845025, 0.011309554, 0.010872417, 0.013849351, 0.013889537, 0.01147312, 0.019868948, 0.013081473, 0.011240606, 0.013534386, 0.010994813, 0.01307681, 0.011501116, 0.012356327, 0.014699443, 0.013636611, 0.012799635, 0.013288861, 0.013523669, 0.010853382, 0.013206197, 0.011612204, 0.013159303, 0.012156596, 0.011549363, 0.0141625535, 0.012212624, 0.012504081, 0.013957503]\n",
      "2022-02-22 11:53:10,091 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:10,099 : INFO : topic #6 (0.010): 0.109*\",\" + 0.100*\"system\" + 0.053*\"-\" + 0.049*\"student\" + 0.039*\"teach\" + 0.034*\"criteria\" + 0.033*\"oper\" + 0.031*\"rout\" + 0.026*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:53:10,100 : INFO : topic #21 (0.010): 0.127*\",\" + 0.078*\"(\" + 0.077*\"-\" + 0.047*\"=\" + 0.046*\").\" + 0.041*\"+\" + 0.039*\"1\" + 0.025*\"context\" + 0.023*\"),\" + 0.022*\")\"\n",
      "2022-02-22 11:53:10,101 : INFO : topic #33 (0.018): 0.221*\"solut\" + 0.135*\"equat\" + 0.127*\"]\" + 0.101*\"problem\" + 0.057*\"comment\" + 0.054*\"differenti\" + 0.035*\"approxim\" + 0.030*\",\" + 0.024*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:10,103 : INFO : topic #77 (0.020): 0.294*\"[\" + 0.209*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.017*\"-\" + 0.011*\"coeffici\" + 0.011*\"normal\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:10,104 : INFO : topic #61 (0.041): 0.364*\"(\" + 0.347*\")\" + 0.226*\"algorithm\" + 0.027*\"complex\" + 0.010*\"function\" + 0.008*\"minim\" + 0.008*\"number\" + 0.005*\"e4\" + 0.002*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:10,105 : INFO : topic diff=0.199526, rho=0.238352\n",
      "2022-02-22 11:53:11,434 : INFO : -6.454 per-word bound, 87.7 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:11,435 : INFO : PROGRESS: pass 15, at document #3204/3204\n",
      "2022-02-22 11:53:12,407 : INFO : optimized alpha [0.0106389, 0.010612637, 0.0134498, 0.011363711, 0.013121601, 0.012849638, 0.010136986, 0.016518962, 0.018312935, 0.011859491, 0.011570675, 0.01312088, 0.0117327925, 0.010331001, 0.011783229, 0.011685819, 0.010630559, 0.012642176, 0.010877585, 0.0125089865, 0.01272092, 0.010201626, 0.011674391, 0.011216356, 0.016391395, 0.015469699, 0.012328162, 0.011251533, 0.01447223, 0.01577358, 0.0115250675, 0.013356657, 0.010396446, 0.018631406, 0.015435757, 0.011155183, 0.012374122, 0.010830752, 0.01213657, 0.016255796, 0.0139386365, 0.016149756, 0.011010585, 0.012267045, 0.0120411, 0.014707939, 0.0136844795, 0.011015255, 0.011986867, 0.011509052, 0.014041076, 0.012307885, 0.0124832885, 0.015494386, 0.011972175, 0.012669772, 0.011215325, 0.015308855, 0.011706878, 0.014006647, 0.010802994, 0.042780332, 0.0138085, 0.012474479, 0.012032204, 0.01156119, 0.011489354, 0.011798869, 0.010348502, 0.011265827, 0.014858563, 0.015057132, 0.011405652, 0.0109189795, 0.01399698, 0.01415156, 0.011568226, 0.01997937, 0.013190446, 0.011339809, 0.013746822, 0.011074437, 0.01321836, 0.011637258, 0.012471498, 0.014939828, 0.013878283, 0.012961672, 0.013401682, 0.013784239, 0.010908496, 0.013405096, 0.011753146, 0.01322722, 0.012243399, 0.011648366, 0.014352312, 0.012357868, 0.012628913, 0.014122574]\n",
      "2022-02-22 11:53:12,413 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:12,421 : INFO : topic #6 (0.010): 0.107*\",\" + 0.100*\"system\" + 0.053*\"-\" + 0.051*\"student\" + 0.040*\"teach\" + 0.034*\"criteria\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.024*\"comput\"\n",
      "2022-02-22 11:53:12,422 : INFO : topic #21 (0.010): 0.128*\",\" + 0.079*\"(\" + 0.076*\"-\" + 0.049*\"=\" + 0.048*\").\" + 0.047*\"+\" + 0.041*\"1\" + 0.023*\"context\" + 0.023*\"),\" + 0.022*\")\"\n",
      "2022-02-22 11:53:12,423 : INFO : topic #33 (0.019): 0.219*\"solut\" + 0.147*\"]\" + 0.130*\"equat\" + 0.102*\"problem\" + 0.059*\"comment\" + 0.053*\"differenti\" + 0.034*\"approxim\" + 0.029*\",\" + 0.023*\"continu\" + 0.023*\"5\"\n",
      "2022-02-22 11:53:12,425 : INFO : topic #77 (0.020): 0.318*\"[\" + 0.211*\"algorithm\" + 0.184*\"(\" + 0.148*\"])\" + 0.020*\"chebyshev\" + 0.018*\"-\" + 0.018*\"s14\" + 0.011*\"normal\" + 0.011*\"coeffici\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:12,428 : INFO : topic #61 (0.043): 0.366*\"(\" + 0.349*\")\" + 0.223*\"algorithm\" + 0.027*\"complex\" + 0.009*\"function\" + 0.009*\"minim\" + 0.007*\"number\" + 0.004*\"e4\" + 0.002*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:12,430 : INFO : topic diff=0.205518, rho=0.238352\n",
      "2022-02-22 11:53:12,441 : INFO : PROGRESS: pass 16, at document #2000/3204\n",
      "2022-02-22 11:53:13,419 : INFO : optimized alpha [0.0106832925, 0.010616243, 0.013565971, 0.01134071, 0.0131709725, 0.012894274, 0.010130416, 0.016816342, 0.01848484, 0.011930909, 0.011589977, 0.013222621, 0.011742572, 0.0103595955, 0.011830717, 0.011856725, 0.010644015, 0.012791454, 0.0109085115, 0.012519628, 0.012849267, 0.010193638, 0.011698893, 0.011209012, 0.016601682, 0.0154998945, 0.012393557, 0.0112432195, 0.014592236, 0.015929356, 0.011548874, 0.013475764, 0.01041505, 0.018734295, 0.015465109, 0.0111410385, 0.012388484, 0.010842208, 0.012137959, 0.016395096, 0.014035549, 0.01630337, 0.011020297, 0.0123013975, 0.012099676, 0.014797752, 0.013745891, 0.011050098, 0.012071479, 0.011545583, 0.014212333, 0.012334197, 0.012495799, 0.015588127, 0.011976549, 0.012693985, 0.011225068, 0.01539829, 0.011713608, 0.014068503, 0.010830055, 0.044342127, 0.013826715, 0.0124716, 0.012031263, 0.01159407, 0.011536954, 0.01189209, 0.010346281, 0.011288732, 0.014835198, 0.015159106, 0.011421326, 0.010978645, 0.014111716, 0.014203004, 0.011571615, 0.020413253, 0.013281605, 0.01133413, 0.01376834, 0.011110908, 0.013335266, 0.011647661, 0.012553577, 0.015181412, 0.013889659, 0.013010357, 0.013483583, 0.013809874, 0.010933725, 0.0133880405, 0.011741963, 0.01333851, 0.012344057, 0.011649038, 0.014511038, 0.012383326, 0.012659797, 0.014237998]\n",
      "2022-02-22 11:53:13,426 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:13,433 : INFO : topic #6 (0.010): 0.109*\",\" + 0.100*\"system\" + 0.053*\"-\" + 0.051*\"student\" + 0.039*\"teach\" + 0.034*\"criteria\" + 0.033*\"oper\" + 0.031*\"rout\" + 0.025*\"comput\" + 0.025*\"conflict\"\n",
      "2022-02-22 11:53:13,433 : INFO : topic #21 (0.010): 0.129*\",\" + 0.082*\"(\" + 0.078*\"-\" + 0.048*\").\" + 0.048*\"=\" + 0.042*\"+\" + 0.040*\"1\" + 0.024*\"),\" + 0.022*\"context\" + 0.021*\")\"\n",
      "2022-02-22 11:53:13,435 : INFO : topic #33 (0.019): 0.226*\"solut\" + 0.138*\"equat\" + 0.126*\"]\" + 0.102*\"problem\" + 0.056*\"comment\" + 0.054*\"differenti\" + 0.035*\"approxim\" + 0.031*\",\" + 0.024*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:13,436 : INFO : topic #77 (0.020): 0.294*\"[\" + 0.210*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.011*\"coeffici\" + 0.011*\"normal\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:13,437 : INFO : topic #61 (0.044): 0.366*\"(\" + 0.350*\")\" + 0.224*\"algorithm\" + 0.026*\"complex\" + 0.008*\"minim\" + 0.008*\"function\" + 0.007*\"number\" + 0.005*\"e4\" + 0.002*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:13,439 : INFO : topic diff=0.183882, rho=0.231857\n",
      "2022-02-22 11:53:14,554 : INFO : -6.450 per-word bound, 87.4 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:14,555 : INFO : PROGRESS: pass 16, at document #3204/3204\n",
      "2022-02-22 11:53:15,405 : INFO : optimized alpha [0.010733201, 0.010722866, 0.01372732, 0.011455811, 0.013326196, 0.013042822, 0.010184497, 0.017098758, 0.018917406, 0.01202619, 0.0117121665, 0.013334042, 0.011861211, 0.010437771, 0.011945851, 0.011916863, 0.010733558, 0.012824206, 0.010988937, 0.012654144, 0.01291872, 0.010257843, 0.011791678, 0.011348447, 0.016814008, 0.0157646, 0.012503602, 0.011353038, 0.014642419, 0.016158417, 0.011644075, 0.013627103, 0.010466764, 0.019225227, 0.015722528, 0.011215487, 0.012530027, 0.010924449, 0.012310071, 0.016675238, 0.014204676, 0.016587187, 0.011104765, 0.012429582, 0.01218303, 0.015022305, 0.014012842, 0.011138027, 0.012144625, 0.011582249, 0.0144239, 0.012482569, 0.012694399, 0.01597181, 0.012090569, 0.012849278, 0.011292154, 0.0156063745, 0.011839681, 0.014247216, 0.010891258, 0.045790367, 0.014014149, 0.012603084, 0.012170662, 0.01167286, 0.011649869, 0.011959035, 0.010403449, 0.0113778915, 0.015111603, 0.015361674, 0.011520011, 0.011024158, 0.014256255, 0.014464223, 0.011664812, 0.020513292, 0.013398545, 0.011435727, 0.013969171, 0.011188889, 0.013474007, 0.011778975, 0.012661544, 0.015433403, 0.01412207, 0.013174595, 0.0135939745, 0.014069517, 0.010992045, 0.013580687, 0.011889405, 0.013404673, 0.01243359, 0.011739318, 0.014692019, 0.0125283, 0.012782089, 0.014405339]\n",
      "2022-02-22 11:53:15,413 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:15,424 : INFO : topic #6 (0.010): 0.106*\",\" + 0.100*\"system\" + 0.053*\"-\" + 0.053*\"student\" + 0.040*\"teach\" + 0.035*\"criteria\" + 0.034*\"rout\" + 0.032*\"oper\" + 0.027*\"conflict\" + 0.024*\"comput\"\n",
      "2022-02-22 11:53:15,427 : INFO : topic #21 (0.010): 0.130*\",\" + 0.081*\"(\" + 0.077*\"-\" + 0.050*\").\" + 0.050*\"=\" + 0.047*\"+\" + 0.041*\"1\" + 0.025*\"),\" + 0.021*\")\" + 0.021*\"context\"\n",
      "2022-02-22 11:53:15,430 : INFO : topic #33 (0.019): 0.224*\"solut\" + 0.146*\"]\" + 0.133*\"equat\" + 0.103*\"problem\" + 0.059*\"comment\" + 0.053*\"differenti\" + 0.033*\"approxim\" + 0.029*\",\" + 0.023*\"5\" + 0.022*\"continu\"\n",
      "2022-02-22 11:53:15,431 : INFO : topic #77 (0.021): 0.319*\"[\" + 0.211*\"algorithm\" + 0.184*\"(\" + 0.149*\"])\" + 0.020*\"chebyshev\" + 0.018*\"-\" + 0.018*\"s14\" + 0.012*\"normal\" + 0.011*\"coeffici\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:15,435 : INFO : topic #61 (0.046): 0.368*\"(\" + 0.351*\")\" + 0.223*\"algorithm\" + 0.026*\"complex\" + 0.008*\"minim\" + 0.007*\"function\" + 0.007*\"number\" + 0.004*\"e4\" + 0.001*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:15,436 : INFO : topic diff=0.189517, rho=0.231857\n",
      "2022-02-22 11:53:15,445 : INFO : PROGRESS: pass 17, at document #2000/3204\n",
      "2022-02-22 11:53:16,725 : INFO : optimized alpha [0.010778053, 0.010729998, 0.013846301, 0.011434594, 0.013380484, 0.0130849155, 0.01017829, 0.017396228, 0.019087883, 0.012096331, 0.011732259, 0.013434035, 0.011873425, 0.010468206, 0.01199365, 0.012080359, 0.010746771, 0.012966847, 0.0110217845, 0.012665829, 0.01305085, 0.01025262, 0.011817068, 0.011340975, 0.017023442, 0.015794948, 0.012569147, 0.011347446, 0.014758439, 0.016317096, 0.011666074, 0.013749025, 0.010483947, 0.019321803, 0.015750296, 0.011200591, 0.0125438, 0.0109344525, 0.012310989, 0.016819267, 0.014298039, 0.016741866, 0.011116855, 0.012463099, 0.012248675, 0.015110145, 0.014074204, 0.0111735, 0.012236014, 0.0116196, 0.014598005, 0.012508122, 0.012706076, 0.016064571, 0.012094846, 0.012875599, 0.011301866, 0.015692014, 0.011850178, 0.014307586, 0.01091791, 0.047445774, 0.014034754, 0.01260154, 0.0121723, 0.011707796, 0.011697874, 0.012052096, 0.01040152, 0.011404229, 0.015089149, 0.015463312, 0.011537977, 0.011087841, 0.014364139, 0.014518787, 0.011668191, 0.020941112, 0.013494082, 0.011430193, 0.013988103, 0.011229727, 0.013590608, 0.011784969, 0.012743634, 0.015675029, 0.014132339, 0.013231099, 0.013672834, 0.014095255, 0.011016985, 0.013564946, 0.011882234, 0.013514103, 0.012533992, 0.011742759, 0.014860194, 0.012552989, 0.012812212, 0.01451707]\n",
      "2022-02-22 11:53:16,733 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:16,743 : INFO : topic #6 (0.010): 0.108*\",\" + 0.100*\"system\" + 0.054*\"-\" + 0.053*\"student\" + 0.040*\"teach\" + 0.035*\"criteria\" + 0.033*\"oper\" + 0.031*\"rout\" + 0.025*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:53:16,754 : INFO : topic #21 (0.010): 0.131*\",\" + 0.085*\"(\" + 0.079*\"-\" + 0.050*\").\" + 0.048*\"=\" + 0.042*\"+\" + 0.041*\"1\" + 0.026*\"),\" + 0.020*\")\" + 0.019*\"context\"\n",
      "2022-02-22 11:53:16,758 : INFO : topic #33 (0.019): 0.230*\"solut\" + 0.141*\"equat\" + 0.126*\"]\" + 0.103*\"problem\" + 0.056*\"comment\" + 0.055*\"differenti\" + 0.034*\"approxim\" + 0.031*\",\" + 0.023*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:16,761 : INFO : topic #77 (0.021): 0.295*\"[\" + 0.211*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.011*\"normal\" + 0.011*\"coeffici\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:16,770 : INFO : topic #61 (0.047): 0.369*\"(\" + 0.353*\")\" + 0.224*\"algorithm\" + 0.024*\"complex\" + 0.008*\"minim\" + 0.007*\"number\" + 0.006*\"function\" + 0.005*\"e4\" + 0.001*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:16,771 : INFO : topic diff=0.170082, rho=0.225865\n",
      "2022-02-22 11:53:17,821 : INFO : -6.444 per-word bound, 87.1 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:17,822 : INFO : PROGRESS: pass 17, at document #3204/3204\n",
      "2022-02-22 11:53:18,722 : INFO : optimized alpha [0.010830982, 0.010834688, 0.014012781, 0.011549658, 0.01353554, 0.013235835, 0.0102314735, 0.017674947, 0.019524306, 0.0121966, 0.011847898, 0.013548218, 0.011987666, 0.010546926, 0.012104413, 0.012141077, 0.010838766, 0.012995933, 0.011098531, 0.012795538, 0.01311846, 0.010319557, 0.011908095, 0.011484384, 0.017231796, 0.016052725, 0.012679417, 0.011450973, 0.014832505, 0.016539535, 0.011766156, 0.013900425, 0.010532659, 0.019815698, 0.016003735, 0.0112758, 0.012687424, 0.011013063, 0.0124802645, 0.017104924, 0.014466893, 0.017034603, 0.011199747, 0.012588932, 0.012335052, 0.01533412, 0.014340925, 0.011266191, 0.012302895, 0.011660095, 0.014814863, 0.01265875, 0.012901687, 0.016451556, 0.012218317, 0.013030622, 0.011369821, 0.015902687, 0.011976309, 0.014475086, 0.010980044, 0.048855543, 0.014216388, 0.012730623, 0.012309239, 0.011780617, 0.0118087875, 0.012119886, 0.010461583, 0.011500285, 0.015364302, 0.015671313, 0.011641415, 0.011132367, 0.014505841, 0.014771144, 0.011759607, 0.021035152, 0.013611283, 0.011529846, 0.014188144, 0.011312506, 0.013729298, 0.011916194, 0.012849545, 0.015953686, 0.014358499, 0.013395139, 0.013794045, 0.014346216, 0.01107837, 0.013749143, 0.012027156, 0.013578621, 0.012626332, 0.011842473, 0.015060429, 0.012700162, 0.012929775, 0.014686756]\n",
      "2022-02-22 11:53:18,729 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:18,739 : INFO : topic #6 (0.010): 0.106*\",\" + 0.100*\"system\" + 0.054*\"student\" + 0.053*\"-\" + 0.040*\"teach\" + 0.035*\"criteria\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.024*\"comput\"\n",
      "2022-02-22 11:53:18,740 : INFO : topic #21 (0.010): 0.132*\",\" + 0.086*\"(\" + 0.077*\"-\" + 0.052*\").\" + 0.050*\"=\" + 0.047*\"+\" + 0.042*\"1\" + 0.028*\"),\" + 0.020*\")\" + 0.019*\"2\"\n",
      "2022-02-22 11:53:18,744 : INFO : topic #33 (0.020): 0.229*\"solut\" + 0.146*\"]\" + 0.135*\"equat\" + 0.104*\"problem\" + 0.058*\"comment\" + 0.053*\"differenti\" + 0.032*\"approxim\" + 0.030*\",\" + 0.022*\"5\" + 0.022*\"continu\"\n",
      "2022-02-22 11:53:18,747 : INFO : topic #77 (0.021): 0.319*\"[\" + 0.212*\"algorithm\" + 0.184*\"(\" + 0.150*\"])\" + 0.020*\"chebyshev\" + 0.019*\"-\" + 0.018*\"s14\" + 0.012*\"normal\" + 0.011*\"g5\" + 0.011*\"coeffici\"\n",
      "2022-02-22 11:53:18,751 : INFO : topic #61 (0.049): 0.370*\"(\" + 0.354*\")\" + 0.222*\"algorithm\" + 0.025*\"complex\" + 0.008*\"minim\" + 0.006*\"number\" + 0.005*\"function\" + 0.004*\"e4\" + 0.001*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:18,752 : INFO : topic diff=0.175141, rho=0.225865\n",
      "2022-02-22 11:53:18,763 : INFO : PROGRESS: pass 18, at document #2000/3204\n",
      "2022-02-22 11:53:19,761 : INFO : optimized alpha [0.010875113, 0.010841653, 0.014139301, 0.0115288505, 0.013590106, 0.013279883, 0.010227963, 0.017976547, 0.019697608, 0.0122682685, 0.011868848, 0.013646617, 0.011999587, 0.010578045, 0.012152672, 0.012309396, 0.01085652, 0.013136463, 0.011128342, 0.012803998, 0.013247285, 0.010316901, 0.011935686, 0.011479356, 0.017436668, 0.016083278, 0.0127450945, 0.01144421, 0.014957937, 0.016684825, 0.011785101, 0.014022135, 0.010549699, 0.019910332, 0.016029961, 0.011265187, 0.012703508, 0.011024182, 0.012480704, 0.017250123, 0.0145586375, 0.017190522, 0.011211658, 0.012623083, 0.012407816, 0.015418391, 0.014403811, 0.0113047715, 0.012392834, 0.011698301, 0.014990432, 0.012686345, 0.012915404, 0.016541623, 0.012223761, 0.0130561935, 0.011378248, 0.015988175, 0.011985148, 0.0145340925, 0.011007547, 0.05060331, 0.014236103, 0.0127289975, 0.012310581, 0.011809743, 0.01186241, 0.012214206, 0.010461046, 0.011526123, 0.015344414, 0.015777862, 0.011658982, 0.011199983, 0.014613488, 0.014828937, 0.011765613, 0.021464106, 0.013706791, 0.011524456, 0.014209307, 0.0113501325, 0.013841081, 0.011923159, 0.012935968, 0.016201058, 0.014371007, 0.013450424, 0.013873067, 0.014372195, 0.011104218, 0.013731689, 0.012017161, 0.013689327, 0.012726635, 0.011845866, 0.015231521, 0.012725562, 0.012957835, 0.014798225]\n",
      "2022-02-22 11:53:19,788 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:19,796 : INFO : topic #6 (0.010): 0.108*\",\" + 0.100*\"system\" + 0.054*\"student\" + 0.054*\"-\" + 0.040*\"teach\" + 0.035*\"criteria\" + 0.033*\"oper\" + 0.031*\"rout\" + 0.025*\"conflict\" + 0.025*\"comput\"\n",
      "2022-02-22 11:53:19,796 : INFO : topic #21 (0.010): 0.133*\",\" + 0.089*\"(\" + 0.079*\"-\" + 0.052*\").\" + 0.048*\"=\" + 0.042*\"+\" + 0.041*\"1\" + 0.028*\"),\" + 0.020*\")\" + 0.017*\"2\"\n",
      "2022-02-22 11:53:19,798 : INFO : topic #33 (0.020): 0.235*\"solut\" + 0.142*\"equat\" + 0.126*\"]\" + 0.104*\"problem\" + 0.056*\"comment\" + 0.055*\"differenti\" + 0.033*\"approxim\" + 0.032*\",\" + 0.023*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:19,801 : INFO : topic #77 (0.021): 0.296*\"[\" + 0.211*\"algorithm\" + 0.190*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.011*\"normal\" + 0.011*\"coeffici\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:19,802 : INFO : topic #61 (0.051): 0.370*\"(\" + 0.355*\")\" + 0.224*\"algorithm\" + 0.023*\"complex\" + 0.007*\"minim\" + 0.006*\"number\" + 0.005*\"e4\" + 0.005*\"function\" + 0.001*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:19,803 : INFO : topic diff=0.158356, rho=0.220316\n",
      "2022-02-22 11:53:20,798 : INFO : -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:20,800 : INFO : PROGRESS: pass 18, at document #3204/3204\n",
      "2022-02-22 11:53:21,803 : INFO : optimized alpha [0.010929044, 0.010946567, 0.0142980525, 0.011641955, 0.0137401875, 0.013433173, 0.010280254, 0.018261254, 0.020138018, 0.012366743, 0.011986969, 0.013761182, 0.012111884, 0.010661204, 0.012261554, 0.012384239, 0.010950925, 0.013162024, 0.011203705, 0.012926729, 0.013313265, 0.010390319, 0.012027283, 0.01162257, 0.017650815, 0.01634021, 0.012853353, 0.011554356, 0.01502999, 0.016900683, 0.011879062, 0.014173634, 0.010599558, 0.020400535, 0.016279554, 0.011339092, 0.012847083, 0.011101462, 0.012647385, 0.017541686, 0.014714006, 0.017489066, 0.011297206, 0.012746784, 0.01249248, 0.015642203, 0.014675957, 0.011393745, 0.012460561, 0.01174029, 0.015207333, 0.012834541, 0.013108341, 0.01693509, 0.012342865, 0.013208747, 0.011445024, 0.01618372, 0.0121114375, 0.0147068305, 0.011070589, 0.05201643, 0.014412133, 0.012853496, 0.012449691, 0.01188345, 0.011978066, 0.012287258, 0.010518178, 0.011622577, 0.015618693, 0.015979752, 0.011762782, 0.011243585, 0.014755171, 0.015078282, 0.011855415, 0.021548266, 0.013824327, 0.011622366, 0.014411524, 0.011435536, 0.013979944, 0.012054423, 0.013042187, 0.016483441, 0.0145992385, 0.013614456, 0.013989402, 0.014625387, 0.011170721, 0.013917984, 0.012159745, 0.013752195, 0.012814865, 0.011946022, 0.015434619, 0.012870343, 0.0130780125, 0.014970466]\n",
      "2022-02-22 11:53:21,809 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:21,818 : INFO : topic #6 (0.010): 0.106*\",\" + 0.099*\"system\" + 0.055*\"student\" + 0.054*\"-\" + 0.041*\"teach\" + 0.035*\"criteria\" + 0.034*\"rout\" + 0.031*\"oper\" + 0.027*\"conflict\" + 0.024*\"comput\"\n",
      "2022-02-22 11:53:21,820 : INFO : topic #21 (0.010): 0.134*\",\" + 0.090*\"(\" + 0.077*\"-\" + 0.054*\").\" + 0.050*\"=\" + 0.047*\"+\" + 0.042*\"1\" + 0.030*\"),\" + 0.020*\")\" + 0.019*\"2\"\n",
      "2022-02-22 11:53:21,823 : INFO : topic #33 (0.020): 0.232*\"solut\" + 0.145*\"]\" + 0.136*\"equat\" + 0.105*\"problem\" + 0.058*\"comment\" + 0.054*\"differenti\" + 0.032*\"approxim\" + 0.030*\",\" + 0.022*\"5\" + 0.021*\"continu\"\n",
      "2022-02-22 11:53:21,826 : INFO : topic #77 (0.022): 0.320*\"[\" + 0.209*\"algorithm\" + 0.185*\"(\" + 0.151*\"])\" + 0.020*\"chebyshev\" + 0.019*\"-\" + 0.018*\"s14\" + 0.012*\"normal\" + 0.011*\"coeffici\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:21,827 : INFO : topic #61 (0.052): 0.371*\"(\" + 0.355*\")\" + 0.223*\"algorithm\" + 0.024*\"complex\" + 0.008*\"minim\" + 0.005*\"number\" + 0.004*\"e4\" + 0.004*\"function\" + 0.001*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:21,831 : INFO : topic diff=0.162989, rho=0.220316\n",
      "2022-02-22 11:53:21,840 : INFO : PROGRESS: pass 19, at document #2000/3204\n",
      "2022-02-22 11:53:22,971 : INFO : optimized alpha [0.010968949, 0.010954489, 0.014418282, 0.01162151, 0.013795108, 0.01347915, 0.010277041, 0.01856903, 0.020305656, 0.012447947, 0.012008703, 0.013858096, 0.012124845, 0.010697513, 0.012308963, 0.012552375, 0.010968392, 0.013302048, 0.011234258, 0.012936359, 0.0134389475, 0.010386683, 0.01205569, 0.011622355, 0.017856993, 0.016370988, 0.012922143, 0.011548921, 0.015163246, 0.017049147, 0.011901487, 0.014298314, 0.010617609, 0.02049542, 0.01630436, 0.011330125, 0.012861229, 0.011111251, 0.012647393, 0.017684432, 0.01480738, 0.017646354, 0.011310173, 0.0127788335, 0.012568102, 0.015726421, 0.014742107, 0.0114329, 0.012549193, 0.0117792655, 0.015386037, 0.012858699, 0.013121228, 0.017020645, 0.01234946, 0.013235051, 0.011453467, 0.016262136, 0.012121274, 0.014764553, 0.011097717, 0.053829063, 0.01442955, 0.012851797, 0.012454832, 0.011908202, 0.012030788, 0.012388095, 0.0105201285, 0.01164915, 0.015596254, 0.016087873, 0.011782554, 0.011308972, 0.014859483, 0.0151344575, 0.011860057, 0.02197153, 0.0139198555, 0.011617093, 0.014427001, 0.011472527, 0.01409316, 0.012065027, 0.0131302, 0.01673319, 0.014616961, 0.013671547, 0.014070158, 0.01464681, 0.011204694, 0.013901882, 0.012153682, 0.013862757, 0.0129165165, 0.011951954, 0.015607135, 0.012897871, 0.0131054595, 0.015080123]\n",
      "2022-02-22 11:53:22,978 : INFO : merging changes from 2000 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:22,987 : INFO : topic #6 (0.010): 0.107*\",\" + 0.100*\"system\" + 0.055*\"student\" + 0.054*\"-\" + 0.041*\"teach\" + 0.036*\"criteria\" + 0.033*\"oper\" + 0.031*\"rout\" + 0.025*\"conflict\" + 0.024*\"comput\"\n",
      "2022-02-22 11:53:22,987 : INFO : topic #21 (0.010): 0.135*\",\" + 0.093*\"(\" + 0.079*\"-\" + 0.054*\").\" + 0.048*\"=\" + 0.042*\"+\" + 0.042*\"1\" + 0.030*\"),\" + 0.019*\")\" + 0.018*\"2\"\n",
      "2022-02-22 11:53:22,989 : INFO : topic #33 (0.020): 0.238*\"solut\" + 0.144*\"equat\" + 0.126*\"]\" + 0.105*\"problem\" + 0.055*\"comment\" + 0.055*\"differenti\" + 0.032*\",\" + 0.032*\"approxim\" + 0.023*\"continu\" + 0.021*\"5\"\n",
      "2022-02-22 11:53:22,991 : INFO : topic #77 (0.022): 0.297*\"[\" + 0.209*\"algorithm\" + 0.191*\"(\" + 0.171*\"])\" + 0.019*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.011*\"normal\" + 0.011*\"coeffici\" + 0.010*\"g5\"\n",
      "2022-02-22 11:53:22,995 : INFO : topic #61 (0.054): 0.372*\"(\" + 0.356*\")\" + 0.225*\"algorithm\" + 0.022*\"complex\" + 0.007*\"minim\" + 0.005*\"number\" + 0.005*\"e4\" + 0.004*\"function\" + 0.000*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:22,996 : INFO : topic diff=0.148049, rho=0.215156\n",
      "2022-02-22 11:53:24,276 : INFO : -6.435 per-word bound, 86.5 perplexity estimate based on a held-out corpus of 1204 documents with 49783 words\n",
      "2022-02-22 11:53:24,278 : INFO : PROGRESS: pass 19, at document #3204/3204\n",
      "2022-02-22 11:53:25,015 : INFO : optimized alpha [0.011021939, 0.011059738, 0.0145745585, 0.011730671, 0.013942854, 0.013632532, 0.010326669, 0.018853633, 0.020746658, 0.012551418, 0.012122781, 0.013973104, 0.012243977, 0.010783181, 0.012422704, 0.012623254, 0.011061271, 0.013324221, 0.011314413, 0.0130570335, 0.013503376, 0.010462676, 0.012145718, 0.011769693, 0.018064322, 0.016627358, 0.013035472, 0.011659336, 0.0152470395, 0.01726176, 0.01200032, 0.014447476, 0.010668621, 0.020978354, 0.016547592, 0.011404906, 0.012995554, 0.011189216, 0.0128161665, 0.017972555, 0.0149682695, 0.017945006, 0.011394274, 0.012902821, 0.01265579, 0.015947355, 0.015019702, 0.011524575, 0.012613291, 0.011824818, 0.015608558, 0.013004699, 0.013316289, 0.017411923, 0.012471161, 0.013385253, 0.011517097, 0.016457625, 0.0122455945, 0.014926626, 0.011159685, 0.0552197, 0.0146107245, 0.012971929, 0.012591817, 0.011980649, 0.012151171, 0.012464122, 0.010576344, 0.011748214, 0.015864266, 0.016289722, 0.011884675, 0.011351721, 0.014998686, 0.015386494, 0.011946189, 0.02205436, 0.014035289, 0.011719526, 0.01463145, 0.011558555, 0.014227186, 0.012196444, 0.013239339, 0.017031027, 0.014829051, 0.013840725, 0.014186963, 0.014894481, 0.011270099, 0.014085302, 0.0122963255, 0.0139266895, 0.013003076, 0.012056978, 0.015810542, 0.013040447, 0.013221293, 0.015246993]\n",
      "2022-02-22 11:53:25,021 : INFO : merging changes from 1204 documents into a model of 3204 documents\n",
      "2022-02-22 11:53:25,030 : INFO : topic #6 (0.010): 0.106*\",\" + 0.100*\"system\" + 0.056*\"student\" + 0.053*\"-\" + 0.041*\"teach\" + 0.036*\"criteria\" + 0.034*\"rout\" + 0.032*\"oper\" + 0.027*\"conflict\" + 0.023*\"comput\"\n",
      "2022-02-22 11:53:25,031 : INFO : topic #21 (0.010): 0.135*\",\" + 0.095*\"(\" + 0.077*\"-\" + 0.057*\").\" + 0.049*\"=\" + 0.046*\"+\" + 0.042*\"1\" + 0.032*\"),\" + 0.020*\"2\" + 0.019*\")\"\n",
      "2022-02-22 11:53:25,031 : INFO : topic #33 (0.021): 0.235*\"solut\" + 0.145*\"]\" + 0.137*\"equat\" + 0.106*\"problem\" + 0.058*\"comment\" + 0.054*\"differenti\" + 0.031*\"approxim\" + 0.031*\",\" + 0.022*\"5\" + 0.021*\"continu\"\n",
      "2022-02-22 11:53:25,033 : INFO : topic #77 (0.022): 0.320*\"[\" + 0.211*\"algorithm\" + 0.185*\"(\" + 0.151*\"])\" + 0.020*\"chebyshev\" + 0.018*\"s14\" + 0.018*\"-\" + 0.012*\"normal\" + 0.011*\"coeffici\" + 0.011*\"g5\"\n",
      "2022-02-22 11:53:25,034 : INFO : topic #61 (0.055): 0.372*\"(\" + 0.357*\")\" + 0.224*\"algorithm\" + 0.022*\"complex\" + 0.008*\"minim\" + 0.004*\"number\" + 0.004*\"e4\" + 0.003*\"function\" + 0.000*\"real\" + 0.000*\"power\"\n",
      "2022-02-22 11:53:25,035 : INFO : topic diff=0.152202, rho=0.215156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.42039937),\n",
       " (1, 0.0045988364),\n",
       " (2, 0.006060362),\n",
       " (3, 0.0048778225),\n",
       " (4, 0.0057976875),\n",
       " (5, 0.0056686504),\n",
       " (6, 0.004294013),\n",
       " (7, 0.007839677),\n",
       " (8, 0.008626831),\n",
       " (9, 0.005219104),\n",
       " (10, 0.0050408687),\n",
       " (11, 0.005810266),\n",
       " (12, 0.0050912644),\n",
       " (13, 0.004483839),\n",
       " (14, 0.005165582),\n",
       " (15, 0.0052489745),\n",
       " (16, 0.004599474),\n",
       " (17, 0.0055404487),\n",
       " (18, 0.004704735),\n",
       " (19, 0.0054293475),\n",
       " (20, 0.005614945),\n",
       " (21, 0.0043505677),\n",
       " (22, 0.0050504063),\n",
       " (23, 0.0048940484),\n",
       " (24, 0.0075114677),\n",
       " (25, 0.0069139525),\n",
       " (26, 0.0054203817),\n",
       " (27, 0.0048481603),\n",
       " (28, 0.0063399915),\n",
       " (29, 0.0071777483),\n",
       " (30, 0.004989947),\n",
       " (31, 0.0060075186),\n",
       " (32, 0.0044362033),\n",
       " (33, 0.008723174),\n",
       " (34, 0.0068807844),\n",
       " (35, 0.004742364),\n",
       " (36, 0.0054037836),\n",
       " (37, 0.0046526757),\n",
       " (38, 0.0053291908),\n",
       " (39, 0.0074733095),\n",
       " (40, 0.006224074),\n",
       " (41, 0.0074618543),\n",
       " (42, 0.004737943),\n",
       " (43, 0.0053652236),\n",
       " (44, 0.0052625034),\n",
       " (45, 0.006631195),\n",
       " (46, 0.0062454604),\n",
       " (47, 0.004792124),\n",
       " (48, 0.0052448316),\n",
       " (49, 0.0049169706),\n",
       " (50, 0.006490317),\n",
       " (51, 0.0054075858),\n",
       " (52, 0.0055371504),\n",
       " (53, 0.0072401883),\n",
       " (54, 0.005185731),\n",
       " (55, 0.0055658272),\n",
       " (56, 0.004789015),\n",
       " (57, 0.006843374),\n",
       " (58, 0.005091937),\n",
       " (59, 0.006206758),\n",
       " (60, 0.0046403967),\n",
       " (61, 0.022961337),\n",
       " (62, 0.0060754004),\n",
       " (63, 0.00539396),\n",
       " (64, 0.0052359025),\n",
       " (65, 0.004981768),\n",
       " (66, 0.005052674),\n",
       " (67, 0.0051828045),\n",
       " (68, 0.004397833),\n",
       " (69, 0.004885117),\n",
       " (70, 0.0065966453),\n",
       " (71, 0.0067735575),\n",
       " (72, 0.00494186),\n",
       " (73, 0.0047202483),\n",
       " (74, 0.0062367213),\n",
       " (75, 0.006397979),\n",
       " (76, 0.004967439),\n",
       " (77, 0.0091705965),\n",
       " (78, 0.005836124),\n",
       " (79, 0.004873188),\n",
       " (80, 0.0060840184),\n",
       " (81, 0.0048062536),\n",
       " (82, 0.005915918),\n",
       " (83, 0.0050714994),\n",
       " (84, 0.0055051534),\n",
       " (85, 0.0070818053),\n",
       " (86, 0.0061661843),\n",
       " (87, 0.0057552205),\n",
       " (88, 0.0058991928),\n",
       " (89, 0.006193391),\n",
       " (90, 0.0046863086),\n",
       " (91, 0.00585692),\n",
       " (92, 0.0051130317),\n",
       " (93, 0.005790966),\n",
       " (94, 0.0054069115),\n",
       " (95, 0.005013507),\n",
       " (96, 0.0065743057),\n",
       " (97, 0.0054224506),\n",
       " (98, 0.00549765),\n",
       " (99, 0.006339972)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Function check\n",
    "lda = LdaRetrievalModel(doc_repr_2)\n",
    "lda.train_model()\n",
    "\n",
    "# you can now get an LDA vector for a given query in the following way:\n",
    "lda.vectorize_query(\"report\")\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00137-b82100c4-8bc6-4c0b-a37d-3f8eed7a4106",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32d83b6ea79ca3ddb789a7f8805a1b25",
     "grade": false,
     "grade_id": "cell-0e24b727d5908c0e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00138-9da9ac44-4973-497c-ae61-6ae44d57702c",
    "deepnote_cell_height": 98.1875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "114a934f0b9ce696e6cf09d3b8da6a3d",
     "grade": false,
     "grade_id": "cell-b1bffcb970b18aeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Now we can use the `DenseRetrievalModel` class to obtain an LDA search function.\n",
    "You can test your LDA model in the following cell: Try finding queries which are lexically different to documents, but semantically similar - does LDA work well for these queries?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_id": "00139-74e10836-ea8e-40f0-99d4-f5422f0f88e6",
    "deepnote_cell_height": 303,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4419,
    "execution_start": 1645186665847,
    "source_hash": "76222337"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eeda3c5bbd41d2b97d63e07146ab03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_lda = DenseRetrievalRanker(lda, jenson_shannon_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_lda.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00140-3dcd44fb-190f-4b30-a761-4fbdb85b38fe",
    "deepnote_cell_height": 405.375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d7f15863b655119b45f4d89354e5661",
     "grade": false,
     "grade_id": "cell-190cd0854b2791cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 8: Word2Vec/Doc2Vec (20 points) <a class=\"anchor\" id=\"2vec\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "We will implement two other methods here, the Word2Vec model and the Doc2Vec model, also using `gensim`. Word2Vec creates representations of words, not documents, so the word level vectors need to be aggregated to obtain a representation for the document. Here, we will simply take the mean of the vectors.\n",
    "\n",
    "\n",
    "A drawback of these models is that they need a lot of training data. Our dataset is tiny, so in addition to using a model trained on the data, we will also use a pre-trained model for Word2Vec (this will be automatically downloaded).\n",
    "\n",
    "*Note*:\n",
    "1. The code in vectorize_documents / vectorize_query should return gensim-like vectors i.e `[(dim, val), .. (dim, val)]`.\n",
    "2. For Word2Vec: You should also handle the following two cases: (a) A word in the query is not present in the vocabulary of the model and (b) none of the words in the query are present in the model - you can return 0 scores for all documents in this case. For either of these, you can check if a `word` is present in the vocab by using `word in self.model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cell_id": "00141-4813dd67-6ab9-4a66-909c-c9ffb52e292c",
    "deepnote_cell_height": 1767.796875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 5958,
    "execution_start": 1645186670275,
    "is_output_hidden": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ab733608ed14c29c09b36b4e1b6daa",
     "grade": false,
     "grade_id": "cell-2b73759f9baf688f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "69fb62df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:53:27,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 11:53:27,627 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115969 corpus positions)\n",
      "2022-02-22 11:53:27,635 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2022-02-22 11:53:27,636 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2022-02-22 11:53:27,639 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2022-02-22 11:53:27,719 : INFO : collecting all words and their counts\n",
      "2022-02-22 11:53:27,720 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-02-22 11:53:27,738 : INFO : collected 5937 word types from a corpus of 115969 raw words and 3204 sentences\n",
      "2022-02-22 11:53:27,739 : INFO : Loading a fresh vocabulary\n",
      "2022-02-22 11:53:27,749 : INFO : effective_min_count=1 retains 5937 unique words (100% of original 5937, drops 0)\n",
      "2022-02-22 11:53:27,750 : INFO : effective_min_count=1 leaves 115969 word corpus (100% of original 115969, drops 0)\n",
      "2022-02-22 11:53:27,768 : INFO : deleting the raw counts dictionary of 5937 items\n",
      "2022-02-22 11:53:27,769 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-02-22 11:53:27,769 : INFO : downsampling leaves estimated 92346 word corpus (79.6% of prior 115969)\n",
      "2022-02-22 11:53:27,802 : INFO : estimated required memory for 5937 words and 100 dimensions: 7718100 bytes\n",
      "2022-02-22 11:53:27,864 : INFO : resetting layer weights\n",
      "2022-02-22 11:53:29,009 : INFO : training model with 3 workers on 5937 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2022-02-22 11:53:29,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:53:29,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:53:29,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:53:29,087 : INFO : EPOCH - 1 : training on 115969 raw words (92272 effective words) took 0.1s, 1269156 effective words/s\n",
      "2022-02-22 11:53:29,169 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:53:29,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:53:29,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:53:29,180 : INFO : EPOCH - 2 : training on 115969 raw words (92367 effective words) took 0.1s, 1096419 effective words/s\n",
      "2022-02-22 11:53:29,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:53:29,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:53:29,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:53:29,273 : INFO : EPOCH - 3 : training on 115969 raw words (92428 effective words) took 0.1s, 1045225 effective words/s\n",
      "2022-02-22 11:53:29,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:53:29,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:53:29,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:53:29,352 : INFO : EPOCH - 4 : training on 115969 raw words (92202 effective words) took 0.1s, 1253485 effective words/s\n",
      "2022-02-22 11:53:29,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:53:29,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:53:29,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:53:29,447 : INFO : EPOCH - 5 : training on 115969 raw words (92405 effective words) took 0.1s, 1079269 effective words/s\n",
      "2022-02-22 11:53:29,448 : INFO : training on a 579845 raw words (461674 effective words) took 0.4s, 1053363 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.0902741476893425),\n",
       " (1, -0.0880788043141365),\n",
       " (2, -0.018406035378575325),\n",
       " (3, -0.32695960998535156),\n",
       " (4, 0.14231689274311066),\n",
       " (5, -0.7386736869812012),\n",
       " (6, -0.5257108807563782),\n",
       " (7, 0.7575127482414246),\n",
       " (8, 0.1915712207555771),\n",
       " (9, 0.015063393861055374),\n",
       " (10, -0.09974463284015656),\n",
       " (11, 0.004178868606686592),\n",
       " (12, -0.009947031736373901),\n",
       " (13, -0.1766352504491806),\n",
       " (14, 0.39396873116493225),\n",
       " (15, 0.3955567181110382),\n",
       " (16, 0.24758219718933105),\n",
       " (17, -0.17081347107887268),\n",
       " (18, -0.5557881593704224),\n",
       " (19, -0.24836885929107666),\n",
       " (20, -0.25361207127571106),\n",
       " (21, 0.6487570405006409),\n",
       " (22, -0.1645529568195343),\n",
       " (23, 0.2121463418006897),\n",
       " (24, 0.32271653413772583),\n",
       " (25, -0.15166234970092773),\n",
       " (26, -0.8991897106170654),\n",
       " (27, 0.16865724325180054),\n",
       " (28, 0.16648253798484802),\n",
       " (29, 0.28749433159828186),\n",
       " (30, 0.2977105677127838),\n",
       " (31, 0.41600051522254944),\n",
       " (32, -0.3335769772529602),\n",
       " (33, -0.02959802933037281),\n",
       " (34, -0.02381269633769989),\n",
       " (35, -0.6242016553878784),\n",
       " (36, 0.46833372116088867),\n",
       " (37, 0.18152132630348206),\n",
       " (38, -1.053282380104065),\n",
       " (39, 0.30941399931907654),\n",
       " (40, 0.011596382595598698),\n",
       " (41, 0.058974239975214005),\n",
       " (42, 0.11979193240404129),\n",
       " (43, -1.0485053062438965),\n",
       " (44, -0.6600604057312012),\n",
       " (45, -0.009799852967262268),\n",
       " (46, -0.48374804854393005),\n",
       " (47, 0.28531473875045776),\n",
       " (48, 1.3044096231460571),\n",
       " (49, 0.5073286890983582),\n",
       " (50, 0.8807292580604553),\n",
       " (51, -0.16068251430988312),\n",
       " (52, 0.29237619042396545),\n",
       " (53, 0.03642479330301285),\n",
       " (54, 0.45671358704566956),\n",
       " (55, 0.3464159667491913),\n",
       " (56, 0.34098902344703674),\n",
       " (57, -0.011774434708058834),\n",
       " (58, 0.20491944253444672),\n",
       " (59, -0.23802649974822998),\n",
       " (60, 0.6544143557548523),\n",
       " (61, 0.08035141229629517),\n",
       " (62, 0.37138494849205017),\n",
       " (63, -0.0013228128664195538),\n",
       " (64, 0.3332441449165344),\n",
       " (65, 0.13326247036457062),\n",
       " (66, -0.19762422144412994),\n",
       " (67, 0.31614363193511963),\n",
       " (68, -0.7750536799430847),\n",
       " (69, -0.13940538465976715),\n",
       " (70, -0.23408561944961548),\n",
       " (71, 0.2634069323539734),\n",
       " (72, 0.5616437792778015),\n",
       " (73, -0.5247160792350769),\n",
       " (74, 0.1618518978357315),\n",
       " (75, -0.6517308354377747),\n",
       " (76, 0.36057108640670776),\n",
       " (77, -0.04241016507148743),\n",
       " (78, -0.8915173411369324),\n",
       " (79, -0.3764938414096832),\n",
       " (80, 0.5923453569412231),\n",
       " (81, 0.17715643346309662),\n",
       " (82, -0.6514021158218384),\n",
       " (83, 0.17044200003147125),\n",
       " (84, -0.45407989621162415),\n",
       " (85, 0.7177895903587341),\n",
       " (86, -0.27758294343948364),\n",
       " (87, -0.42464104294776917),\n",
       " (88, 0.17556501924991608),\n",
       " (89, 0.19845204055309296),\n",
       " (90, 0.9716867804527283),\n",
       " (91, -0.04332949221134186),\n",
       " (92, 0.3913642168045044),\n",
       " (93, -0.18590444326400757),\n",
       " (94, 0.5105605721473694),\n",
       " (95, 0.11837754398584366),\n",
       " (96, 0.1363171935081482),\n",
       " (97, -0.13938187062740326),\n",
       " (98, -0.1186819076538086),\n",
       " (99, 0.5826388597488403)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "class W2VRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "\n",
    "        # the dimensionality of the vectors\n",
    "        self.size = 100\n",
    "        self.min_count = 1\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Trains the W2V model\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        self.model = Word2Vec(\n",
    "            sentences=self.documents, size=self.size, min_count=self.min_count\n",
    "        )\n",
    "\n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "        Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        vectors = {}\n",
    "        for (doc_id, doc) in self.doc_repr:\n",
    "            # initializations for this document\n",
    "            doc_vector = np.zeros(self.size)\n",
    "            n_words = 0\n",
    "            for word in doc:\n",
    "                n_words += 1\n",
    "                # check that current word in doc in our model (needed for pretrained)\n",
    "                try:\n",
    "                    doc_vector += self.model.wv[word]\n",
    "                except KeyError:\n",
    "                    # don't count this word\n",
    "                    n_words -= 1\n",
    "                    continue\n",
    "            if n_words > 0:\n",
    "                # aggregate by taking the mean over the found words\n",
    "                doc_vector = doc_vector / n_words\n",
    "            # convert to weird gensim format that is desired\n",
    "            doc_vector = [(i, el) for i, el in enumerate(doc_vector)]\n",
    "            # and save to our dictionary\n",
    "            vectors[doc_id] = doc_vector\n",
    "\n",
    "        return vectors\n",
    "\n",
    "    def vectorize_query(self, query):\n",
    "        \"\"\"\n",
    "        Vectorizes the query using the W2V model\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        query = process_text(query, **config_2)\n",
    "        # initialize query vector\n",
    "        query_vec = np.zeros(self.size)\n",
    "        # handle valid queries (i.e. processing hasn't made it empty)\n",
    "        if len(query) > 0:\n",
    "            n_words = 0\n",
    "            for word in query:\n",
    "                n_words += 1\n",
    "                # check that current word in query in our vocab\n",
    "                try:\n",
    "                    query_vec += self.model.wv[word]\n",
    "                except KeyError:\n",
    "                    # don't count this word\n",
    "                    n_words -= 1\n",
    "                    continue\n",
    "                if n_words > 0:\n",
    "                    # aggregate by taking the mean over the found words\n",
    "                    query_vec = query_vec / n_words\n",
    "        # convert to weird gensim format that is desired\n",
    "        query_vec = [(i, el) for i, el in enumerate(query_vec)]\n",
    "        return query_vec\n",
    "\n",
    "\n",
    "class W2VPretrainedRetrievalModel(W2VRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        self.model_name = \"word2vec-google-news-300\"\n",
    "        self.size = 300\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Loads the pretrained model\n",
    "        \"\"\"\n",
    "        self.model = g_downloader.load(self.model_name)\n",
    "\n",
    "\n",
    "w2v = W2VRetrievalModel(doc_repr_2)\n",
    "w2v.train_model()\n",
    "\n",
    "# you can now get a W2V vector for a given query in the following way:\n",
    "w2v.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cell_id": "00142-4fd5a03c-b76f-4fd4-b70f-2670bd4416e5",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 11300785,
    "execution_start": 1645186676074,
    "lines_to_next_cell": 2,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f92b5c5a8c6c4b80652b94223209ab0b",
     "grade": true,
     "grade_id": "cell-b31c0f8d214b8bdf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "3f3d7257"
   },
   "outputs": [],
   "source": [
    "assert len(w2v.vectorize_query(\"report\")) == 100\n",
    "assert len(w2v.vectorize_query(\"this is a sentence that is not mellifluous\")) == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00143-dca6cd62-6d5c-4c14-8cc4-7299f1f8390e",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dfaabebcb06f308a7ca61fdc5d369e7",
     "grade": false,
     "grade_id": "cell-c2614fa067386384",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cell_id": "00144-7801f559-0e0a-405d-84bf-a02dd1269f5a",
    "deepnote_cell_height": 304.9375,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     40.375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 611,
    "execution_start": 1645186676087,
    "source_hash": "8ab4bf3a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:53:29,469 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 11:53:29,622 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115969 corpus positions)\n",
      "2022-02-22 11:53:29,629 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2022-02-22 11:53:29,629 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2022-02-22 11:53:29,633 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2022-02-22 11:53:29,851 : INFO : loading projection weights from /Users/thesofakillers/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2022-02-22 11:54:22,785 : INFO : loaded (3000000, 300) matrix from /Users/thesofakillers/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, -0.142578125),\n",
       " (1, -0.1640625),\n",
       " (2, -0.09033203125),\n",
       " (3, -0.1123046875),\n",
       " (4, 0.10009765625),\n",
       " (5, -0.041259765625),\n",
       " (6, 0.048828125),\n",
       " (7, -0.13671875),\n",
       " (8, 0.1962890625),\n",
       " (9, -0.134765625),\n",
       " (10, -0.017578125),\n",
       " (11, 0.0322265625),\n",
       " (12, 0.09521484375),\n",
       " (13, -0.10595703125),\n",
       " (14, -0.169921875),\n",
       " (15, 0.041015625),\n",
       " (16, -0.263671875),\n",
       " (17, -0.006317138671875),\n",
       " (18, -0.177734375),\n",
       " (19, -0.240234375),\n",
       " (20, 0.3515625),\n",
       " (21, -0.01220703125),\n",
       " (22, -0.162109375),\n",
       " (23, -0.12060546875),\n",
       " (24, 0.043212890625),\n",
       " (25, 0.10986328125),\n",
       " (26, 0.052490234375),\n",
       " (27, 0.1787109375),\n",
       " (28, -0.1455078125),\n",
       " (29, 0.1376953125),\n",
       " (30, -0.08203125),\n",
       " (31, -0.283203125),\n",
       " (32, -0.10888671875),\n",
       " (33, -0.2890625),\n",
       " (34, 0.072265625),\n",
       " (35, -0.04736328125),\n",
       " (36, 0.040283203125),\n",
       " (37, 0.06787109375),\n",
       " (38, 0.11669921875),\n",
       " (39, 0.00083160400390625),\n",
       " (40, 0.068359375),\n",
       " (41, 0.1201171875),\n",
       " (42, -0.08837890625),\n",
       " (43, 0.337890625),\n",
       " (44, -0.044677734375),\n",
       " (45, -0.0301513671875),\n",
       " (46, 0.0076904296875),\n",
       " (47, -0.0211181640625),\n",
       " (48, -0.25390625),\n",
       " (49, 0.1494140625),\n",
       " (50, 0.3984375),\n",
       " (51, 0.0216064453125),\n",
       " (52, -0.023193359375),\n",
       " (53, 0.00634765625),\n",
       " (54, 0.00823974609375),\n",
       " (55, -0.1689453125),\n",
       " (56, 0.037353515625),\n",
       " (57, -0.0634765625),\n",
       " (58, 0.1171875),\n",
       " (59, -0.1484375),\n",
       " (60, -0.07861328125),\n",
       " (61, 0.369140625),\n",
       " (62, -0.224609375),\n",
       " (63, 0.173828125),\n",
       " (64, 0.01385498046875),\n",
       " (65, 0.1875),\n",
       " (66, -0.10107421875),\n",
       " (67, 0.037841796875),\n",
       " (68, 0.0021209716796875),\n",
       " (69, -0.05126953125),\n",
       " (70, 0.09619140625),\n",
       " (71, -0.05712890625),\n",
       " (72, 0.10595703125),\n",
       " (73, -0.02099609375),\n",
       " (74, 0.1611328125),\n",
       " (75, 0.09765625),\n",
       " (76, 0.038330078125),\n",
       " (77, 0.2197265625),\n",
       " (78, 0.1064453125),\n",
       " (79, 0.0859375),\n",
       " (80, 0.1796875),\n",
       " (81, -0.0830078125),\n",
       " (82, -0.033203125),\n",
       " (83, 0.041015625),\n",
       " (84, -0.06494140625),\n",
       " (85, 0.0198974609375),\n",
       " (86, 0.1337890625),\n",
       " (87, -0.09765625),\n",
       " (88, -0.193359375),\n",
       " (89, -0.2353515625),\n",
       " (90, 0.1904296875),\n",
       " (91, 0.0024871826171875),\n",
       " (92, -0.0157470703125),\n",
       " (93, 0.0322265625),\n",
       " (94, -0.2197265625),\n",
       " (95, -0.09130859375),\n",
       " (96, 0.021240234375),\n",
       " (97, 0.158203125),\n",
       " (98, 0.298828125),\n",
       " (99, -0.328125),\n",
       " (100, 0.057373046875),\n",
       " (101, -0.04638671875),\n",
       " (102, 0.11328125),\n",
       " (103, -0.1015625),\n",
       " (104, 0.1806640625),\n",
       " (105, -0.025146484375),\n",
       " (106, -0.166015625),\n",
       " (107, -0.09619140625),\n",
       " (108, 0.018798828125),\n",
       " (109, -0.1943359375),\n",
       " (110, 0.1494140625),\n",
       " (111, -0.056640625),\n",
       " (112, -0.10693359375),\n",
       " (113, -0.150390625),\n",
       " (114, -0.17578125),\n",
       " (115, 0.11279296875),\n",
       " (116, 0.04931640625),\n",
       " (117, 0.2197265625),\n",
       " (118, 0.318359375),\n",
       " (119, 0.1572265625),\n",
       " (120, -0.29296875),\n",
       " (121, 0.10498046875),\n",
       " (122, -0.296875),\n",
       " (123, -0.013427734375),\n",
       " (124, 0.0908203125),\n",
       " (125, 0.0125732421875),\n",
       " (126, -0.051513671875),\n",
       " (127, -0.12890625),\n",
       " (128, 0.01446533203125),\n",
       " (129, 0.12060546875),\n",
       " (130, -0.10107421875),\n",
       " (131, -0.111328125),\n",
       " (132, 0.06396484375),\n",
       " (133, -0.052978515625),\n",
       " (134, -0.043212890625),\n",
       " (135, -0.012939453125),\n",
       " (136, -0.027587890625),\n",
       " (137, -0.09716796875),\n",
       " (138, -0.2021484375),\n",
       " (139, 0.123046875),\n",
       " (140, -0.04248046875),\n",
       " (141, 0.173828125),\n",
       " (142, -0.013671875),\n",
       " (143, 0.1015625),\n",
       " (144, -0.00093841552734375),\n",
       " (145, -0.03564453125),\n",
       " (146, 0.30078125),\n",
       " (147, -0.068359375),\n",
       " (148, -0.05615234375),\n",
       " (149, 0.03759765625),\n",
       " (150, 0.06591796875),\n",
       " (151, 0.040283203125),\n",
       " (152, 0.01190185546875),\n",
       " (153, 0.09619140625),\n",
       " (154, 0.3671875),\n",
       " (155, -0.279296875),\n",
       " (156, -0.052001953125),\n",
       " (157, -0.10693359375),\n",
       " (158, -0.134765625),\n",
       " (159, -0.046142578125),\n",
       " (160, 0.25),\n",
       " (161, 0.00567626953125),\n",
       " (162, -0.014404296875),\n",
       " (163, -0.031005859375),\n",
       " (164, -0.060302734375),\n",
       " (165, 0.10595703125),\n",
       " (166, 0.37890625),\n",
       " (167, 0.058837890625),\n",
       " (168, 0.123046875),\n",
       " (169, -0.115234375),\n",
       " (170, 0.1494140625),\n",
       " (171, -0.1640625),\n",
       " (172, -0.2333984375),\n",
       " (173, -0.07763671875),\n",
       " (174, 0.0267333984375),\n",
       " (175, -0.0211181640625),\n",
       " (176, 0.1943359375),\n",
       " (177, -0.05615234375),\n",
       " (178, -0.006439208984375),\n",
       " (179, -0.169921875),\n",
       " (180, -0.11865234375),\n",
       " (181, -0.0673828125),\n",
       " (182, -0.06884765625),\n",
       " (183, -0.0869140625),\n",
       " (184, -0.1015625),\n",
       " (185, 0.01416015625),\n",
       " (186, -0.201171875),\n",
       " (187, 0.09814453125),\n",
       " (188, -0.01025390625),\n",
       " (189, 0.1875),\n",
       " (190, 0.1962890625),\n",
       " (191, -0.220703125),\n",
       " (192, -0.1962890625),\n",
       " (193, -0.07373046875),\n",
       " (194, 0.06640625),\n",
       " (195, -0.1337890625),\n",
       " (196, 0.18359375),\n",
       " (197, -0.2001953125),\n",
       " (198, 0.1982421875),\n",
       " (199, 0.05029296875),\n",
       " (200, 0.0299072265625),\n",
       " (201, 0.0177001953125),\n",
       " (202, -0.193359375),\n",
       " (203, -0.09619140625),\n",
       " (204, -0.1025390625),\n",
       " (205, 0.212890625),\n",
       " (206, -0.0299072265625),\n",
       " (207, 0.1435546875),\n",
       " (208, 0.041015625),\n",
       " (209, -0.2119140625),\n",
       " (210, 0.2080078125),\n",
       " (211, 0.1376953125),\n",
       " (212, -0.0196533203125),\n",
       " (213, 0.01495361328125),\n",
       " (214, -0.09765625),\n",
       " (215, 0.2431640625),\n",
       " (216, 0.080078125),\n",
       " (217, 0.08251953125),\n",
       " (218, 0.0986328125),\n",
       " (219, 0.056884765625),\n",
       " (220, 0.04248046875),\n",
       " (221, 0.06884765625),\n",
       " (222, -0.035400390625),\n",
       " (223, -0.076171875),\n",
       " (224, -0.00016117095947265625),\n",
       " (225, -0.0751953125),\n",
       " (226, 0.224609375),\n",
       " (227, 0.1513671875),\n",
       " (228, 0.1005859375),\n",
       " (229, 0.10986328125),\n",
       " (230, 0.0238037109375),\n",
       " (231, 0.08837890625),\n",
       " (232, 0.061767578125),\n",
       " (233, -0.10791015625),\n",
       " (234, 0.062255859375),\n",
       " (235, 0.0034332275390625),\n",
       " (236, 0.08056640625),\n",
       " (237, 0.10693359375),\n",
       " (238, 0.0888671875),\n",
       " (239, -0.2373046875),\n",
       " (240, 0.06494140625),\n",
       " (241, 0.01019287109375),\n",
       " (242, -0.08837890625),\n",
       " (243, -0.33203125),\n",
       " (244, 0.004669189453125),\n",
       " (245, 0.212890625),\n",
       " (246, 0.0859375),\n",
       " (247, 0.0203857421875),\n",
       " (248, 0.045654296875),\n",
       " (249, 0.1484375),\n",
       " (250, 0.1181640625),\n",
       " (251, 0.0556640625),\n",
       " (252, -0.1728515625),\n",
       " (253, -0.125),\n",
       " (254, -0.025390625),\n",
       " (255, -0.318359375),\n",
       " (256, 0.0311279296875),\n",
       " (257, 0.0859375),\n",
       " (258, -0.0419921875),\n",
       " (259, 0.15625),\n",
       " (260, 0.1611328125),\n",
       " (261, 0.1982421875),\n",
       " (262, -0.10009765625),\n",
       " (263, 0.203125),\n",
       " (264, 0.12890625),\n",
       " (265, 0.2333984375),\n",
       " (266, -0.267578125),\n",
       " (267, 0.05517578125),\n",
       " (268, 0.048828125),\n",
       " (269, 0.072265625),\n",
       " (270, 0.244140625),\n",
       " (271, 0.244140625),\n",
       " (272, 0.056884765625),\n",
       " (273, -0.0546875),\n",
       " (274, -0.03369140625),\n",
       " (275, -0.12060546875),\n",
       " (276, 0.034912109375),\n",
       " (277, -0.1455078125),\n",
       " (278, 0.08740234375),\n",
       " (279, -0.0830078125),\n",
       " (280, 0.0172119140625),\n",
       " (281, 0.1435546875),\n",
       " (282, -0.12255859375),\n",
       " (283, 0.1796875),\n",
       " (284, 0.130859375),\n",
       " (285, -0.1650390625),\n",
       " (286, 0.01275634765625),\n",
       " (287, 0.16015625),\n",
       " (288, -0.0311279296875),\n",
       " (289, 0.08203125),\n",
       " (290, 0.173828125),\n",
       " (291, -0.16796875),\n",
       " (292, 0.130859375),\n",
       " (293, 0.08544921875),\n",
       " (294, -0.2109375),\n",
       " (295, -0.130859375),\n",
       " (296, -0.0289306640625),\n",
       " (297, -0.10546875),\n",
       " (298, 0.08447265625),\n",
       " (299, -0.1416015625)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pretrained = W2VPretrainedRetrievalModel(doc_repr_2)\n",
    "w2v_pretrained.train_model()\n",
    "\n",
    "# you can now get an W2V vector for a given query in the following way:\n",
    "w2v_pretrained.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cell_id": "00145-65d4934b-cf4d-414e-8525-dff2c72b8313",
    "deepnote_cell_height": 198.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 1303,
    "execution_start": 1645186676707,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0822845afb5eafe5ddb1ffeaa4f4942a",
     "grade": true,
     "grade_id": "cell-1b1466f8ce516f42",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "d4727a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "\n",
    "print(len(w2v_pretrained.vectorize_query(\"report\")))\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cell_id": "00146-c209a2da-8745-4211-89bc-c716df8bb9ce",
    "deepnote_cell_height": 303,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1086,
    "execution_start": 1645187351976,
    "source_hash": "8865e3e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e13d8d766c41c2a82ee9bea08b0478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_w2v = DenseRetrievalRanker(w2v, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_w2v.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_id": "00147-e85d21fc-9447-411a-8131-fda7837fdf00",
    "deepnote_cell_height": 306.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 174,
    "execution_start": 1645187355913,
    "source_hash": "8fd1ee96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4a0c4488eb46589dd9688dff346cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_w2v_pretrained = DenseRetrievalRanker(w2v_pretrained, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_w2v_pretrained.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00148-18690d99-32f6-4368-8791-fa8a660313c5",
    "deepnote_cell_height": 91,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51b778984fd60757974f51047c61eb15",
     "grade": false,
     "grade_id": "cell-b92f701cbc706108",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (10 points):**\n",
    "For Doc2Vec, you will need to create a list of `TaggedDocument` instead of using the `self.corpus` or `self.documents` variable. Use the document id as the 'tag'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cell_id": "00149-f7ea4b9a-161d-4405-9440-ab008f8bc0ac",
    "deepnote_cell_height": 2261,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 33704,
    "execution_start": 1645187360265,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f60fdeb97febb7f4a6fd5bf109aac20",
     "grade": false,
     "grade_id": "cell-680facdcc98a19ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "ad328353",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 11:54:26,594 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-22 11:54:26,835 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115969 corpus positions)\n",
      "2022-02-22 11:54:27,010 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2022-02-22 11:54:27,011 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2022-02-22 11:54:27,016 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2022-02-22 11:54:27,337 : INFO : collecting all words and their counts\n",
      "2022-02-22 11:54:27,348 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2022-02-22 11:54:27,616 : INFO : collected 5937 word types and 3204 unique tags from a corpus of 3204 examples and 115969 words\n",
      "2022-02-22 11:54:27,618 : INFO : Loading a fresh vocabulary\n",
      "2022-02-22 11:54:27,649 : INFO : effective_min_count=1 retains 5937 unique words (100% of original 5937, drops 0)\n",
      "2022-02-22 11:54:27,672 : INFO : effective_min_count=1 leaves 115969 word corpus (100% of original 115969, drops 0)\n",
      "2022-02-22 11:54:27,695 : INFO : deleting the raw counts dictionary of 5937 items\n",
      "2022-02-22 11:54:27,696 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2022-02-22 11:54:27,697 : INFO : downsampling leaves estimated 92346 word corpus (79.6% of prior 115969)\n",
      "2022-02-22 11:54:27,721 : INFO : estimated required memory for 5937 words and 100 dimensions: 9640500 bytes\n",
      "2022-02-22 11:54:27,723 : INFO : resetting layer weights\n",
      "2022-02-22 11:54:29,547 : INFO : training model with 3 workers on 5937 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2022-02-22 11:54:29,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:29,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:29,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:29,866 : INFO : EPOCH - 1 : training on 115969 raw words (95660 effective words) took 0.3s, 316320 effective words/s\n",
      "2022-02-22 11:54:30,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:30,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:30,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:30,173 : INFO : EPOCH - 2 : training on 115969 raw words (95586 effective words) took 0.3s, 316456 effective words/s\n",
      "2022-02-22 11:54:30,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:30,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:30,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:30,526 : INFO : EPOCH - 3 : training on 115969 raw words (95475 effective words) took 0.3s, 276441 effective words/s\n",
      "2022-02-22 11:54:30,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:30,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:30,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:30,816 : INFO : EPOCH - 4 : training on 115969 raw words (95483 effective words) took 0.3s, 337422 effective words/s\n",
      "2022-02-22 11:54:31,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:31,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:31,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:31,136 : INFO : EPOCH - 5 : training on 115969 raw words (95600 effective words) took 0.3s, 305487 effective words/s\n",
      "2022-02-22 11:54:31,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:31,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:31,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:31,477 : INFO : EPOCH - 6 : training on 115969 raw words (95628 effective words) took 0.3s, 287636 effective words/s\n",
      "2022-02-22 11:54:31,743 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:31,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:31,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:31,764 : INFO : EPOCH - 7 : training on 115969 raw words (95421 effective words) took 0.3s, 340655 effective words/s\n",
      "2022-02-22 11:54:32,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:32,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:32,075 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:32,076 : INFO : EPOCH - 8 : training on 115969 raw words (95663 effective words) took 0.3s, 311838 effective words/s\n",
      "2022-02-22 11:54:32,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:32,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:32,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:32,632 : INFO : EPOCH - 9 : training on 115969 raw words (95440 effective words) took 0.5s, 179111 effective words/s\n",
      "2022-02-22 11:54:32,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:33,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:33,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:33,018 : INFO : EPOCH - 10 : training on 115969 raw words (95608 effective words) took 0.4s, 251504 effective words/s\n",
      "2022-02-22 11:54:33,301 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:33,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:33,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:33,325 : INFO : EPOCH - 11 : training on 115969 raw words (95557 effective words) took 0.3s, 318209 effective words/s\n",
      "2022-02-22 11:54:33,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:33,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:33,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:33,624 : INFO : EPOCH - 12 : training on 115969 raw words (95517 effective words) took 0.3s, 325855 effective words/s\n",
      "2022-02-22 11:54:33,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:33,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:33,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:33,923 : INFO : EPOCH - 13 : training on 115969 raw words (95472 effective words) took 0.3s, 330375 effective words/s\n",
      "2022-02-22 11:54:34,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:34,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:34,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:34,234 : INFO : EPOCH - 14 : training on 115969 raw words (95578 effective words) took 0.3s, 313344 effective words/s\n",
      "2022-02-22 11:54:34,517 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:34,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:34,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:34,537 : INFO : EPOCH - 15 : training on 115969 raw words (95596 effective words) took 0.3s, 326378 effective words/s\n",
      "2022-02-22 11:54:34,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:34,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:34,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:34,817 : INFO : EPOCH - 16 : training on 115969 raw words (95483 effective words) took 0.3s, 350991 effective words/s\n",
      "2022-02-22 11:54:35,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:35,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:35,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:35,115 : INFO : EPOCH - 17 : training on 115969 raw words (95545 effective words) took 0.3s, 325768 effective words/s\n",
      "2022-02-22 11:54:35,413 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:35,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:35,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:35,550 : INFO : EPOCH - 18 : training on 115969 raw words (95512 effective words) took 0.4s, 223956 effective words/s\n",
      "2022-02-22 11:54:36,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:36,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:36,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:36,084 : INFO : EPOCH - 19 : training on 115969 raw words (95674 effective words) took 0.5s, 189891 effective words/s\n",
      "2022-02-22 11:54:36,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-02-22 11:54:36,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-02-22 11:54:36,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-02-22 11:54:36,570 : INFO : EPOCH - 20 : training on 115969 raw words (95605 effective words) took 0.5s, 199280 effective words/s\n",
      "2022-02-22 11:54:36,570 : INFO : training on a 2319380 raw words (1911103 effective words) took 7.0s, 272150 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.10123092),\n",
       " (1, 0.056053888),\n",
       " (2, -0.049866445),\n",
       " (3, -0.02389549),\n",
       " (4, -0.01951382),\n",
       " (5, -0.06116458),\n",
       " (6, -0.02969487),\n",
       " (7, 0.04750476),\n",
       " (8, 0.06811353),\n",
       " (9, -0.011387921),\n",
       " (10, 0.044818103),\n",
       " (11, 0.02312302),\n",
       " (12, 0.023320356),\n",
       " (13, -0.07262612),\n",
       " (14, 0.020377185),\n",
       " (15, 0.033094145),\n",
       " (16, 0.007701487),\n",
       " (17, 0.0057898113),\n",
       " (18, -0.05617214),\n",
       " (19, -0.05881749),\n",
       " (20, -0.064016975),\n",
       " (21, 0.07517376),\n",
       " (22, -0.049733374),\n",
       " (23, -0.0165358),\n",
       " (24, 0.043660846),\n",
       " (25, -0.0252918),\n",
       " (26, -0.09076827),\n",
       " (27, 0.03172994),\n",
       " (28, 0.03649448),\n",
       " (29, 0.04347303),\n",
       " (30, 0.050682046),\n",
       " (31, 0.061241772),\n",
       " (32, 0.0025545757),\n",
       " (33, -0.020249777),\n",
       " (34, 0.01341199),\n",
       " (35, -0.035759944),\n",
       " (36, 0.108048156),\n",
       " (37, -0.01851519),\n",
       " (38, -0.08908697),\n",
       " (39, -0.034545172),\n",
       " (40, 0.027170558),\n",
       " (41, -0.018688664),\n",
       " (42, -0.054179195),\n",
       " (43, -0.12870902),\n",
       " (44, -0.013563063),\n",
       " (45, 0.036462042),\n",
       " (46, -0.056207348),\n",
       " (47, 0.025305025),\n",
       " (48, 0.12785974),\n",
       " (49, 0.040124413),\n",
       " (50, 0.087721705),\n",
       " (51, -0.053991124),\n",
       " (52, 0.06491477),\n",
       " (53, 0.006871138),\n",
       " (54, 0.07455836),\n",
       " (55, 0.0046668896),\n",
       " (56, 0.021715509),\n",
       " (57, 0.004800208),\n",
       " (58, -0.00042916826),\n",
       " (59, 0.0055223117),\n",
       " (60, 0.08060897),\n",
       " (61, 0.034623623),\n",
       " (62, -0.062392287),\n",
       " (63, 0.07197196),\n",
       " (64, 0.052511595),\n",
       " (65, 0.07650145),\n",
       " (66, -0.04401847),\n",
       " (67, 0.04886763),\n",
       " (68, -0.06536034),\n",
       " (69, 0.00297591),\n",
       " (70, -0.027048664),\n",
       " (71, 0.040871818),\n",
       " (72, 0.017233947),\n",
       " (73, -0.04735968),\n",
       " (74, -0.015505968),\n",
       " (75, 0.02374588),\n",
       " (76, 0.012442593),\n",
       " (77, 0.04732791),\n",
       " (78, -0.021232558),\n",
       " (79, -0.04551973),\n",
       " (80, 0.07211001),\n",
       " (81, 0.022768116),\n",
       " (82, -0.036736798),\n",
       " (83, -0.06390281),\n",
       " (84, 0.0069320407),\n",
       " (85, 0.13638142),\n",
       " (86, -0.10125667),\n",
       " (87, -0.027329722),\n",
       " (88, 0.01506266),\n",
       " (89, 0.011148654),\n",
       " (90, 0.068304054),\n",
       " (91, -0.0044439496),\n",
       " (92, 0.027220875),\n",
       " (93, -0.04497067),\n",
       " (94, 0.070219934),\n",
       " (95, -0.0069855857),\n",
       " (96, 0.038815748),\n",
       " (97, 0.044548523),\n",
       " (98, 0.0034908003),\n",
       " (99, 0.057756163)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "class D2VRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "\n",
    "        self.vector_size = 100\n",
    "        self.min_count = 1\n",
    "        self.epochs = 20\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.tagged_documents = [\n",
    "            TaggedDocument(doc, [doc_id]) for doc_id, doc in self.doc_repr\n",
    "        ]\n",
    "\n",
    "    def train_model(self):\n",
    "        # YOUR CODE HERE\n",
    "        self.model = Doc2Vec(\n",
    "            documents=self.tagged_documents,\n",
    "            vector_size=self.vector_size,\n",
    "            epochs=self.epochs,\n",
    "            min_count=self.min_count,\n",
    "        )\n",
    "\n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "        Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        vectors = {}\n",
    "        for (doc_id, doc) in self.doc_repr:\n",
    "            doc_vec = self.model.docvecs[doc_id]\n",
    "            # conver to weird gensim format\n",
    "            doc_vec = [(i, el) for i, el in enumerate(doc_vec)]\n",
    "            # store\n",
    "            vectors[doc_id] = doc_vec\n",
    "        return vectors\n",
    "\n",
    "    def vectorize_query(self, query):\n",
    "        # YOUR CODE HERE\n",
    "        query = process_text(query, **config_2)\n",
    "        query_vec = self.model.infer_vector(query)\n",
    "        # conver to weird gensim format\n",
    "        query_vec = [(i, el) for i, el in enumerate(query_vec)]\n",
    "        return query_vec\n",
    "\n",
    "\n",
    "d2v = D2VRetrievalModel(doc_repr_2)\n",
    "d2v.train_model()\n",
    "\n",
    "\n",
    "# # you can now get an LSI vector for a given query in the following way:\n",
    "d2v.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cell_id": "00150-51d38d3e-9d84-4728-935b-b2266a0f7700",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 13,
    "execution_start": 1645187446843,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e83a363a9d4f136efbdde1426a83925e",
     "grade": true,
     "grade_id": "cell-5e2c5e0c9a2e8cb5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "28110d30"
   },
   "outputs": [],
   "source": [
    "#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00151-fb85191e-b51e-42ca-812f-693c5a17802d",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bb46bf6b9be1e0ca66f0b0bc6260ecb",
     "grade": false,
     "grade_id": "cell-8a49d414f798a595",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cell_id": "00152-f0e8290b-0789-4c20-965c-0a941de12a6d",
    "deepnote_cell_height": 303,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 302,
    "execution_start": 1645187449617,
    "source_hash": "2beb5e63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cec480462f349ef964ea203f0b1cabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_d2v = DenseRetrievalRanker(d2v, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_d2v.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00153-7795ce30-661e-4988-b26a-e3ed09ce3615",
    "deepnote_cell_height": 168.171875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "363ec36c1d03d9f9e1c2045a6e193c14",
     "grade": false,
     "grade_id": "cell-3529ae29eece7b97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 9: Re-ranking (10 points) <a class=\"anchor\" id=\"reranking\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "To motivate the re-ranking perspective (i.e retrieve with lexical method + rerank with a semantic method), let's search using semantic methods and compare it to BM25's performance, along with their runtime:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_id": "00154-4c11daad-82ca-4156-9d9b-7d9457aaf21b",
    "deepnote_cell_height": 567.875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 22802,
    "execution_start": 1645187474568,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5755f70e3eb28abc65d14d80125338af",
     "grade": false,
     "grade_id": "cell-f8f43bf5ae383128",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "3fb54859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25: \n",
      "1.87 ms  121 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n",
      "LSI: \n",
      "848 ms  120 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "LDA: \n",
      "241 ms  26.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "W2V: \n",
      "719 ms  34.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "W2V(Pretrained): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05 s  135 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "D2V:\n",
      "3.17 s  154 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "query = \"algebraic functions\"\n",
    "print(\"BM25: \")\n",
    "%timeit bm25_search(query, 2)\n",
    "print(\"LSI: \")\n",
    "%timeit drm_lsi.search(query)\n",
    "print(\"LDA: \")\n",
    "%timeit drm_lda.search(query)\n",
    "print(\"W2V: \")\n",
    "%timeit drm_w2v.search(query)\n",
    "print(\"W2V(Pretrained): \")\n",
    "%timeit drm_w2v_pretrained.search(query)\n",
    "print(\"D2V:\")\n",
    "%timeit drm_d2v.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00155-48f43fee-cf35-4878-adef-f41c0c70d38b",
    "deepnote_cell_height": 165.375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae398da0a8c23c95bcbb0023b7ec6f34",
     "grade": false,
     "grade_id": "cell-db5ff09f97841af7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Implementation (10 points):**\n",
    "Re-ranking involves retrieving a small set of documents using simple but fast methods like BM25 and then re-ranking them with the aid of semantic methods such as LDA or LSI. Implement the following class, which takes in an `initial_retrieval_fn` - the initial retrieval function and `vsrm` - an instance of the `VectorSpaceRetrievalModel` class (i.e LSI/LDA) as input. The search function should first retrieve an initial list of K documents, and then these documents are re-ranked using a semantic method. This not only makes retrieval faster, but semantic methods perform poorly when used in isolation, as you will find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cell_id": "00156-e15452e3-f043-4451-be79-5e3c6e3f889e",
    "deepnote_cell_height": 639,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 0,
    "execution_start": 1645189040776,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63b6b05a676a2ae3f08d8bed1bc59428",
     "grade": false,
     "grade_id": "cell-5bf47600d1a0c507",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "fa2995d"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "class DenseRerankingModel:\n",
    "    def __init__(self, initial_retrieval_fn, vsrm, similarity_fn):\n",
    "        \"\"\"\n",
    "        initial_retrieval_fn: takes in a query and returns a list of [(doc_id, score)] (sorted)\n",
    "        vsrm: instance of `VectorSpaceRetrievalModel`\n",
    "        similarity_fn: function instance that takes in two vectors\n",
    "                        and returns a similarity score e.g cosine_sim defined earlier\n",
    "        \"\"\"\n",
    "        self.ret = initial_retrieval_fn\n",
    "        self.vsrm = vsrm\n",
    "        self.similarity_fn = similarity_fn\n",
    "        self.vectorized_documents = vsrm.vectorize_documents()\n",
    "\n",
    "        assert len(self.vectorized_documents) == len(doc_repr_2)\n",
    "\n",
    "    def search(self, query, K=50):\n",
    "        \"\"\"\n",
    "        First, retrieve the top K results using the retrieval function\n",
    "        Then, re-rank the results using the VSRM instance\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        top_k = self.ret(query)[:K]\n",
    "        results = {}\n",
    "        for doc_id, _score in top_k:\n",
    "            doc_vector = self.vectorized_documents[doc_id]\n",
    "            query_vector = self.vsrm.vectorize_query(query)\n",
    "            new_score = self.similarity_fn(doc_vector, query_vector)\n",
    "            results[doc_id] = new_score\n",
    "        # convert results to list and sort descending\n",
    "        results = sorted(list(results.items()), key=lambda x: x[1], reverse=True)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "cell_id": "00157-3538784a-efa2-4b36-b167-d05248360ac1",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 5334,
    "execution_start": 1645189060550,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "334ab5af96976265cace682ab82a7387",
     "grade": true,
     "grade_id": "cell-52c6d18a4c0b4882",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "f5babc28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "##### Function check\n",
    "bm25_search_2 = partial(bm25_search, index_set=2)\n",
    "lsi_rerank = DenseRerankingModel(bm25_search_2, lsi, cosine_sim)\n",
    "lda_rerank = DenseRerankingModel(bm25_search_2, lda, jenson_shannon_sim)\n",
    "w2v_rerank = DenseRerankingModel(bm25_search_2, w2v, cosine_sim)\n",
    "w2v_pretrained_rerank = DenseRerankingModel(bm25_search_2, w2v_pretrained, cosine_sim)\n",
    "d2v_rerank = DenseRerankingModel(bm25_search_2, d2v, cosine_sim)\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00158-5fbe0f74-4068-4e6e-9f3b-854b724106d7",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd904253f45f84e63bab3a69729058fc",
     "grade": false,
     "grade_id": "cell-93215dfe6bcf7cff",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\\#### Please do not change this. This cell is used for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00159-f5e855d2-5764-440e-a8e4-10860c9a9ac3",
    "deepnote_cell_height": 55,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b592e60292bfe3d9ef2930a354c4077a",
     "grade": false,
     "grade_id": "cell-aa694ff55fa91e7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Now, let us time the new search functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_id": "00160-933196c3-9483-4ca6-a4a6-ca24aad69936",
    "deepnote_cell_height": 530.0625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 38436,
    "execution_start": 1645189086450,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "338c7e3528cba266a865a061287c0e38",
     "grade": false,
     "grade_id": "cell-5edbd481562ad91f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "bfac7774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25: \n",
      "1.92 ms  322 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n",
      "LSI: \n",
      "31.5 ms  3.92 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n",
      "LDA: \n",
      "29.2 ms  2.17 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n",
      "W2V: \n",
      "23.6 ms  4.09 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n",
      "W2V(Pretrained): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.2 ms  7.34 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n",
      "D2V:\n",
      "123 ms  19.5 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "query = \"algebraic functions\"\n",
    "print(\"BM25: \")\n",
    "%timeit bm25_search(query, 2)\n",
    "print(\"LSI: \")\n",
    "%timeit lsi_rerank.search(query)\n",
    "print(\"LDA: \")\n",
    "%timeit lda_rerank.search(query)\n",
    "print(\"W2V: \")\n",
    "%timeit w2v_rerank.search(query)\n",
    "print(\"W2V(Pretrained): \")\n",
    "%timeit w2v_pretrained_rerank.search(query)\n",
    "print(\"D2V:\")\n",
    "%timeit d2v_rerank.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00161-7e54209c-2f42-4a49-bab8-78710df71f6b",
    "deepnote_cell_height": 55,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c45c5e3f015b2de89d9d39ae3766368b",
     "grade": false,
     "grade_id": "cell-85c50f2ab9eec301",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "As you can see, it is much faster (but BM25 is still orders of magnitude faster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00162-b811d517-f3b2-45f1-9dac-88d1fe08cfda",
    "deepnote_cell_height": 311.375,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e2f3388e3807659f303fe31a75a010e",
     "grade": false,
     "grade_id": "cell-5071bb99b2af61cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 10: Evaluation & Analysis (30 points) <a class=\"anchor\" id=\"reranking_eval\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "[Previously](#evaluation) we have implemented some evaluation metrics and used them for measuring the ranking performance of term-based IR algorithms. In this section, we will do the same for semantic methods, both with and without re-ranking.\n",
    "\n",
    "### Section 10.1: Plot (10 points)\n",
    "\n",
    "First, gather the results. The results should consider the index set, the different search functions and different metrics. Plot the results in bar charts, per metric, with clear labels.\n",
    "\n",
    "Then, gather only the re-ranking models, and plot and compare them with the results obtained in part 1 (only index set 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "cell_id": "00163-2e475730-a0ad-40ed-b4cf-04ccd10e3e34",
    "deepnote_cell_height": 297,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "editable": false,
    "execution_millis": 5,
    "execution_start": 1645189150648,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe81520ac6413a803838913fd64de03",
     "grade": false,
     "grade_id": "cell-b672fe6dfae0b1ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "c2b8785a"
   },
   "outputs": [],
   "source": [
    "list_of_sem_search_fns = [\n",
    "    (\"lda\", drm_lda.search),\n",
    "    (\"lsi\", drm_lsi.search),\n",
    "    (\"w2v\", drm_w2v.search),\n",
    "    (\"w2v_pretrained\", drm_w2v_pretrained.search),\n",
    "    (\"d2v\", drm_d2v.search),\n",
    "    (\"lsi_rr\", lsi_rerank.search),\n",
    "    (\"lda_rr\", lda_rerank.search),\n",
    "    (\"w2v_rr\", w2v_rerank.search),\n",
    "    (\"w2v_pretrained_rr\", w2v_pretrained_rerank.search),\n",
    "    (\"d2v_rr\", d2v_rerank.search),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "cell_id": "00164-ba70f9d6-5fd4-4ccc-9243-56081705849b",
    "deepnote_cell_height": 2368.78125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     472.390625,
     472.390625
    ],
    "deepnote_to_be_reexecuted": false,
    "deletable": false,
    "execution_millis": 699543,
    "execution_start": 1645197094542,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54707c4afac084299aeefa047259b4a9",
     "grade": true,
     "grade_id": "cell-7dd8273b0f5a3c22",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "source_hash": "7b8cce53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vanilla\n",
      "\tlda\n",
      "{'ERR': 0.10726382,\n",
      " 'MAP': 0.050203778,\n",
      " 'Precision@1': 0.057692308,\n",
      " 'Precision@10': 0.07115385,\n",
      " 'Precision@5': 0.09230769,\n",
      " 'Recall@1': 0.004166667,\n",
      " 'Recall@10': 0.06741483,\n",
      " 'Recall@5': 0.050696727}\n",
      "\tlsi\n",
      "{'ERR': 0.12303415,\n",
      " 'MAP': 0.063562624,\n",
      " 'Precision@1': 0.115384616,\n",
      " 'Precision@10': 0.075,\n",
      " 'Precision@5': 0.08846155,\n",
      " 'Recall@1': 0.015510531,\n",
      " 'Recall@10': 0.05435463,\n",
      " 'Recall@5': 0.03464716}\n",
      "\tw2v\n",
      "{'ERR': 0.010588806,\n",
      " 'MAP': 0.00883175,\n",
      " 'Precision@1': 0.0,\n",
      " 'Precision@10': 0.0038461538,\n",
      " 'Precision@5': 0.0038461538,\n",
      " 'Recall@1': 0.0,\n",
      " 'Recall@10': 0.002335165,\n",
      " 'Recall@5': 0.00096153846}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thesofakillers/miniconda3/envs/ir1/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tw2v_pretrained\n",
      "{'ERR': 0.054419413,\n",
      " 'MAP': 0.03211335,\n",
      " 'Precision@1': 0.01923077,\n",
      " 'Precision@10': 0.03846154,\n",
      " 'Precision@5': 0.046153847,\n",
      " 'Recall@1': 0.0006203474,\n",
      " 'Recall@10': 0.02390376,\n",
      " 'Recall@5': 0.01720492}\n",
      "\td2v\n",
      "{'ERR': 0.114532776,\n",
      " 'MAP': 0.04877985,\n",
      " 'Precision@1': 0.115384616,\n",
      " 'Precision@10': 0.057692308,\n",
      " 'Precision@5': 0.080769226,\n",
      " 'Recall@1': 0.0077195633,\n",
      " 'Recall@10': 0.042856924,\n",
      " 'Recall@5': 0.035504673}\n",
      "\n",
      "Reranked\n",
      "\tlsi\n",
      "{'ERR': 0.218711,\n",
      " 'MAP': 0.11692687,\n",
      " 'Precision@1': 0.1923077,\n",
      " 'Precision@10': 0.17884615,\n",
      " 'Precision@5': 0.18846154,\n",
      " 'Recall@1': 0.033948842,\n",
      " 'Recall@10': 0.26302183,\n",
      " 'Recall@5': 0.15124404}\n",
      "\tlda\n",
      "{'ERR': 0.2869446,\n",
      " 'MAP': 0.11570974,\n",
      " 'Precision@1': 0.30769232,\n",
      " 'Precision@10': 0.20769231,\n",
      " 'Precision@5': 0.23846155,\n",
      " 'Recall@1': 0.060911078,\n",
      " 'Recall@10': 0.33012375,\n",
      " 'Recall@5': 0.20121916}\n",
      "\tw2v\n",
      "{'ERR': 0.13271439,\n",
      " 'MAP': 0.08308046,\n",
      " 'Precision@1': 0.03846154,\n",
      " 'Precision@10': 0.107692294,\n",
      " 'Precision@5': 0.111538455,\n",
      " 'Recall@1': 0.0046822745,\n",
      " 'Recall@10': 0.19724187,\n",
      " 'Recall@5': 0.10667272}\n",
      "\tw2v_pretrained\n",
      "{'ERR': 0.16118278,\n",
      " 'MAP': 0.09908687,\n",
      " 'Precision@1': 0.09615385,\n",
      " 'Precision@10': 0.15,\n",
      " 'Precision@5': 0.14615384,\n",
      " 'Recall@1': 0.0070565995,\n",
      " 'Recall@10': 0.20512038,\n",
      " 'Recall@5': 0.10120458}\n",
      "\td2v\n",
      "{'ERR': 0.2531312,\n",
      " 'MAP': 0.13640016,\n",
      " 'Precision@1': 0.25,\n",
      " 'Precision@10': 0.21346153,\n",
      " 'Precision@5': 0.21153845,\n",
      " 'Recall@1': 0.042428486,\n",
      " 'Recall@10': 0.3309789,\n",
      " 'Recall@5': 0.15262762}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # YOUR CODE HERE\n",
    "# takes roughly 10 mins to run\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 8), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# need this to make side by side bars\n",
    "N = len(list_of_sem_search_fns) // 2\n",
    "method_loc = np.arange(N)\n",
    "bar_width = 0.25\n",
    "\n",
    "vanilla_search_fns = list_of_sem_search_fns[:N]\n",
    "reranked_search_fns = list_of_sem_search_fns[N:]\n",
    "\n",
    "search_fns_map = {\"Vanilla\": vanilla_search_fns, \"Reranked\": reranked_search_fns}\n",
    "\n",
    "for j, mode in enumerate([\"Vanilla\", \"Reranked\"]):\n",
    "    results = {}\n",
    "    print(f\"\\n{mode}\")\n",
    "    \n",
    "    for search_alg, search_fn in search_fns_map[mode]:\n",
    "        # remove _rr from reranked algo's so that the labels match\n",
    "        search_alg = search_alg.replace(\"_rr\", \"\")\n",
    "        results[search_alg] = evaluate_search_fn(search_fn, list_of_metrics)\n",
    "        print(f\"\\t{search_alg}\")\n",
    "        pprint(results[search_alg])\n",
    "\n",
    "    for i, (metric_name, _metric_fn) in enumerate(list_of_metrics):\n",
    "        metric_results = {k: v[metric_name] for k, v in results.items()}\n",
    "\n",
    "        labels = list(metric_results.keys())\n",
    "        values = [metric_results[label] for label in labels]\n",
    "\n",
    "        axes[i].grid(True, which=\"major\", axis=\"y\", alpha=0.35)\n",
    "        if i % 4 == 0:\n",
    "            axes[i].set_ylabel(\"Average Metric Value\")\n",
    "        if j == 0:\n",
    "            axes[i].bar(method_loc, values, bar_width, label=f\"{mode}\")\n",
    "        else:\n",
    "            axes[i].bar(method_loc + bar_width, values, bar_width, label=f\"{mode}\")\n",
    "            axes[i].set_xticks(method_loc + bar_width / 2)\n",
    "            axes[i].set_xticklabels(labels, rotation=30, ha=\"right\")\n",
    "            axes[i].set_title(metric_name)\n",
    "            if i == 7:\n",
    "                axes[i].legend()\n",
    "\n",
    "\n",
    "fig.suptitle(\"Comparison of different Semantic IR algorithms across various Metrics\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #2nd Plot: Compare semantic search with reranking to models from part 1,\n",
    "# commented out as it is extra work: uncomment and rerun to see (will take time)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 4, figsize=(14, 7), sharey=True)\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# list_of_rerank_sem_search_fns = [\n",
    "#     (\"lsi_rr\", lsi_rerank.search),\n",
    "#     (\"lda_rr\", lda_rerank.search),\n",
    "#     (\"w2v_rr\", w2v_rerank.search),\n",
    "#     # (\"w2v_pretrained_rr\", w2v_pretrained_rerank.search),\n",
    "#     (\"d2v_rr\", d2v_rerank.search),\n",
    "# ]\n",
    "\n",
    "# N = len(list_of_rerank_sem_search_fns + list_of_search_fns)\n",
    "# method_loc = np.arange(N)\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# for i, (search_alg, search_fn) in enumerate(reranked_search_fns + list_of_search_fns):\n",
    "#     if i >= len(list_of_rerank_sem_search_fns):\n",
    "#         results[search_alg] = evaluate_search_fn(\n",
    "#             search_fn, list_of_metrics, index_set=2\n",
    "#         )\n",
    "#     else:\n",
    "#         results[search_alg] = evaluate_search_fn(search_fn, list_of_metrics)\n",
    "\n",
    "# for i, (metric_name, _metric_fn) in enumerate(list_of_metrics):\n",
    "#     metric_results = {k: v[metric_name] for k, v in results.items()}\n",
    "\n",
    "#     labels = list(metric_results.keys())\n",
    "#     values = [metric_results[label] for label in labels]\n",
    "\n",
    "#     axes[i].grid(True, which=\"major\", axis=\"y\", alpha=0.35)\n",
    "#     if i % 4 == 0:\n",
    "#         axes[i].set_ylabel(\"Average Metric Value\")\n",
    "#     axes[i].bar(method_loc, values, bar_width)\n",
    "#     axes[i].set_xticks(method_loc)\n",
    "#     axes[i].set_xticklabels(labels, rotation=45)\n",
    "#     axes[i].set_title(metric_name)\n",
    "\n",
    "# fig.suptitle(\"Comparison between semantic and term-based ranking algorithms\")\n",
    "# fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00165-821599fc-9264-4123-a542-2b0354dde4f7",
    "deepnote_cell_height": 145.1875,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8a3b6189bdde66704c694d85e38d049",
     "grade": false,
     "grade_id": "cell-deb2ef3daa306e82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 10.2: Summary (20 points)\n",
    "\n",
    "Your summary should compare methods from Part 1 and Part 2 (only for index set 2). State what you expected to see in the results, followed by either supporting evidence *or* justify why the results did not support your expectations. Consider the availability of data, scalability, domain/type of data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00166-930e721d-9166-4296-ad5c-4c4449f6c99e",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff97c43837d10bff6aaffa75e1492887",
     "grade": true,
     "grade_id": "cell-ec5dd7d9cf59dd86",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. In general term-based models perform better than semantic ones. This is\n",
    "   somewhat surprising - we would expect that semantic models would be better at\n",
    "   capturing relevance without the need for relevant documents to contain the\n",
    "   exact tokens in the query.\n",
    "   - TODO why do semantic models perform worse?? ->some ideas:\n",
    "     1. pretrained models have been trained on a corpus from a different domain\n",
    "        therefore representations are not as good for current domain.\n",
    "     2. semantic models might be better for much larger corpus with more\n",
    "        documents where words occur more frequently in similar contexts.\n",
    "2. Reranking clearly works better. This might be due to the fact that we first\n",
    "   use term-based models and as discussed in 1. we know that term-based models\n",
    "   perform better in the first place.\n",
    "3. W2V performs very poorly - likely because the corpus is too small for\n",
    "   meaningful representations to be generated for words.\n",
    "4. LSI and LDA perform better than any of the word or document representation\n",
    "   models. Again could be because those methods use SVD for word representation\n",
    "   instead of learning based on data and should therefore be better for a\n",
    "   smaller corpus.\n",
    "\n",
    "## Notes Giulio\n",
    "\n",
    "- Maybe also add the even the pretrained w2v isn't that great, probably because\n",
    "  often words from our documents weren't found in the model, perhaps due to\n",
    "  different preprocessing pipelines or due to lack of finetuning on our end\n",
    "- ngl i dont know much about lda and lsi so hard for me to make other comments\n",
    "  here"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "13b77af2-2689-4e0d-949d-ce0f01912b71",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
